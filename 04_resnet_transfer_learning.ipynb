{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a173eb3-03df-4aeb-95a9-a614de5b79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.python.client import device_lib \n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet101V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "train_directory = \"./data/organized/train/\"\n",
    "val_directory = \"./data/organized/val/\"\n",
    "test_directory = \"./data/organized/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d648de32-2ca5-4252-ba24-1cef0209eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow Tensorflow to allocate GPU memory as needed, rather than pre-allocating the entire GPU memory at the start of program execution.\n",
    "# This option allows for better monitoring of system resource utilization.\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd548f5-acb9-4506-84e6-0808a3667318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(res101_base, show_shapes=True, expand_nested=True, show_dtype=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2194a53b-a541-433a-b779-7058381f58bf",
   "metadata": {},
   "source": [
    "### Creating tf datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d12ac8-a202-48f8-8b11-1260c51a0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function creates training, validation and test datasets using the file structure created in the\n",
    "# 01_create_train_val_test_directories notebook. \n",
    "# ===============================================================================================================\n",
    "def create_tensorflow_datasets(image_size=(700, 484), batch_size=32):\n",
    "    \n",
    "    train_dataset = image_dataset_from_directory(directory = train_directory,\n",
    "                                                 labels='inferred',\n",
    "                                                 label_mode = 'int',\n",
    "                                                 image_size=image_size,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 smart_resize=True)\n",
    "\n",
    "    val_dataset = image_dataset_from_directory(directory = val_directory,\n",
    "                                               labels='inferred',\n",
    "                                               label_mode = 'int',\n",
    "                                               image_size=image_size,\n",
    "                                               batch_size=batch_size,\n",
    "                                               smart_resize=True)\n",
    "\n",
    "    test_dataset = image_dataset_from_directory(directory = test_directory,\n",
    "                                                labels = \"inferred\",\n",
    "                                                label_mode = \"int\",\n",
    "                                                image_size=image_size,\n",
    "                                                batch_size=batch_size,\n",
    "                                                smart_resize=True)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b038a1-7505-43e0-b648-8b71f6363cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10520 files belonging to 196 classes.\n",
      "Found 3234 files belonging to 196 classes.\n",
      "Found 2431 files belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_tensorflow_datasets(image_size=(520, 520), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb7d04d-5d97-4060-8ec3-337b5378f7b1",
   "metadata": {},
   "source": [
    "### Resnet Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4370fd2-8a00-45d0-a5bc-c1f3d5a37268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is used to instantiate either the Adam or RMSProp optimizers with the desired learning rate.\n",
    "# ===============================================================================================================\n",
    "def get_optimizer(optimizer_name, lr):\n",
    "    \n",
    "    if optimizer_name == 'rmsprop':\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.RMSProp(learning_rate = lr)\n",
    "    \n",
    "    elif optimizer_name == 'adam':\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "        \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99a9f56c-ae65-448e-958c-dea7e7d0d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is used to generate a unique filename to save the \"best model\" found during training.\n",
    "# ===============================================================================================================\n",
    "def get_model_save_path(optimizer, lr, epochs, batch_size, model_name):\n",
    "    \n",
    "    optimizer_string = optimizer + str(lr).split('.')[1]\n",
    "    time_stamp = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    \n",
    "    model_save_path = os.path.join(os.getcwd(), f\"trained_models/convnet/{time_stamp}_{model_name}_E{epochs}_O{optimizer_string}_B{batch_size}.keras\")\n",
    "    \n",
    "    return model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f3b02fc-a22e-4997-94e3-5ea9e21bc917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function insantiates and compiles a model that contains the following:\n",
    "#\n",
    "# 1. A pretrained Resnet101 base model with all weights frozen.\n",
    "# 2. A set of keras preprocessing layers to perform random data augmentations.\n",
    "# 3. A \"model top\" (output dense classifier) that needs to be trained.\n",
    "# ===============================================================================================================\n",
    "def build_resnet_classifier(input_shape, optimizer, learning_rate, metrics):\n",
    "    \n",
    "    \n",
    "    optimizer = get_optimizer(optimizer, learning_rate)\n",
    "\n",
    "    res101_base = keras.applications.ResNet101V2(weights='imagenet',\n",
    "                                                 input_shape = input_shape,\n",
    "                                                 include_top=False)\n",
    "    \n",
    "    # Freeze the resnet backbone.\n",
    "    res101_base.trainable = False\n",
    "    \n",
    "    # Create a layer that is a set of data augmentations.\n",
    "    data_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "                                          layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "                                          layers.experimental.preprocessing.RandomZoom(0.2)])\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Perform data augmentation\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # Preprocess the images the way resnet101 expects them.\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    # Pass the input to the resnet101 backbone.\n",
    "    # Setting training = False tells the resnet to run its forward pass in inference mode\n",
    "    # rather than training mode.\n",
    "    x = res101_base(x, training = False)\n",
    "    \n",
    "    x = layers.GlobalAvgPool2D()(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    \n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = layers.Dense(196, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss = SparseCategoricalCrossentropy(),\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c792c9f-5453-4e50-8afa-709499f93b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is used for the following:\n",
    "#\n",
    "# 1. Setup callbacks and fit the model instantiated by the function above.\n",
    "# 2. Save the model history attribtue after training is completed.\n",
    "# ===============================================================================================================\n",
    "def train_convnet_classifier(model, train_ds, val_ds, epochs=20, model_save_path=None):\n",
    "    \n",
    "    callbacks = [\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            filepath=model_save_path,\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\")\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(train_ds,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_ds,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    try:\n",
    "        history_save_path = model_save_path.split(\".\")[0] + \"_HISTORY.csv\"\n",
    "        df = pd.DataFrame(history.history)\n",
    "        df.to_csv(history_save_path, index=False)\n",
    "    except:\n",
    "        print(\"Couldn't save history!\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39f8c3b0-d317-4f44-960c-5c15bc3c993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function takes as input a tensorflow dataset containing test data, and either a trained model\n",
    "# or the path to where a trained model is located. \n",
    "#\n",
    "# The function then evaluates the model using the test data and returns the associated test metrics.\n",
    "# ===============================================================================================================\n",
    "def test_convnet_classifier(test_ds, model=None, model_path=None):\n",
    "    \n",
    "    if model is not None:\n",
    "        \n",
    "        test_loss, test_acc = model.evaluate(test_ds)\n",
    "        print(\"\\n========================== Model Test Results ===============================\")\n",
    "        print(f\"Test Accuracy: {test_acc}\")\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "        print(\"=============================================================================\\n\")\n",
    "        \n",
    "    elif model_path is not None:\n",
    "        \n",
    "        model = keras.models.load_model(model_path)\n",
    "        test_loss, test_acc = model.evaluate(test_dataset)\n",
    "        print(\"\\n========================== Model Test Results ===============================\")\n",
    "        print(f\"Test Accuracy: {test_acc}\")\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "        print(\"=============================================================================\\n\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n========================== Error ===============================\")\n",
    "        print(\"Must pass either a trained model or a path to a trained model file.\")\n",
    "        print(\"Cannot have both model and model_path = None\")\n",
    "        print(\"=============================================================================\\n\")\n",
    "        return -1\n",
    "    \n",
    "    return test_loss, test_acc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1b81f40-f9c7-426c-bcd4-5be67a06bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function uses all the other functions defined above to drive the entire model training process.\n",
    "# The full process implemented by this function is as follows:\n",
    "#\n",
    "# 1. Instantiate and compile the model using the build_convnet_classifier function.\n",
    "# 2. Generate a uniue filepath to save the best model found during training.\n",
    "# 3. Train the model and save the history attribute after training.\n",
    "# 4. Evaluate the best model on the test data.\n",
    "# ===============================================================================================================\n",
    "def build_and_train_resnet(train_ds, val_ds, test_ds = None, input_shape=(520, 520, 3), optimizer='adam', metrics=['accuracy'],\n",
    "                           epochs=20, batch_size=32, lr = 0.001, model_name = 'resnet101'):\n",
    "    \n",
    "    \n",
    "    # Build and compile the model \n",
    "    model = build_resnet_classifier(input_shape=input_shape, optimizer=optimizer, learning_rate=lr, metrics=metrics)\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model_save_path = get_model_save_path(optimizer=optimizer, lr=lr, epochs=epochs, batch_size=batch_size, model_name=model_name)\n",
    "    \n",
    "    # Train the model\n",
    "    training_history = train_convnet_classifier(model, train_ds, val_ds, epochs=epochs, model_save_path=model_save_path)\n",
    "    \n",
    "    if test_ds is not None:\n",
    "        \n",
    "        test_loss, test_acc, best_model = test_convnet_classifier(test_ds, model=None, model_path=model_save_path)\n",
    "    \n",
    "    return training_history, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba17add2-a9b5-489b-a8d0-41f151fbadcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 520, 520, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda) (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet101v2 (Functional)     (None, 17, 17, 2048)      42626560  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 196)               50372     \n",
      "=================================================================\n",
      "Total params: 43,201,476\n",
      "Trainable params: 574,916\n",
      "Non-trainable params: 42,626,560\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "329/329 [==============================] - 237s 689ms/step - loss: 5.1643 - accuracy: 0.0143 - val_loss: 4.7391 - val_accuracy: 0.0476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/300\n",
      "329/329 [==============================] - 225s 682ms/step - loss: 4.6276 - accuracy: 0.0493 - val_loss: 4.0781 - val_accuracy: 0.1481\n",
      "Epoch 3/300\n",
      "329/329 [==============================] - 223s 678ms/step - loss: 4.1966 - accuracy: 0.0828 - val_loss: 3.6532 - val_accuracy: 0.2025\n",
      "Epoch 4/300\n",
      "329/329 [==============================] - 225s 682ms/step - loss: 3.8929 - accuracy: 0.1217 - val_loss: 3.3655 - val_accuracy: 0.2520\n",
      "Epoch 5/300\n",
      "329/329 [==============================] - 224s 679ms/step - loss: 3.6624 - accuracy: 0.1496 - val_loss: 3.1439 - val_accuracy: 0.2817\n",
      "Epoch 6/300\n",
      "329/329 [==============================] - 219s 666ms/step - loss: 3.4682 - accuracy: 0.1741 - val_loss: 2.9587 - val_accuracy: 0.3169\n",
      "Epoch 7/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 3.3168 - accuracy: 0.1999 - val_loss: 2.8020 - val_accuracy: 0.3435\n",
      "Epoch 8/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 3.1961 - accuracy: 0.2222 - val_loss: 2.7267 - val_accuracy: 0.3547\n",
      "Epoch 9/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 3.0691 - accuracy: 0.2475 - val_loss: 2.5940 - val_accuracy: 0.3726\n",
      "Epoch 10/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.9921 - accuracy: 0.2578 - val_loss: 2.5121 - val_accuracy: 0.3936\n",
      "Epoch 11/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.9274 - accuracy: 0.2703 - val_loss: 2.4465 - val_accuracy: 0.4054\n",
      "Epoch 12/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 2.8127 - accuracy: 0.2894 - val_loss: 2.3732 - val_accuracy: 0.4307\n",
      "Epoch 13/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 2.7499 - accuracy: 0.3040 - val_loss: 2.2900 - val_accuracy: 0.4357\n",
      "Epoch 14/300\n",
      "329/329 [==============================] - 216s 657ms/step - loss: 2.6938 - accuracy: 0.3120 - val_loss: 2.2478 - val_accuracy: 0.4465\n",
      "Epoch 15/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 2.6340 - accuracy: 0.3257 - val_loss: 2.1998 - val_accuracy: 0.4456\n",
      "Epoch 16/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 2.5682 - accuracy: 0.3414 - val_loss: 2.1438 - val_accuracy: 0.4589\n",
      "Epoch 17/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 2.5288 - accuracy: 0.3471 - val_loss: 2.1030 - val_accuracy: 0.4672\n",
      "Epoch 18/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 2.4632 - accuracy: 0.3607 - val_loss: 2.0641 - val_accuracy: 0.4743\n",
      "Epoch 19/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 2.4255 - accuracy: 0.3736 - val_loss: 2.0399 - val_accuracy: 0.4799\n",
      "Epoch 20/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 2.4002 - accuracy: 0.3753 - val_loss: 1.9997 - val_accuracy: 0.4907\n",
      "Epoch 21/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 2.3508 - accuracy: 0.3862 - val_loss: 1.9574 - val_accuracy: 0.4981\n",
      "Epoch 22/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 2.3339 - accuracy: 0.3859 - val_loss: 1.9270 - val_accuracy: 0.5043\n",
      "Epoch 23/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 2.3092 - accuracy: 0.3924 - val_loss: 1.9151 - val_accuracy: 0.5071\n",
      "Epoch 24/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 2.2533 - accuracy: 0.4031 - val_loss: 1.8846 - val_accuracy: 0.5043\n",
      "Epoch 25/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 2.2288 - accuracy: 0.4031 - val_loss: 1.8670 - val_accuracy: 0.5111\n",
      "Epoch 26/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 2.1817 - accuracy: 0.4176 - val_loss: 1.8343 - val_accuracy: 0.5118\n",
      "Epoch 27/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 2.1805 - accuracy: 0.4180 - val_loss: 1.8262 - val_accuracy: 0.5198\n",
      "Epoch 28/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.1478 - accuracy: 0.4202 - val_loss: 1.7874 - val_accuracy: 0.5291\n",
      "Epoch 29/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 2.1014 - accuracy: 0.4352 - val_loss: 1.7726 - val_accuracy: 0.5312\n",
      "Epoch 30/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 2.0683 - accuracy: 0.4447 - val_loss: 1.7492 - val_accuracy: 0.5380\n",
      "Epoch 31/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 2.0477 - accuracy: 0.4491 - val_loss: 1.7366 - val_accuracy: 0.5340\n",
      "Epoch 32/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.0323 - accuracy: 0.4502 - val_loss: 1.7482 - val_accuracy: 0.5390\n",
      "Epoch 33/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.0235 - accuracy: 0.4543 - val_loss: 1.7012 - val_accuracy: 0.5408\n",
      "Epoch 34/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.9824 - accuracy: 0.4719 - val_loss: 1.6777 - val_accuracy: 0.5399\n",
      "Epoch 35/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.9520 - accuracy: 0.4706 - val_loss: 1.6591 - val_accuracy: 0.5430\n",
      "Epoch 36/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.9502 - accuracy: 0.4670 - val_loss: 1.6521 - val_accuracy: 0.5476\n",
      "Epoch 37/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.9274 - accuracy: 0.4747 - val_loss: 1.6606 - val_accuracy: 0.5427\n",
      "Epoch 38/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.8939 - accuracy: 0.4894 - val_loss: 1.6359 - val_accuracy: 0.5485\n",
      "Epoch 39/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.8752 - accuracy: 0.4869 - val_loss: 1.6340 - val_accuracy: 0.5492\n",
      "Epoch 40/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.8691 - accuracy: 0.4824 - val_loss: 1.6227 - val_accuracy: 0.5476\n",
      "Epoch 41/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.8496 - accuracy: 0.4882 - val_loss: 1.6135 - val_accuracy: 0.5526\n",
      "Epoch 42/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.8451 - accuracy: 0.4913 - val_loss: 1.6035 - val_accuracy: 0.5550\n",
      "Epoch 43/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.8355 - accuracy: 0.4969 - val_loss: 1.5746 - val_accuracy: 0.5656\n",
      "Epoch 44/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.8039 - accuracy: 0.5028 - val_loss: 1.5698 - val_accuracy: 0.5717\n",
      "Epoch 45/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.7831 - accuracy: 0.5099 - val_loss: 1.5817 - val_accuracy: 0.5686\n",
      "Epoch 46/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.7825 - accuracy: 0.5128 - val_loss: 1.5632 - val_accuracy: 0.5699\n",
      "Epoch 47/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.7603 - accuracy: 0.5155 - val_loss: 1.5428 - val_accuracy: 0.5711\n",
      "Epoch 48/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.7396 - accuracy: 0.5128 - val_loss: 1.5457 - val_accuracy: 0.5683\n",
      "Epoch 49/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.7468 - accuracy: 0.5092 - val_loss: 1.5276 - val_accuracy: 0.5668\n",
      "Epoch 50/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.7453 - accuracy: 0.5130 - val_loss: 1.5340 - val_accuracy: 0.5748\n",
      "Epoch 51/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.6996 - accuracy: 0.5240 - val_loss: 1.5042 - val_accuracy: 0.5748\n",
      "Epoch 52/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.6842 - accuracy: 0.5299 - val_loss: 1.5136 - val_accuracy: 0.5785\n",
      "Epoch 53/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.6955 - accuracy: 0.5325 - val_loss: 1.5070 - val_accuracy: 0.5804\n",
      "Epoch 54/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.6830 - accuracy: 0.5298 - val_loss: 1.5009 - val_accuracy: 0.5816\n",
      "Epoch 55/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.6469 - accuracy: 0.5404 - val_loss: 1.4784 - val_accuracy: 0.5860\n",
      "Epoch 56/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.6506 - accuracy: 0.5437 - val_loss: 1.4889 - val_accuracy: 0.5829\n",
      "Epoch 57/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.6420 - accuracy: 0.5361 - val_loss: 1.4848 - val_accuracy: 0.5847\n",
      "Epoch 58/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.6021 - accuracy: 0.5477 - val_loss: 1.4593 - val_accuracy: 0.5928\n",
      "Epoch 59/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.6159 - accuracy: 0.5453 - val_loss: 1.4749 - val_accuracy: 0.5844\n",
      "Epoch 60/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.6128 - accuracy: 0.5453 - val_loss: 1.4703 - val_accuracy: 0.5844\n",
      "Epoch 61/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.6047 - accuracy: 0.5474 - val_loss: 1.4794 - val_accuracy: 0.5844\n",
      "Epoch 62/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.5893 - accuracy: 0.5543 - val_loss: 1.4592 - val_accuracy: 0.5823\n",
      "Epoch 63/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.5737 - accuracy: 0.5550 - val_loss: 1.4681 - val_accuracy: 0.5857\n",
      "Epoch 64/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.5763 - accuracy: 0.5571 - val_loss: 1.4533 - val_accuracy: 0.5940\n",
      "Epoch 65/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.5603 - accuracy: 0.5566 - val_loss: 1.4629 - val_accuracy: 0.5903\n",
      "Epoch 66/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.5352 - accuracy: 0.5668 - val_loss: 1.4249 - val_accuracy: 0.6042\n",
      "Epoch 67/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.5559 - accuracy: 0.5572 - val_loss: 1.4521 - val_accuracy: 0.5878\n",
      "Epoch 68/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.5421 - accuracy: 0.5662 - val_loss: 1.4419 - val_accuracy: 0.5949\n",
      "Epoch 69/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.5389 - accuracy: 0.5644 - val_loss: 1.4244 - val_accuracy: 0.5993\n",
      "Epoch 70/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.5033 - accuracy: 0.5688 - val_loss: 1.4208 - val_accuracy: 0.5968\n",
      "Epoch 71/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.5311 - accuracy: 0.5657 - val_loss: 1.4234 - val_accuracy: 0.6005\n",
      "Epoch 72/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.5198 - accuracy: 0.5712 - val_loss: 1.4133 - val_accuracy: 0.5999\n",
      "Epoch 73/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.4841 - accuracy: 0.5815 - val_loss: 1.4137 - val_accuracy: 0.6002\n",
      "Epoch 74/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.4979 - accuracy: 0.5749 - val_loss: 1.4155 - val_accuracy: 0.5980\n",
      "Epoch 75/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.4736 - accuracy: 0.5754 - val_loss: 1.4104 - val_accuracy: 0.6020\n",
      "Epoch 76/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.4813 - accuracy: 0.5764 - val_loss: 1.3931 - val_accuracy: 0.6045\n",
      "Epoch 77/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.4856 - accuracy: 0.5745 - val_loss: 1.3868 - val_accuracy: 0.6095\n",
      "Epoch 78/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.4524 - accuracy: 0.5820 - val_loss: 1.3911 - val_accuracy: 0.6092\n",
      "Epoch 79/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.4388 - accuracy: 0.5858 - val_loss: 1.4035 - val_accuracy: 0.6051\n",
      "Epoch 80/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.4283 - accuracy: 0.5885 - val_loss: 1.3934 - val_accuracy: 0.6098\n",
      "Epoch 81/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.4486 - accuracy: 0.5774 - val_loss: 1.3901 - val_accuracy: 0.6027\n",
      "Epoch 82/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.4417 - accuracy: 0.5894 - val_loss: 1.3724 - val_accuracy: 0.6051\n",
      "Epoch 83/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.4342 - accuracy: 0.5894 - val_loss: 1.3722 - val_accuracy: 0.6104\n",
      "Epoch 84/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.4228 - accuracy: 0.5910 - val_loss: 1.3579 - val_accuracy: 0.6095\n",
      "Epoch 85/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.4206 - accuracy: 0.5916 - val_loss: 1.3744 - val_accuracy: 0.6079\n",
      "Epoch 86/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.4110 - accuracy: 0.5980 - val_loss: 1.3796 - val_accuracy: 0.6104\n",
      "Epoch 87/300\n",
      "329/329 [==============================] - 217s 658ms/step - loss: 1.3876 - accuracy: 0.6007 - val_loss: 1.3686 - val_accuracy: 0.6113\n",
      "Epoch 88/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.3962 - accuracy: 0.5963 - val_loss: 1.3676 - val_accuracy: 0.6144\n",
      "Epoch 89/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.3854 - accuracy: 0.6015 - val_loss: 1.3632 - val_accuracy: 0.6116\n",
      "Epoch 90/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.3795 - accuracy: 0.6019 - val_loss: 1.3696 - val_accuracy: 0.6141\n",
      "Epoch 91/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3746 - accuracy: 0.6097 - val_loss: 1.3501 - val_accuracy: 0.6218\n",
      "Epoch 92/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3808 - accuracy: 0.6025 - val_loss: 1.3512 - val_accuracy: 0.6178\n",
      "Epoch 93/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.3452 - accuracy: 0.6106 - val_loss: 1.3532 - val_accuracy: 0.6160\n",
      "Epoch 94/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.3594 - accuracy: 0.6067 - val_loss: 1.3624 - val_accuracy: 0.6132\n",
      "Epoch 95/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3619 - accuracy: 0.6119 - val_loss: 1.3406 - val_accuracy: 0.6194\n",
      "Epoch 96/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3436 - accuracy: 0.6098 - val_loss: 1.3564 - val_accuracy: 0.6122\n",
      "Epoch 97/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3377 - accuracy: 0.6125 - val_loss: 1.3627 - val_accuracy: 0.6101\n",
      "Epoch 98/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.3470 - accuracy: 0.6057 - val_loss: 1.3582 - val_accuracy: 0.6122\n",
      "Epoch 99/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.3293 - accuracy: 0.6147 - val_loss: 1.3687 - val_accuracy: 0.6129\n",
      "Epoch 100/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3377 - accuracy: 0.6125 - val_loss: 1.3425 - val_accuracy: 0.6172\n",
      "Epoch 101/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.3322 - accuracy: 0.6166 - val_loss: 1.3382 - val_accuracy: 0.6218\n",
      "Epoch 102/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3143 - accuracy: 0.6212 - val_loss: 1.3427 - val_accuracy: 0.6153\n",
      "Epoch 103/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3330 - accuracy: 0.6135 - val_loss: 1.3348 - val_accuracy: 0.6153\n",
      "Epoch 104/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.3021 - accuracy: 0.6222 - val_loss: 1.3311 - val_accuracy: 0.6172\n",
      "Epoch 105/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3067 - accuracy: 0.6166 - val_loss: 1.3432 - val_accuracy: 0.6153\n",
      "Epoch 106/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3032 - accuracy: 0.6230 - val_loss: 1.3269 - val_accuracy: 0.6206\n",
      "Epoch 107/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3025 - accuracy: 0.6212 - val_loss: 1.3328 - val_accuracy: 0.6231\n",
      "Epoch 108/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3181 - accuracy: 0.6202 - val_loss: 1.3318 - val_accuracy: 0.6240\n",
      "Epoch 109/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3005 - accuracy: 0.6189 - val_loss: 1.3444 - val_accuracy: 0.6153\n",
      "Epoch 110/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2836 - accuracy: 0.6268 - val_loss: 1.3196 - val_accuracy: 0.6246\n",
      "Epoch 111/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2754 - accuracy: 0.6292 - val_loss: 1.3365 - val_accuracy: 0.6231\n",
      "Epoch 112/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2703 - accuracy: 0.6298 - val_loss: 1.3221 - val_accuracy: 0.6268\n",
      "Epoch 113/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.2630 - accuracy: 0.6314 - val_loss: 1.3242 - val_accuracy: 0.6175\n",
      "Epoch 114/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2792 - accuracy: 0.6239 - val_loss: 1.3279 - val_accuracy: 0.6212\n",
      "Epoch 115/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2777 - accuracy: 0.6218 - val_loss: 1.3166 - val_accuracy: 0.6224\n",
      "Epoch 116/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.2816 - accuracy: 0.6208 - val_loss: 1.3145 - val_accuracy: 0.6234\n",
      "Epoch 117/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.2631 - accuracy: 0.6330 - val_loss: 1.3180 - val_accuracy: 0.6259\n",
      "Epoch 118/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2691 - accuracy: 0.6317 - val_loss: 1.3210 - val_accuracy: 0.6215\n",
      "Epoch 119/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.2638 - accuracy: 0.6274 - val_loss: 1.3388 - val_accuracy: 0.6147\n",
      "Epoch 120/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.2632 - accuracy: 0.6312 - val_loss: 1.3213 - val_accuracy: 0.6302\n",
      "Epoch 121/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2516 - accuracy: 0.6289 - val_loss: 1.3319 - val_accuracy: 0.6246\n",
      "Epoch 122/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2437 - accuracy: 0.6315 - val_loss: 1.3073 - val_accuracy: 0.6246\n",
      "Epoch 123/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.2475 - accuracy: 0.6331 - val_loss: 1.3088 - val_accuracy: 0.6274\n",
      "Epoch 124/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2405 - accuracy: 0.6349 - val_loss: 1.3249 - val_accuracy: 0.6181\n",
      "Epoch 125/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2449 - accuracy: 0.6373 - val_loss: 1.3303 - val_accuracy: 0.6206\n",
      "Epoch 126/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.2366 - accuracy: 0.6356 - val_loss: 1.3204 - val_accuracy: 0.6262\n",
      "Epoch 127/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.2332 - accuracy: 0.6367 - val_loss: 1.3163 - val_accuracy: 0.6234\n",
      "Epoch 128/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2244 - accuracy: 0.6370 - val_loss: 1.3135 - val_accuracy: 0.6320\n",
      "Epoch 129/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.2084 - accuracy: 0.6448 - val_loss: 1.3291 - val_accuracy: 0.6228\n",
      "Epoch 130/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2245 - accuracy: 0.6444 - val_loss: 1.3343 - val_accuracy: 0.6178\n",
      "Epoch 131/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2231 - accuracy: 0.6389 - val_loss: 1.3136 - val_accuracy: 0.6357\n",
      "Epoch 132/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.1920 - accuracy: 0.6510 - val_loss: 1.3209 - val_accuracy: 0.6274\n",
      "Epoch 133/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.1942 - accuracy: 0.6521 - val_loss: 1.3051 - val_accuracy: 0.6305\n",
      "Epoch 134/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2019 - accuracy: 0.6467 - val_loss: 1.3170 - val_accuracy: 0.6246\n",
      "Epoch 135/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2067 - accuracy: 0.6465 - val_loss: 1.3197 - val_accuracy: 0.6259\n",
      "Epoch 136/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.1945 - accuracy: 0.6496 - val_loss: 1.3148 - val_accuracy: 0.6280\n",
      "Epoch 137/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1827 - accuracy: 0.6490 - val_loss: 1.3250 - val_accuracy: 0.6280\n",
      "Epoch 138/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2115 - accuracy: 0.6424 - val_loss: 1.3131 - val_accuracy: 0.6268\n",
      "Epoch 139/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2140 - accuracy: 0.6466 - val_loss: 1.3276 - val_accuracy: 0.6314\n",
      "Epoch 140/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1812 - accuracy: 0.6514 - val_loss: 1.3100 - val_accuracy: 0.6311\n",
      "Epoch 141/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1833 - accuracy: 0.6503 - val_loss: 1.3040 - val_accuracy: 0.6302\n",
      "Epoch 142/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1998 - accuracy: 0.6433 - val_loss: 1.3147 - val_accuracy: 0.6308\n",
      "Epoch 143/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1834 - accuracy: 0.6514 - val_loss: 1.3303 - val_accuracy: 0.6293\n",
      "Epoch 144/300\n",
      "329/329 [==============================] - 219s 666ms/step - loss: 1.1699 - accuracy: 0.6546 - val_loss: 1.3088 - val_accuracy: 0.6302\n",
      "Epoch 145/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 1.1550 - accuracy: 0.6588 - val_loss: 1.3094 - val_accuracy: 0.6342\n",
      "Epoch 146/300\n",
      "329/329 [==============================] - 217s 658ms/step - loss: 1.1549 - accuracy: 0.6610 - val_loss: 1.3056 - val_accuracy: 0.6274\n",
      "Epoch 147/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.1343 - accuracy: 0.6608 - val_loss: 1.3115 - val_accuracy: 0.6311\n",
      "Epoch 148/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 1.1768 - accuracy: 0.6544 - val_loss: 1.3264 - val_accuracy: 0.6345\n",
      "Epoch 149/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 1.1483 - accuracy: 0.6562 - val_loss: 1.3184 - val_accuracy: 0.6317\n",
      "Epoch 150/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.1570 - accuracy: 0.6512 - val_loss: 1.3074 - val_accuracy: 0.6388\n",
      "Epoch 151/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1512 - accuracy: 0.6554 - val_loss: 1.3320 - val_accuracy: 0.6296\n",
      "Epoch 152/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1629 - accuracy: 0.6539 - val_loss: 1.3407 - val_accuracy: 0.6286\n",
      "Epoch 153/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1428 - accuracy: 0.6575 - val_loss: 1.3139 - val_accuracy: 0.6286\n",
      "Epoch 154/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1249 - accuracy: 0.6660 - val_loss: 1.3197 - val_accuracy: 0.6308\n",
      "Epoch 155/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1522 - accuracy: 0.6612 - val_loss: 1.3338 - val_accuracy: 0.6296\n",
      "Epoch 156/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1484 - accuracy: 0.6592 - val_loss: 1.3231 - val_accuracy: 0.6320\n",
      "Epoch 157/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1249 - accuracy: 0.6682 - val_loss: 1.3110 - val_accuracy: 0.6330\n",
      "Epoch 158/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1459 - accuracy: 0.6547 - val_loss: 1.3390 - val_accuracy: 0.6252\n",
      "Epoch 159/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1279 - accuracy: 0.6646 - val_loss: 1.3265 - val_accuracy: 0.6283\n",
      "Epoch 160/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.1460 - accuracy: 0.6662 - val_loss: 1.3434 - val_accuracy: 0.6172\n",
      "Epoch 161/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1292 - accuracy: 0.6589 - val_loss: 1.3124 - val_accuracy: 0.6320\n",
      "Epoch 162/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1282 - accuracy: 0.6642 - val_loss: 1.3355 - val_accuracy: 0.6286\n",
      "Epoch 163/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1062 - accuracy: 0.6737 - val_loss: 1.3069 - val_accuracy: 0.6367\n",
      "Epoch 164/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.1120 - accuracy: 0.6694 - val_loss: 1.3310 - val_accuracy: 0.6240\n",
      "Epoch 165/300\n",
      "329/329 [==============================] - 216s 657ms/step - loss: 1.1144 - accuracy: 0.6749 - val_loss: 1.3236 - val_accuracy: 0.6320\n",
      "Epoch 166/300\n",
      "329/329 [==============================] - 218s 661ms/step - loss: 1.1168 - accuracy: 0.6721 - val_loss: 1.3241 - val_accuracy: 0.6259\n",
      "Epoch 167/300\n",
      "329/329 [==============================] - 222s 673ms/step - loss: 1.1121 - accuracy: 0.6676 - val_loss: 1.3209 - val_accuracy: 0.6333\n",
      "Epoch 168/300\n",
      "329/329 [==============================] - 222s 675ms/step - loss: 1.1100 - accuracy: 0.6673 - val_loss: 1.3364 - val_accuracy: 0.6215\n",
      "Epoch 169/300\n",
      "329/329 [==============================] - 223s 676ms/step - loss: 1.1160 - accuracy: 0.6666 - val_loss: 1.3001 - val_accuracy: 0.6342\n",
      "Epoch 170/300\n",
      "329/329 [==============================] - 223s 676ms/step - loss: 1.1186 - accuracy: 0.6699 - val_loss: 1.3178 - val_accuracy: 0.6296\n",
      "Epoch 171/300\n",
      "329/329 [==============================] - 223s 675ms/step - loss: 1.1096 - accuracy: 0.6671 - val_loss: 1.3162 - val_accuracy: 0.6370\n",
      "Epoch 172/300\n",
      "329/329 [==============================] - 222s 674ms/step - loss: 1.1114 - accuracy: 0.6726 - val_loss: 1.3255 - val_accuracy: 0.6302\n",
      "Epoch 173/300\n",
      "329/329 [==============================] - 222s 674ms/step - loss: 1.1190 - accuracy: 0.6713 - val_loss: 1.3025 - val_accuracy: 0.6407\n",
      "Epoch 174/300\n",
      "329/329 [==============================] - 222s 675ms/step - loss: 1.0938 - accuracy: 0.6751 - val_loss: 1.3080 - val_accuracy: 0.6299\n",
      "Epoch 175/300\n",
      "329/329 [==============================] - 222s 674ms/step - loss: 1.1019 - accuracy: 0.6704 - val_loss: 1.3331 - val_accuracy: 0.6184\n",
      "Epoch 176/300\n",
      "329/329 [==============================] - 222s 674ms/step - loss: 1.1081 - accuracy: 0.6679 - val_loss: 1.3194 - val_accuracy: 0.6289\n",
      "Epoch 177/300\n",
      "329/329 [==============================] - 231s 702ms/step - loss: 1.1139 - accuracy: 0.6665 - val_loss: 1.3208 - val_accuracy: 0.6286\n",
      "Epoch 178/300\n",
      "329/329 [==============================] - 243s 739ms/step - loss: 1.0874 - accuracy: 0.6793 - val_loss: 1.3203 - val_accuracy: 0.6249\n",
      "Epoch 179/300\n",
      "329/329 [==============================] - 243s 737ms/step - loss: 1.1138 - accuracy: 0.6702 - val_loss: 1.3083 - val_accuracy: 0.6314\n",
      "Epoch 180/300\n",
      "329/329 [==============================] - 243s 738ms/step - loss: 1.0910 - accuracy: 0.6765 - val_loss: 1.3648 - val_accuracy: 0.6178\n",
      "Epoch 181/300\n",
      "329/329 [==============================] - 243s 737ms/step - loss: 1.0797 - accuracy: 0.6801 - val_loss: 1.3069 - val_accuracy: 0.6398\n",
      "Epoch 182/300\n",
      "329/329 [==============================] - 245s 742ms/step - loss: 1.0860 - accuracy: 0.6724 - val_loss: 1.3394 - val_accuracy: 0.6246\n",
      "Epoch 183/300\n",
      "329/329 [==============================] - 243s 737ms/step - loss: 1.0872 - accuracy: 0.6708 - val_loss: 1.3253 - val_accuracy: 0.6283\n",
      "Epoch 184/300\n",
      "329/329 [==============================] - 243s 737ms/step - loss: 1.0793 - accuracy: 0.6778 - val_loss: 1.3200 - val_accuracy: 0.6320\n",
      "Epoch 185/300\n",
      "329/329 [==============================] - 231s 702ms/step - loss: 1.0812 - accuracy: 0.6815 - val_loss: 1.3195 - val_accuracy: 0.6255\n",
      "Epoch 186/300\n",
      "329/329 [==============================] - 227s 689ms/step - loss: 1.0679 - accuracy: 0.6753 - val_loss: 1.3050 - val_accuracy: 0.6351\n",
      "Epoch 187/300\n",
      "329/329 [==============================] - 218s 660ms/step - loss: 1.0996 - accuracy: 0.6725 - val_loss: 1.3406 - val_accuracy: 0.6280\n",
      "Epoch 188/300\n",
      "329/329 [==============================] - 213s 647ms/step - loss: 1.0708 - accuracy: 0.6768 - val_loss: 1.3113 - val_accuracy: 0.6379\n",
      "Epoch 189/300\n",
      "329/329 [==============================] - 212s 645ms/step - loss: 1.0585 - accuracy: 0.6820 - val_loss: 1.3020 - val_accuracy: 0.6388\n",
      "Epoch 190/300\n",
      "329/329 [==============================] - 218s 663ms/step - loss: 1.0629 - accuracy: 0.6851 - val_loss: 1.3141 - val_accuracy: 0.6351\n",
      "Epoch 191/300\n",
      "329/329 [==============================] - 236s 715ms/step - loss: 1.0775 - accuracy: 0.6779 - val_loss: 1.3258 - val_accuracy: 0.6296\n",
      "Epoch 192/300\n",
      "329/329 [==============================] - 230s 697ms/step - loss: 1.0705 - accuracy: 0.6770 - val_loss: 1.3048 - val_accuracy: 0.6382\n",
      "Epoch 193/300\n",
      "329/329 [==============================] - 231s 702ms/step - loss: 1.0568 - accuracy: 0.6837 - val_loss: 1.3317 - val_accuracy: 0.6370\n",
      "Epoch 194/300\n",
      "329/329 [==============================] - 234s 710ms/step - loss: 1.0642 - accuracy: 0.6847 - val_loss: 1.3116 - val_accuracy: 0.6367\n",
      "Epoch 195/300\n",
      "329/329 [==============================] - 231s 702ms/step - loss: 1.0593 - accuracy: 0.6863 - val_loss: 1.3164 - val_accuracy: 0.6280\n",
      "Epoch 196/300\n",
      "329/329 [==============================] - 227s 690ms/step - loss: 1.0601 - accuracy: 0.6828 - val_loss: 1.3267 - val_accuracy: 0.6348\n",
      "Epoch 197/300\n",
      "329/329 [==============================] - 229s 694ms/step - loss: 1.0675 - accuracy: 0.6795 - val_loss: 1.3140 - val_accuracy: 0.6296\n",
      "Epoch 198/300\n",
      "329/329 [==============================] - 234s 711ms/step - loss: 1.0646 - accuracy: 0.6780 - val_loss: 1.3336 - val_accuracy: 0.6314\n",
      "Epoch 199/300\n",
      "329/329 [==============================] - 235s 713ms/step - loss: 1.0431 - accuracy: 0.6876 - val_loss: 1.3292 - val_accuracy: 0.6320\n",
      "Epoch 200/300\n",
      "329/329 [==============================] - 237s 720ms/step - loss: 1.0812 - accuracy: 0.6809 - val_loss: 1.3168 - val_accuracy: 0.6370\n",
      "Epoch 201/300\n",
      "329/329 [==============================] - 237s 719ms/step - loss: 1.0882 - accuracy: 0.6739 - val_loss: 1.3273 - val_accuracy: 0.6299\n",
      "Epoch 202/300\n",
      "329/329 [==============================] - 237s 719ms/step - loss: 1.0435 - accuracy: 0.6888 - val_loss: 1.3191 - val_accuracy: 0.6373\n",
      "Epoch 203/300\n",
      "329/329 [==============================] - 235s 715ms/step - loss: 1.0642 - accuracy: 0.6853 - val_loss: 1.3228 - val_accuracy: 0.6327\n",
      "Epoch 204/300\n",
      "329/329 [==============================] - 234s 711ms/step - loss: 1.0605 - accuracy: 0.6825 - val_loss: 1.3184 - val_accuracy: 0.6370\n",
      "Epoch 205/300\n",
      "329/329 [==============================] - 239s 725ms/step - loss: 1.0534 - accuracy: 0.6828 - val_loss: 1.3097 - val_accuracy: 0.6348\n",
      "Epoch 206/300\n",
      "329/329 [==============================] - 235s 713ms/step - loss: 1.0544 - accuracy: 0.6909 - val_loss: 1.3081 - val_accuracy: 0.6342\n",
      "Epoch 207/300\n",
      "329/329 [==============================] - 228s 693ms/step - loss: 1.0486 - accuracy: 0.6905 - val_loss: 1.3226 - val_accuracy: 0.6351\n",
      "Epoch 208/300\n",
      "329/329 [==============================] - 214s 648ms/step - loss: 1.0422 - accuracy: 0.6917 - val_loss: 1.3375 - val_accuracy: 0.6333\n",
      "Epoch 209/300\n",
      "329/329 [==============================] - 213s 647ms/step - loss: 1.0270 - accuracy: 0.6909 - val_loss: 1.3361 - val_accuracy: 0.6382\n",
      "Epoch 210/300\n",
      "329/329 [==============================] - 219s 665ms/step - loss: 1.0588 - accuracy: 0.6861 - val_loss: 1.3213 - val_accuracy: 0.6293\n",
      "Epoch 211/300\n",
      "329/329 [==============================] - 234s 711ms/step - loss: 1.0207 - accuracy: 0.6926 - val_loss: 1.3157 - val_accuracy: 0.6370\n",
      "Epoch 212/300\n",
      "329/329 [==============================] - 234s 712ms/step - loss: 1.0302 - accuracy: 0.6967 - val_loss: 1.3246 - val_accuracy: 0.6308\n",
      "Epoch 213/300\n",
      "329/329 [==============================] - 232s 705ms/step - loss: 1.0249 - accuracy: 0.6924 - val_loss: 1.3167 - val_accuracy: 0.6398\n",
      "Epoch 214/300\n",
      "329/329 [==============================] - 235s 714ms/step - loss: 1.0242 - accuracy: 0.6907 - val_loss: 1.3136 - val_accuracy: 0.6327\n",
      "Epoch 215/300\n",
      "329/329 [==============================] - 235s 712ms/step - loss: 1.0282 - accuracy: 0.6867 - val_loss: 1.3213 - val_accuracy: 0.6395\n",
      "Epoch 216/300\n",
      "329/329 [==============================] - 233s 707ms/step - loss: 1.0186 - accuracy: 0.6925 - val_loss: 1.3349 - val_accuracy: 0.6314\n",
      "Epoch 217/300\n",
      "329/329 [==============================] - 237s 718ms/step - loss: 1.0414 - accuracy: 0.6918 - val_loss: 1.3371 - val_accuracy: 0.6314\n",
      "Epoch 218/300\n",
      "329/329 [==============================] - 231s 701ms/step - loss: 1.0256 - accuracy: 0.6942 - val_loss: 1.3252 - val_accuracy: 0.6336\n",
      "Epoch 219/300\n",
      "329/329 [==============================] - 231s 701ms/step - loss: 1.0317 - accuracy: 0.6902 - val_loss: 1.3361 - val_accuracy: 0.6271\n",
      "Epoch 220/300\n",
      "329/329 [==============================] - 239s 725ms/step - loss: 1.0315 - accuracy: 0.6916 - val_loss: 1.3462 - val_accuracy: 0.6370\n",
      "Epoch 221/300\n",
      "329/329 [==============================] - 233s 706ms/step - loss: 1.0246 - accuracy: 0.6923 - val_loss: 1.3118 - val_accuracy: 0.6407\n",
      "Epoch 222/300\n",
      "329/329 [==============================] - 231s 700ms/step - loss: 1.0329 - accuracy: 0.6871 - val_loss: 1.3352 - val_accuracy: 0.6314\n",
      "Epoch 223/300\n",
      "329/329 [==============================] - 236s 715ms/step - loss: 0.9996 - accuracy: 0.7017 - val_loss: 1.3451 - val_accuracy: 0.6286\n",
      "Epoch 224/300\n",
      "329/329 [==============================] - 233s 708ms/step - loss: 1.0024 - accuracy: 0.7010 - val_loss: 1.3326 - val_accuracy: 0.6320\n",
      "Epoch 225/300\n",
      "329/329 [==============================] - 217s 657ms/step - loss: 1.0379 - accuracy: 0.6900 - val_loss: 1.3405 - val_accuracy: 0.6317\n",
      "Epoch 226/300\n",
      "329/329 [==============================] - 217s 658ms/step - loss: 1.0233 - accuracy: 0.6908 - val_loss: 1.3223 - val_accuracy: 0.6255\n",
      "Epoch 227/300\n",
      "329/329 [==============================] - 217s 658ms/step - loss: 1.0163 - accuracy: 0.6957 - val_loss: 1.3253 - val_accuracy: 0.6367\n",
      "Epoch 228/300\n",
      "329/329 [==============================] - 217s 657ms/step - loss: 1.0070 - accuracy: 0.7010 - val_loss: 1.3326 - val_accuracy: 0.6407\n",
      "Epoch 229/300\n",
      "329/329 [==============================] - 217s 657ms/step - loss: 1.0101 - accuracy: 0.7013 - val_loss: 1.3252 - val_accuracy: 0.6395\n",
      "Epoch 230/300\n",
      "329/329 [==============================] - 217s 658ms/step - loss: 1.0063 - accuracy: 0.6984 - val_loss: 1.3246 - val_accuracy: 0.6336\n",
      "Epoch 231/300\n",
      "329/329 [==============================] - 217s 657ms/step - loss: 1.0239 - accuracy: 0.6915 - val_loss: 1.3438 - val_accuracy: 0.6308\n",
      "Epoch 232/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.0004 - accuracy: 0.6971 - val_loss: 1.3095 - val_accuracy: 0.6354\n",
      "Epoch 233/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.0135 - accuracy: 0.6942 - val_loss: 1.3112 - val_accuracy: 0.6379\n",
      "Epoch 234/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.0109 - accuracy: 0.6969 - val_loss: 1.3440 - val_accuracy: 0.6333\n",
      "Epoch 235/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 0.9909 - accuracy: 0.6981 - val_loss: 1.3453 - val_accuracy: 0.6367\n",
      "Epoch 236/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 0.9848 - accuracy: 0.7029 - val_loss: 1.3473 - val_accuracy: 0.6379\n",
      "Epoch 237/300\n",
      "329/329 [==============================] - 218s 661ms/step - loss: 1.0111 - accuracy: 0.7015 - val_loss: 1.3248 - val_accuracy: 0.6339\n",
      "Epoch 238/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.0107 - accuracy: 0.6999 - val_loss: 1.3094 - val_accuracy: 0.6361\n",
      "Epoch 239/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 1.0024 - accuracy: 0.7014 - val_loss: 1.3181 - val_accuracy: 0.6398\n",
      "Epoch 240/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 0.9779 - accuracy: 0.7068 - val_loss: 1.3129 - val_accuracy: 0.6456\n",
      "Epoch 241/300\n",
      "329/329 [==============================] - 216s 657ms/step - loss: 1.0258 - accuracy: 0.6903 - val_loss: 1.3325 - val_accuracy: 0.6388\n",
      "Epoch 242/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 0.9963 - accuracy: 0.6999 - val_loss: 1.3231 - val_accuracy: 0.6382\n",
      "Epoch 243/300\n",
      "329/329 [==============================] - 211s 641ms/step - loss: 1.0000 - accuracy: 0.7000 - val_loss: 1.3348 - val_accuracy: 0.6327\n",
      "Epoch 244/300\n",
      "329/329 [==============================] - 219s 664ms/step - loss: 0.9952 - accuracy: 0.7026 - val_loss: 1.3351 - val_accuracy: 0.6339\n",
      "Epoch 245/300\n",
      "329/329 [==============================] - 220s 668ms/step - loss: 1.0265 - accuracy: 0.6902 - val_loss: 1.3379 - val_accuracy: 0.6388\n",
      "Epoch 246/300\n",
      "329/329 [==============================] - 223s 676ms/step - loss: 1.0034 - accuracy: 0.6991 - val_loss: 1.3375 - val_accuracy: 0.6410\n",
      "Epoch 247/300\n",
      "329/329 [==============================] - 223s 678ms/step - loss: 0.9911 - accuracy: 0.6971 - val_loss: 1.3233 - val_accuracy: 0.6395\n",
      "Epoch 248/300\n",
      "329/329 [==============================] - 226s 685ms/step - loss: 0.9909 - accuracy: 0.7053 - val_loss: 1.3119 - val_accuracy: 0.6438\n",
      "Epoch 249/300\n",
      "329/329 [==============================] - 224s 680ms/step - loss: 0.9986 - accuracy: 0.6948 - val_loss: 1.3287 - val_accuracy: 0.6435\n",
      "Epoch 250/300\n",
      "329/329 [==============================] - 220s 669ms/step - loss: 0.9783 - accuracy: 0.7059 - val_loss: 1.3246 - val_accuracy: 0.6357\n",
      "Epoch 251/300\n",
      "329/329 [==============================] - 219s 664ms/step - loss: 0.9883 - accuracy: 0.7000 - val_loss: 1.3317 - val_accuracy: 0.6364\n",
      "Epoch 252/300\n",
      "329/329 [==============================] - 219s 665ms/step - loss: 0.9902 - accuracy: 0.6989 - val_loss: 1.3332 - val_accuracy: 0.6413\n",
      "Epoch 253/300\n",
      "329/329 [==============================] - 220s 668ms/step - loss: 0.9633 - accuracy: 0.7112 - val_loss: 1.3453 - val_accuracy: 0.6438\n",
      "Epoch 254/300\n",
      "329/329 [==============================] - 217s 657ms/step - loss: 0.9748 - accuracy: 0.7085 - val_loss: 1.3332 - val_accuracy: 0.6425\n",
      "Epoch 255/300\n",
      "329/329 [==============================] - 213s 646ms/step - loss: 0.9863 - accuracy: 0.7068 - val_loss: 1.3359 - val_accuracy: 0.6364\n",
      "Epoch 256/300\n",
      "329/329 [==============================] - 214s 648ms/step - loss: 0.9874 - accuracy: 0.7076 - val_loss: 1.3446 - val_accuracy: 0.6265\n",
      "Epoch 257/300\n",
      "329/329 [==============================] - 217s 658ms/step - loss: 1.0142 - accuracy: 0.6947 - val_loss: 1.3591 - val_accuracy: 0.6274\n",
      "Epoch 258/300\n",
      "329/329 [==============================] - 222s 672ms/step - loss: 0.9886 - accuracy: 0.7016 - val_loss: 1.3396 - val_accuracy: 0.6293\n",
      "Epoch 259/300\n",
      "329/329 [==============================] - 219s 666ms/step - loss: 0.9746 - accuracy: 0.7095 - val_loss: 1.3413 - val_accuracy: 0.6345\n",
      "Epoch 260/300\n",
      "329/329 [==============================] - 220s 667ms/step - loss: 0.9877 - accuracy: 0.6989 - val_loss: 1.3487 - val_accuracy: 0.6314\n",
      "Epoch 261/300\n",
      "329/329 [==============================] - 220s 667ms/step - loss: 0.9729 - accuracy: 0.7039 - val_loss: 1.3365 - val_accuracy: 0.6404\n",
      "Epoch 262/300\n",
      "329/329 [==============================] - 221s 671ms/step - loss: 0.9576 - accuracy: 0.7085 - val_loss: 1.3284 - val_accuracy: 0.6293\n",
      "Epoch 263/300\n",
      "329/329 [==============================] - 219s 665ms/step - loss: 0.9668 - accuracy: 0.7111 - val_loss: 1.3363 - val_accuracy: 0.6367\n",
      "Epoch 264/300\n",
      "329/329 [==============================] - 219s 664ms/step - loss: 0.9872 - accuracy: 0.7093 - val_loss: 1.3453 - val_accuracy: 0.6314\n",
      "Epoch 265/300\n",
      "329/329 [==============================] - 222s 673ms/step - loss: 0.9579 - accuracy: 0.7072 - val_loss: 1.3410 - val_accuracy: 0.6302\n",
      "Epoch 266/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 1.0065 - accuracy: 0.6964 - val_loss: 1.3161 - val_accuracy: 0.6429\n",
      "Epoch 267/300\n",
      "329/329 [==============================] - 216s 657ms/step - loss: 0.9505 - accuracy: 0.7122 - val_loss: 1.3320 - val_accuracy: 0.6395\n",
      "Epoch 268/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 1.0174 - accuracy: 0.6947 - val_loss: 1.3268 - val_accuracy: 0.6379\n",
      "Epoch 269/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 0.9787 - accuracy: 0.7040 - val_loss: 1.3321 - val_accuracy: 0.6342\n",
      "Epoch 270/300\n",
      "329/329 [==============================] - 217s 660ms/step - loss: 0.9726 - accuracy: 0.7083 - val_loss: 1.3285 - val_accuracy: 0.6391\n",
      "Epoch 271/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 0.9604 - accuracy: 0.7095 - val_loss: 1.3375 - val_accuracy: 0.6395\n",
      "Epoch 272/300\n",
      "329/329 [==============================] - 216s 655ms/step - loss: 0.9794 - accuracy: 0.7013 - val_loss: 1.3337 - val_accuracy: 0.6345\n",
      "Epoch 273/300\n",
      "329/329 [==============================] - 217s 659ms/step - loss: 0.9489 - accuracy: 0.7119 - val_loss: 1.3179 - val_accuracy: 0.6398\n",
      "Epoch 274/300\n",
      "329/329 [==============================] - 216s 657ms/step - loss: 0.9942 - accuracy: 0.7013 - val_loss: 1.3502 - val_accuracy: 0.6351\n",
      "Epoch 275/300\n",
      "329/329 [==============================] - 216s 657ms/step - loss: 0.9641 - accuracy: 0.7134 - val_loss: 1.3484 - val_accuracy: 0.6317\n",
      "Epoch 276/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 0.9750 - accuracy: 0.7056 - val_loss: 1.3633 - val_accuracy: 0.6351\n",
      "Epoch 277/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9662 - accuracy: 0.7057 - val_loss: 1.3574 - val_accuracy: 0.6348\n",
      "Epoch 278/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 0.9604 - accuracy: 0.7101 - val_loss: 1.3375 - val_accuracy: 0.6379\n",
      "Epoch 279/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 0.9707 - accuracy: 0.7113 - val_loss: 1.3483 - val_accuracy: 0.6296\n",
      "Epoch 280/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9324 - accuracy: 0.7221 - val_loss: 1.3620 - val_accuracy: 0.6271\n",
      "Epoch 281/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9843 - accuracy: 0.7040 - val_loss: 1.3886 - val_accuracy: 0.6293\n",
      "Epoch 282/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9655 - accuracy: 0.7102 - val_loss: 1.3512 - val_accuracy: 0.6314\n",
      "Epoch 283/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9633 - accuracy: 0.7123 - val_loss: 1.3347 - val_accuracy: 0.6342\n",
      "Epoch 284/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9602 - accuracy: 0.7101 - val_loss: 1.3538 - val_accuracy: 0.6330\n",
      "Epoch 285/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 0.9228 - accuracy: 0.7200 - val_loss: 1.3297 - val_accuracy: 0.6361\n",
      "Epoch 286/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 0.9517 - accuracy: 0.7129 - val_loss: 1.3487 - val_accuracy: 0.6299\n",
      "Epoch 287/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9726 - accuracy: 0.7105 - val_loss: 1.3460 - val_accuracy: 0.6410\n",
      "Epoch 288/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9555 - accuracy: 0.7123 - val_loss: 1.3556 - val_accuracy: 0.6296\n",
      "Epoch 289/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 0.9591 - accuracy: 0.7087 - val_loss: 1.3544 - val_accuracy: 0.6255\n",
      "Epoch 290/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 0.9289 - accuracy: 0.7139 - val_loss: 1.3606 - val_accuracy: 0.6376\n",
      "Epoch 291/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 0.9499 - accuracy: 0.7183 - val_loss: 1.3471 - val_accuracy: 0.6333\n",
      "Epoch 292/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9352 - accuracy: 0.7177 - val_loss: 1.3478 - val_accuracy: 0.6354\n",
      "Epoch 293/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9380 - accuracy: 0.7154 - val_loss: 1.3651 - val_accuracy: 0.6265\n",
      "Epoch 294/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9468 - accuracy: 0.7171 - val_loss: 1.3495 - val_accuracy: 0.6271\n",
      "Epoch 295/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9362 - accuracy: 0.7154 - val_loss: 1.3487 - val_accuracy: 0.6351\n",
      "Epoch 296/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 0.9614 - accuracy: 0.7113 - val_loss: 1.3601 - val_accuracy: 0.6382\n",
      "Epoch 297/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9602 - accuracy: 0.7102 - val_loss: 1.3511 - val_accuracy: 0.6320\n",
      "Epoch 298/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 0.9493 - accuracy: 0.7153 - val_loss: 1.3565 - val_accuracy: 0.6351\n",
      "Epoch 299/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9649 - accuracy: 0.7117 - val_loss: 1.3557 - val_accuracy: 0.6336\n",
      "Epoch 300/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 0.9415 - accuracy: 0.7117 - val_loss: 1.3421 - val_accuracy: 0.6404\n",
      "76/76 [==============================] - 39s 497ms/step - loss: 1.2735 - accuracy: 0.6528\n",
      "\n",
      "========================== Model Test Results ===============================\n",
      "Test Accuracy: 0.6528177857398987\n",
      "Test Loss: 1.2734698057174683\n",
      "=============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history, model = build_and_train_resnet(train_ds=train_dataset,\n",
    "                                         val_ds = val_dataset,\n",
    "                                         test_ds = test_dataset,\n",
    "                                         input_shape = (520, 520, 3),\n",
    "                                         optimizer = 'adam',\n",
    "                                         metrics=['accuracy'],\n",
    "                                         lr = 0.0005,\n",
    "                                         epochs=300,\n",
    "                                         batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce98376-9e04-42c8-9791-61b3c35dbaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d2078df-b5fb-4232-987b-24cd1d02a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./model_histories/first_resnet101_history_300epochs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1215bd7a-a71e-442f-9c64-760893c458c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./trained_models/2021_07_18-23_11_22_resnet101_E300_Oadam0005_B32_FINAL_EPOCH_SAVE.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "final_model_save_path = f\"./trained_models/2021_07_18-23_11_22_resnet101_E300_Oadam0005_B32_FINAL_EPOCH_SAVE.tf\"\n",
    "\n",
    "save_model(model=model, filepath=final_model_save_path, overwrite=True, include_optimizer=True, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55e7a211-40ba-446d-9fc5-3fe37a602b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 39s 491ms/step - loss: 1.2735 - accuracy: 0.6528\n",
      "\n",
      "========================== Model Test Results ===============================\n",
      "Test Accuracy: 0.6528177857398987\n",
      "Test Loss: 1.2734696865081787\n",
      "=============================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.2734696865081787,\n",
       " 0.6528177857398987,\n",
       " <tensorflow.python.keras.engine.functional.Functional at 0x14e4d72e220>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_convnet_classifier(test_dataset, model=None, model_path=final_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c99fce-674e-474b-91b7-ae5d4ec37e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
