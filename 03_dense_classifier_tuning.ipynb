{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc88d805-84e0-44f6-b99e-154c8614f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import keras_tuner as kt\n",
    "import tensorboard\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.python.client import device_lib \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet101V2, Xception, InceptionResNetV2\n",
    "from tensorflow.keras.applications import resnet_v2, xception, inception_resnet_v2\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "global PROJECT_DIRECTORY\n",
    "PROJECT_DIRECTORY = os.getcwd()\n",
    "\n",
    "train_directory = \"./data/organized/train/\"\n",
    "val_directory = \"./data/organized/val/\"\n",
    "test_directory = \"./data/organized/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5002cb59-118b-4bf4-90fc-60935d2eb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow Tensorflow to allocate GPU memory as needed, rather than pre-allocating the entire GPU memory at the start of program execution.\n",
    "# This option allows for better monitoring of system resource utilization.\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f8b31-ba01-419b-a3dd-1a666f1cbff5",
   "metadata": {},
   "source": [
    "## Creating a tensorflow dataset from TFRecord Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac0140ae-f018-4089-abec-f6dad5319b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is used to return the file paths to the tensorflow record shard files that contain the precalculated\n",
    "# base model (e.g. resnet) outputs. These files containing the precalculated outputs are created in the \n",
    "# 03_save_pretrained_model_outputs_tfr notebook.\n",
    "#\n",
    "# Additional logic has been implemented to give unique names to these files that would be useful if it was \n",
    "# ever desired to create multiple datasets worth of precalculated outputs (using randomly augmented image\n",
    "# variations) and implement a system where the datasets are swapped out at the end of each epoch. The idea behind\n",
    "# using such a system would be to better simulate the enviornment where the base model (resnet) is in the loop\n",
    "# and therefore data augmentation can be utilized as a preprocessing layer in the network. \n",
    "#\n",
    "# Using data augmentation as a preprocessing layer is highly desireable because it randomly augments the training\n",
    "# images at each training iteration, which results in the model being unlikely to ever see the same image twice. \n",
    "#\n",
    "# Unfortunately, using data augmentation as a preprocessing layer is not possible when precalculated resnet outputs\n",
    "# are utilized (and the resnet is removed from the loop) because the resnet is no longer there to continually provide\n",
    "# outputs for the randomly augmented images.\n",
    "#\n",
    "# The challenge with leaving the base model in the loop is that each training iteration becomes signiciantly more\n",
    "# expensive, because the most time consuming part of the network is processing each image through the large base model.\n",
    "# This increased overhead that occurs when leaving the base model in the loop makes it difficult to quickly\n",
    "# try out different architectures and hyperparameter options.\n",
    "# ===============================================================================================================\n",
    "def get_all_tf_shard_paths(base_model_type, input_shape, output_pooling, epoch_num, dataset_type):\n",
    "    \n",
    "    global PROJECT_DIRECTORY\n",
    "    \n",
    "    valid_dataset_types = ['train', 'val', 'test']\n",
    "    \n",
    "    if dataset_type not in valid_dataset_types:\n",
    "        print(\"/n===========================================================\")\n",
    "        print(\"Invalid input for parameter dataset_type\")\n",
    "        print(f\"Valid inputs are: {valid_dataset_types}\")\n",
    "        print(\"===========================================================\\n\")\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    base_outputs_directory = os.path.join(os.path.join(PROJECT_DIRECTORY, \"pretrained_model_output_features\"),\n",
    "                                          f\"{base_model_type}_pool{str(output_pooling)}_inShape_{str(input_shape)}\")\n",
    "    \n",
    "    \n",
    "    all_dirs = os.listdir(base_outputs_directory)\n",
    "    \n",
    "    correct_dir = [directory for directory in all_dirs if (dataset_type in directory) and (f'epoch_{epoch_num}' in directory)]\n",
    "        \n",
    "    if len(correct_dir) != 1:\n",
    "        print(\"/n============================ Error ===============================\")\n",
    "        print(\"Invalid directory filtering!\")\n",
    "        print(f\"Filtering returned: {correct_dir}\")\n",
    "        return -1\n",
    "        print(\"=========================================================================\\n\")\n",
    "            \n",
    "    correct_dir = correct_dir[0]\n",
    "        \n",
    "    filepath = os.path.join(base_outputs_directory, correct_dir)\n",
    "    \n",
    "    files = os.listdir(filepath)\n",
    "    \n",
    "    full_file_paths = [os.path.join(filepath, file) for file in files]\n",
    "    \n",
    "    return full_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7391395-c776-4531-b298-69e3a4173ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is used to parse the tfrecord files containing the precalculated resnet outputs and reshape the\n",
    "# tensors into the format that would be provided if the base model were left in the network.\n",
    "#\n",
    "# ===============================================================================================================\n",
    "def parse_tfrecords(example):\n",
    "    \n",
    "    feature_description = {\n",
    "        \"dim_1\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"dim_2\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"dim_3\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"raw_image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    \n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    \n",
    "    dim_1 = example['dim_1']\n",
    "    dim_2 = example['dim_2']\n",
    "    dim_3 = example['dim_3']\n",
    "    raw_image = example['raw_image']\n",
    "    label = example['label']\n",
    "    \n",
    "    feature = tf.io.parse_tensor(raw_image, out_type=tf.float32)\n",
    "    feature = tf.reshape(feature, shape=[dim_1, dim_2, dim_3])\n",
    "    \n",
    "    \n",
    "    return (feature, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112d40fb-8b1e-4143-80d2-eb0764a0795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is not utilized because the SparseCategoricalCrossentropy loss function utilized by the \n",
    "# build model function expects the target labels to be integers rather than one-hot encoder. \n",
    "#\n",
    "# If however, there was a desire to instead utilized one-hot encoded target labels and along with the similar\n",
    "# categorical_crossentropy loss function, this one_hot_encode_label helper function could be utilize to efficiently\n",
    "# perform the encoding as the data is read in.\n",
    "# \n",
    "# ===============================================================================================================\n",
    "def one_hot_encode_label(features, label):\n",
    "    label = tf.one_hot(tf.cast(label, tf.int32), 196)\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53e014bb-9bd5-4e6b-8e5a-44b4124a95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function uses the helper functions defined above to drive the entire process of obtaining the filepaths\n",
    "# for a desired set of tfrecord files, parsing the files and storing the information in a tensorflow dataset.\n",
    "#\n",
    "# ===============================================================================================================\n",
    "def get_dataset_from_multiple_tfrecords(base_model_type, dataset_type, batch_size, input_shape, output_pooling, epoch_num, compression = \"ZLIB\"):\n",
    "    \n",
    "    filepaths = get_all_tf_shard_paths(base_model_type = base_model_type,\n",
    "                                     input_shape = input_shape,\n",
    "                                     output_pooling = output_pooling,\n",
    "                                     epoch_num = epoch_num,\n",
    "                                     dataset_type = dataset_type)\n",
    "    \n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    #create the dataset\n",
    "    dataset = tf.data.TFRecordDataset(filepaths, compression_type = compression,num_parallel_reads=AUTOTUNE)\n",
    "\n",
    "    #pass every single feature through our mapping function\n",
    "    dataset = dataset.map(parse_tfrecords).shuffle(batch_size * 10).batch(32).prefetch(AUTOTUNE)\n",
    "    \n",
    "    # Uncomment if one-hot encoded targets are desired\n",
    "    #dataset = dataset.map(lambda x, y : (x, one_hot_encode_label(y)))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1039fb-47c1-4e68-8c18-1bcc3aa4a4a9",
   "metadata": {},
   "source": [
    "### Custom file swapping sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf21ae6-a4dc-454c-b78a-895c5e6d0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# The code in this cell is not currently utilized, but is left here as a starting point if there is a desire to\n",
    "# implement the idea of swapping out unique copies of precalculated output data at each epoch (or some multiple \n",
    "# of epochs).\n",
    "# \n",
    "# ===============================================================================================================\n",
    "'''\n",
    "class customSequence(Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.epoch = 0\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "            resize(imread(file_name), (200, 200))\n",
    "               for file_name in batch_x]), np.array(batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.epoch % N == 0:\n",
    "            pass\n",
    "        \n",
    "        # modify data\n",
    "        self.epoch += 1''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b15d24-d202-4820-b9bb-e152f2d9b74e",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf58a61f-6cbd-4f0f-bdd6-3c42b436739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================\n",
    "# Model building function to pass to keras tuner.\n",
    "#===================================================================================\n",
    "def tune_output_classifier(hp):\n",
    "    \n",
    "    # Number of Dense layers before the final Dense classifier. \n",
    "    num_layers = hp.Choice('num_layers', values=[0, 1, 2, 3])\n",
    "    \n",
    "    # These are always the first three layers no matter what. \n",
    "    inputs = keras.Input(shape=(17, 17, 2048))\n",
    "    \n",
    "    x = layers.GlobalAvgPool2D()(inputs)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    #===================================================================================\n",
    "    # Layer 3\n",
    "    # If there are three Dense layers before the final dense classifier.\n",
    "    #===================================================================================   \n",
    "    if hp.get('num_layers') >= 3:\n",
    "        with hp.conditional_scope(\"num_layers\", [3]):\n",
    "                 \n",
    "            # L2 regularization on the layers weights and biases.\n",
    "            layer3_kreg = hp.Choice('layer3_kreg', values = [0.0, 0.01, 0.001, 0.0001])\n",
    "            layer3_breg = hp.Choice('layer3_breg', values = [0.0, 0.01, 0.001, 0.0001])\n",
    "            \n",
    "            # Number of hidden units in the dense layer 3.\n",
    "            layer3_hidden_units = hp.Int('layer3_hidden_units',\n",
    "                                         min_value=768,\n",
    "                                         max_value=1024,\n",
    "                                         step=32,\n",
    "                                         default=1024)\n",
    "            \n",
    "            x = layers.Dense(layer3_hidden_units,\n",
    "                             activation=\"relu\",\n",
    "                             kernel_regularizer=l2(layer3_kreg),\n",
    "                             bias_regularizer=l2(layer3_breg))(x)\n",
    "            \n",
    "            # Dropout applied to the layers output.\n",
    "            #layer3_dropout = hp.Choice('layer3_dropout', values=[0.35, 0.4, 0.5], default = 0.5)\n",
    "            layer3_dropout = hp.Fixed('layer3_dropout', value=0.5)\n",
    "            x = layers.Dropout(layer3_dropout)(x)\n",
    "    \n",
    "    #===================================================================================\n",
    "    # Layer 2\n",
    "    # If there are two or more dense layers before the final dense classifier.\n",
    "    #===================================================================================   \n",
    "    if hp.get('num_layers') >= 2:\n",
    "        with hp.conditional_scope(\"num_layers\", [2, 3]):\n",
    "                \n",
    "            # L2 regularization on the layers weights and biases.\n",
    "            layer2_kreg = hp.Choice('layer2_kreg', values = [0.0, 0.01, 0.001, 0.0001])\n",
    "            layer2_breg = hp.Choice('layer2_breg', values = [0.0, 0.01, 0.001, 0.0001])\n",
    "            \n",
    "            # Options for the number of hidden units in Dense layer 2\n",
    "            layer2_hidden_units = hp.Int('layer2_hidden_units',\n",
    "                                         min_value=512,\n",
    "                                         max_value=768,\n",
    "                                         step=32,\n",
    "                                         default=512)\n",
    "            \n",
    "            # Adding the dense layer\n",
    "            x = layers.Dense(layer2_hidden_units,\n",
    "                             activation=\"relu\",\n",
    "                             kernel_regularizer=l2(layer2_kreg),\n",
    "                             bias_regularizer=l2(layer2_breg))(x)\n",
    "            \n",
    "            # Dropout applied to the output of layer 2.\n",
    "            #layer2_dropout = hp.Choice('layer2_dropout', values=[0.35, 0.4, 0.5], default = 0.5)\n",
    "            layer2_dropout = hp.Fixed('layer2_dropout', value=0.5)\n",
    "            x = layers.Dropout(layer2_dropout)(x)\n",
    "    \n",
    "    #===================================================================================\n",
    "    # Layer 1\n",
    "    # If there are one or more dense layers before the final dense classifier.\n",
    "    #===================================================================================        \n",
    "    if hp.get('num_layers') >= 1:\n",
    "        with hp.conditional_scope(\"num_layers\", [1, 2, 3]):\n",
    "            \n",
    "            # L2 regularization on the layers weights and biases.\n",
    "            layer1_kreg = hp.Choice('layer1_kreg', values = [0.0, 0.01, 0.001, 0.0001])\n",
    "            layer1_breg = hp.Choice('layer1_breg', values = [0.0, 0.01, 0.001, 0.0001])\n",
    "            \n",
    "            # Options for the number of hidden units in layer 2\n",
    "            layer1_hidden_units = hp.Int('layer1_hidden_units',\n",
    "                                         min_value=224,\n",
    "                                         max_value=512,\n",
    "                                         step=32,\n",
    "                                         default=256)\n",
    "\n",
    "            x = layers.Dense(layer1_hidden_units,\n",
    "                             activation=\"relu\",\n",
    "                             kernel_regularizer=l2(layer1_kreg),\n",
    "                             bias_regularizer=l2(layer1_breg))(x)\n",
    "    \n",
    "    # Dropout applied to the output of layer 2.\n",
    "    #layer1_dropout = hp.Choice('layer1_dropout', values=[0.35, 0.4, 0.5], default = 0.5)\n",
    "    layer1_dropout = hp.Fixed('layer1_dropout', value=0.5)\n",
    "    x = layers.Dropout(layer1_dropout)(x)\n",
    "    \n",
    "    \n",
    "    # Final Dense Classifier.\n",
    "    outputs = layers.Dense(196, activation = 'softmax')(x)\n",
    "    \n",
    "    \n",
    "    # Instantiate the model.\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    learning_rate = hp.Choice(name='learning_rate',\n",
    "                              values = [0.001, 0.002, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.00009])\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=learning_rate),\n",
    "                  metrics=  ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da5f9d21-8e55-46a2-bd13-ba9ed117f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================\n",
    "# Model building function to pass to keras tuner.\n",
    "#===================================================================================\n",
    "def tune_output_classifier_experiment_two(hp):\n",
    "    \n",
    "    # These are always the first three layers no matter what. \n",
    "    inputs = keras.Input(shape=(17, 17, 2048))\n",
    "    \n",
    "    pool_type = hp.Choice('pooling_strategy', values=['avg', 'max'])\n",
    "    \n",
    "    if pool_type == 'avg':\n",
    "        x = layers.GlobalAvgPool2D()(inputs)\n",
    "    elif pool_type == 'max':\n",
    "        x = layers.GlobalMaxPooling2D()(inputs)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    # Options for the number of hidden units in layer 1\n",
    "    layer1_hidden_units = hp.Int('layer1_hidden_units',\n",
    "                                 min_value=256,\n",
    "                                 max_value=512,\n",
    "                                 step=32)\n",
    "\n",
    "    x = layers.Dense(layer1_hidden_units,\n",
    "                             activation=\"relu\")(x)\n",
    "    \n",
    "    # Dropout applied to the output of layer 2.\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Final Dense Classifier.\n",
    "    outputs = layers.Dense(196, activation = 'softmax')(x)\n",
    "    \n",
    "    # Instantiate the model.\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    learning_rate = hp.Float(name='learning_rate',\n",
    "                             min_value = 0.0001,\n",
    "                             max_value = 0.002,\n",
    "                             sampling = 'log')\n",
    "    \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "                  optimizer=Adam(learning_rate=learning_rate),\n",
    "                  metrics=  ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "756987d6-52f1-41ef-96fa-43d46e39afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is used to instantiate and run a keras tuner based on a provided model building function and \n",
    "# a path that specifies the location of tf datasets containing precalculated base model (e.g. resnet) outputs.\n",
    "# ===============================================================================================================\n",
    "def tune_driver(base_model_type, input_shape, max_epochs, tuner_iterations, tuner_reduction_factor, base_directory, tb_directory,\n",
    "                verbose=True, patience=5, model_builder_func=tune_output_classifier, output_pooling=None, file_compression = 'ZLIB',\n",
    "                batch_size = 32, expierment_name = ''):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        start_time = time.time()\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(f\"Getting training dataset containing output features for the {base_model_type} model.\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "    \n",
    "    train_ds = get_dataset_from_multiple_tfrecords(base_model_type = base_model_type,\n",
    "                                                   dataset_type = 'train',\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   input_shape = input_shape,\n",
    "                                                   output_pooling = output_pooling,\n",
    "                                                   epoch_num = 1,\n",
    "                                                   compression = file_compression)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(f\"Getting validation dataset containing output features for the {base_model_type} model.\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "        \n",
    "        \n",
    "    val_ds = get_dataset_from_multiple_tfrecords(base_model_type = base_model_type,\n",
    "                                                   dataset_type = 'val',\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   input_shape = input_shape,\n",
    "                                                   output_pooling = output_pooling,\n",
    "                                                   epoch_num = 1,\n",
    "                                                   compression = file_compression)\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(\"Finished loading training and validation sets.\")\n",
    "        print(f\"Total time to load datasets: {time.time() - start_time}\\n\")\n",
    "        print(f\"Insantiating Keras Tuner.\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "\n",
    "    \n",
    "    if False:\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        inspect_tf_dataset(train_ds)\n",
    "        pause_for_input = input(\"Press any key to start the search process, or press 'q' to quit: \")\n",
    "        if pause_for_input == 'q':\n",
    "            return\n",
    "        else:\n",
    "            print(\"Starting the search!\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "        \n",
    "    tuner = kt.Hyperband(hypermodel=model_builder_func,\n",
    "                         max_epochs=max_epochs,\n",
    "                         objective=kt.Objective('accuracy', direction=\"max\"), \n",
    "                         factor=tuner_reduction_factor,\n",
    "                         directory=os.path.join(base_directory, f\"keras_tuning_{expierment_name}{base_model_type}_{output_pooling}/\"),\n",
    "                         hyperband_iterations = tuner_iterations,\n",
    "                         project_name=f\"kt_hyperband_tuning_{base_model_type}\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(f\"Tuner Search Space Summary:\\n\")\n",
    "        print(tuner.search_space_summary())\n",
    "        pause_for_input = input(\"Press any key to start the search process, or press 'q' to quit: \")\n",
    "        if pause_for_input == 'q':\n",
    "            return\n",
    "        else:\n",
    "            print(\"Starting the search!\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "    \n",
    "    callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                               patience=10),\n",
    "                 keras.callbacks.TensorBoard(tb_directory)]\n",
    "    \n",
    "    tuner.search(train_ds,\n",
    "                 epochs=max_epochs,\n",
    "                 validation_data=val_ds,\n",
    "                 callbacks=callbacks)\n",
    "    \n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56508f28-64a3-4021-974a-940e719cf6a4",
   "metadata": {},
   "source": [
    "### Tuning the output classifier for the Resnet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d50335f-aa85-4096-ace6-e09e377a5260",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "time_stamp = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "tb_callback_directory = os.path.join(PROJECT_DIRECTORY, f\"tb_logs_kt_resnet_{time_stamp}\")\n",
    "#os.makedirs(tb_callback_directory, exist_ok=True)\n",
    "\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir tb_callback_directory\n",
    "\n",
    "resnet_tuner = tune_driver(base_model_type = 'resnet101',\n",
    "                           input_shape = (520, 520, 3),\n",
    "                           max_epochs = 10,\n",
    "                           tuner_iterations = 1,\n",
    "                           tuner_reduction_factor = 3,\n",
    "                           base_directory = PROJECT_DIRECTORY,\n",
    "                           tb_directory=tb_callback_directory)\n",
    "                           ''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eedba367-d265-4b66-b5e1-5c3673674cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir tb_callback_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "281df16a-ba98-4cfb-afff-9ea41f4cb434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 12m 03s]\n",
      "accuracy: 0.008460075594484806\n",
      "\n",
      "Best accuracy So Far: 0.4495247006416321\n",
      "Total elapsed time: 02h 25m 03s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "time_stamp = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "tb_callback_directory = os.path.join(PROJECT_DIRECTORY, f\"tb_logs_kt_resnet_{time_stamp}\")\n",
    "os.makedirs(tb_callback_directory, exist_ok=True)\n",
    "\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir tb_callback_directory\n",
    "\n",
    "resnet_tuner = tune_driver(base_model_type = 'resnet101',\n",
    "                           input_shape = (520, 520, 3),\n",
    "                           max_epochs = 10,\n",
    "                           tuner_iterations = 1,\n",
    "                           tuner_reduction_factor = 3,\n",
    "                           base_directory = PROJECT_DIRECTORY,\n",
    "                           tb_directory=tb_callback_directory,\n",
    "                           expierment_name = 'CONFIG2',\n",
    "                           model_builder_func=tune_output_classifier_experiment_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1928ec3d-bf00-45b1-bdb7-871b0b882e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\keras_tuning_CONFIG2resnet101_None/kt_hyperband_tuning_resnet101\n",
      "Showing 1 best trials\n",
      "Objective(name='accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "pooling_strategy: avg\n",
      "layer1_hidden_units: 480\n",
      "learning_rate: 0.0003419781419918064\n",
      "tuner/epochs: 10\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.4495247006416321\n"
     ]
    }
   ],
   "source": [
    "resnet_tuner.results_summary(num_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64071c07-e880-4a4e-b04b-655f61173ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_performance(tuner, base_model_type, input_shape=(520, 520, 3), verbose=True, output_pooling=None, epoch_num=1,\n",
    "                              file_compression = 'ZLIB', batch_size=32):\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(f\"Getting test data for the {base_model_type} model.\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "        \n",
    "    train_ds = get_dataset_from_multiple_tfrecords(base_model_type = base_model_type,\n",
    "                                                   dataset_type = 'test',\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   input_shape = input_shape,\n",
    "                                                   output_pooling = output_pooling,\n",
    "                                                   epoch_num = epoch_num,\n",
    "                                                   compression = file_compression)\n",
    "    \n",
    "    \n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(f\"Best Hyperparams:\\n {tuner.get_best_hyperparameters(num_trials=1)[0]}\\n\\n\")\n",
    "        print(\"Performing evaluation...\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "    \n",
    "    evaluation_results = best_model.evaluate(train_ds)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(f\"Evaluation Results:\\n {evaluation_results}\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "    \n",
    "    return best_model, evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3eebca6-5c60-4cae-964d-9b472250a823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================================================\n",
      "Getting test data for the resnet101 model.\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "=======================================================================================\n",
      "Best Hyperparams:\n",
      " <keras_tuner.engine.hyperparameters.HyperParameters object at 0x0000018F5D931F40>\n",
      "\n",
      "\n",
      "Performing evaluation...\n",
      "=======================================================================================\n",
      "\n",
      "76/76 [==============================] - 12s 143ms/step - loss: 2.5485 - accuracy: 0.3957\n",
      "\n",
      "=======================================================================================\n",
      "Evaluation Results:\n",
      " [2.548501491546631, 0.3957219123840332]\n",
      "=======================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_resnet_classifier, resnet_test_eval = get_test_data_performance(tuner = resnet_tuner,\n",
    "                                                                     base_model_type = 'resnet101',\n",
    "                                                                     output_pooling=None,\n",
    "                                                                     epoch_num = 1,\n",
    "                                                                     input_shape=(520, 520, 3),\n",
    "                                                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6b647-0f1a-4cc5-9fb3-91611cf6dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is not currently utilized in this notebook, but would facilitate loading in precalculated \n",
    "# base model outputs that were stored in a numpy array using the process shown in the\n",
    "# 03_save_pretrained_model_outputs_numpy notebook.\n",
    "#\n",
    "# The method of storing precalculated outputs in a numpy array is generally less desireable than storing\n",
    "# the outputs as tfrecord files because tfrecords can be easily read in as a tensorflow dataset, and are \n",
    "# therefore able to take advantage of the tf dataset feature where data is only loaded into memory batch-wise.\n",
    "#\n",
    "# Reading an entire dataset into memory all at once in the form of a numpy array is not feasible for anything\n",
    "# other than very small datasets.\n",
    "# ===============================================================================================================\n",
    "def load_base_model_outputs_from_numpy(base_model_type, input_shape, output_pooling, epoch_num, dataset_type = 'all'):\n",
    "    \n",
    "    global PROJECT_DIRECTORY\n",
    "    \n",
    "    valid_dataset_types = ['all', 'train', 'val', 'test']\n",
    "    \n",
    "    if dataset_type not in valid_dataset_types:\n",
    "        print(\"/n===========================================================\")\n",
    "        print(\"Invalid input for parameter dataset_type\")\n",
    "        print(f\"Valid inputs are: {valid_dataset_types}\")\n",
    "        print(\"===========================================================\\n\")\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    base_dir_name = f\"pretrained_model_output_features/{base_model_type}_pool{str(output_pooling)}_inShape_{str(input_shape)}\"\n",
    "    base_outputs_directory = os.path.join(PROJECT_DIRECTORY, base_dir_name)\n",
    "    \n",
    "    all_dirs = os.listdir(base_outputs_directory)\n",
    "    \n",
    "    if dataset_type != 'all':\n",
    "    \n",
    "        correct_dir = [directory for directory in all_dirs if (dataset_type in directory) and (f'epoch_{epoch_num}' in directory)]\n",
    "        \n",
    "        if len(correct_dir) != 1:\n",
    "            print(\"/n============================ Error ===============================\")\n",
    "            print(\"Invalid directory filtering!\")\n",
    "            print(f\"Filtering returned: {correct_dir}\")\n",
    "            return -1\n",
    "            print(\"=========================================================================\\n\")\n",
    "            \n",
    "        correct_dir = correct_dir[0]\n",
    "        \n",
    "        filepath = os.path.join(base_outputs_directory, correct_dir + f\"/{dataset_type}.npz\")\n",
    "        \n",
    "        arrays = np.load(filepath)\n",
    "        features = arrays[f\"{dataset_type}_features\"]\n",
    "        labels = arrays[f\"{dataset_type}_labels\"]\n",
    "        \n",
    "        return features, labels\n",
    "    \n",
    "    elif dataset_type == 'all':\n",
    "        \n",
    "        correct_dirs = [directory for directory in dirs if (f'epoch_{epoch_num}' in directory)]\n",
    "        train_dir = [directory for directory in correct_dirs if ('train' in directory)]\n",
    "        val_dir = [directory for directory in correct_dirs if ('val' in directory)]\n",
    "        test_dir = [directory for directory in correct_dirs if ('test' in directory)]\n",
    "    \n",
    "    if len(train_dir) != 1 or len(val_dir) != 1 or len(test_dir) != 1:\n",
    "        print(\"/n============================ Error ===============================\")\n",
    "        print(\"Invalid directory filtering!\")\n",
    "        print(f\"Train Directory: {train_dir}\")\n",
    "        print(f\"Val Directory: {val_dir}\")\n",
    "        print(f\"Test Directory: {test_dir}\")\n",
    "        return -1\n",
    "        print(\"=========================================================================\\n\")\n",
    "            \n",
    "    train_filepath = os.path.join(base_outputs_directory, train_dir)\n",
    "    val_filepath = os.path.join(base_outputs_directory, val_dir)\n",
    "    test_filepath = os.path.join(base_outputs_directory, test_dir)\n",
    "    \n",
    "    filepaths = {'train' : train_filepath, 'val' : val_filepath, 'test' : test_filepath}\n",
    "    \n",
    "    output_dict = {}\n",
    "    \n",
    "    for dataset_type, filepath in filepeths.items():\n",
    "        \n",
    "        arrays = np.load(filepath)\n",
    "        feats = arrays[f\"{dataset_type}_features\"]\n",
    "        labels = arrays[f\"{dataset_type}_labels\"]\n",
    "        temp_dict = {'features' : feats, 'labels' : labels}\n",
    "        output_dict[dataset_type] = temp_dict\n",
    "    \n",
    "    return output_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
