{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e102847f-9f78-409a-9c0a-f32f8e4ab908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e700a1eb-9be6-43e6-8ff2-e8df0e73149c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>min_x</th>\n",
       "      <th>min_y</th>\n",
       "      <th>max_x</th>\n",
       "      <th>max_y</th>\n",
       "      <th>target</th>\n",
       "      <th>unknown</th>\n",
       "      <th>car_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>112</td>\n",
       "      <td>7</td>\n",
       "      <td>853</td>\n",
       "      <td>717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AM General Hummer SUV 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>48</td>\n",
       "      <td>24</td>\n",
       "      <td>441</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AM General Hummer SUV 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>277</td>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AM General Hummer SUV 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "      <td>197</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AM General Hummer SUV 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>83</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>AM General Hummer SUV 2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  min_x  min_y  max_x  max_y  target  unknown  \\\n",
       "0  000001.jpg    112      7    853    717       1        0   \n",
       "1  000002.jpg     48     24    441    202       1        0   \n",
       "2  000003.jpg      7      4    277    180       1        0   \n",
       "3  000004.jpg     33     50    197    150       1        0   \n",
       "4  000005.jpg      5      8     83     58       1        0   \n",
       "\n",
       "                    car_names  \n",
       "0  AM General Hummer SUV 2000  \n",
       "1  AM General Hummer SUV 2000  \n",
       "2  AM General Hummer SUV 2000  \n",
       "3  AM General Hummer SUV 2000  \n",
       "4  AM General Hummer SUV 2000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_df = pd.read_csv(\"./data/labeled_car_data.csv\")\n",
    "\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c1e95a-427a-4d45-936a-0d967c6cf994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 percent: 10520.25\n",
      "20 percent: 3237.0\n",
      "15 percent: 2427.75\n"
     ]
    }
   ],
   "source": [
    "print(f\"65 percent: {len(car_df.index) * 0.65}\")\n",
    "print(f\"20 percent: {len(car_df.index) * 0.20}\")\n",
    "print(f\"15 percent: {len(car_df.index) * 0.15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87de5369-7e49-4275-ad50-24234672ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes = list(np.unique(car_df['target'].to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c267773b-798a-42be-8bf1-865d4c05f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================================================================\n",
    "# Later, we will use the keras image_dataset_from_directory function to efficiently read in the image files into\n",
    "# tensorflow datasets that will be used for model training. This function has an option to automatically infer the class\n",
    "# labels based on a directory structure. When this option is used, it is very important that the folders for each class be\n",
    "# labeled such that their alpha numeric ordering is the same as the final class labels you want them to have.\n",
    "#\n",
    "# This means if we want our classes to remain labeled in the same order as the .csv file we created in the previous notebook, \n",
    "# we need to make sure the folder for class 1 is the first folder found alpha-numerically, and the folder for class 196 is the\n",
    "# last alpha-numerically.\n",
    "#\n",
    "# This function is used to create a dictionary mapping each target class to the appropriate \n",
    "# folder names class_001 - class_196, to fullfill the above mentioned requirements.\n",
    "# ============================================================================================================================\n",
    "def make_class_num_to_folder_ext_map(df):\n",
    "    \n",
    "    class_to_folder_ext = {}\n",
    "    \n",
    "    unique_classes = list(np.unique(car_df['target'].to_numpy()))\n",
    "    \n",
    "    for class_num in unique_classes:\n",
    "\n",
    "        if len(str(class_num)) == 1:\n",
    "\n",
    "            ext = \"00\" + str(class_num)\n",
    "\n",
    "        elif len(str(class_num)) == 2:\n",
    "\n",
    "            ext = \"0\" + str(class_num)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            ext = str(class_num)\n",
    "            \n",
    "        class_to_folder_ext[class_num] = ext\n",
    "    \n",
    "    return class_to_folder_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a313c6b2-8b4e-4173-ac68-48cf5df5ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================================================================\n",
    "# This function is used to create training, validation and test directories. Each of which containing 196 subfolders that\n",
    "# are labeled class_001 to class_196. \n",
    "# ============================================================================================================================\n",
    "def make_class_directories(df):\n",
    "    \n",
    "    base_train = './data/organized/train/'\n",
    "    base_val = './data/organized/val/'\n",
    "    base_test ='./data/organized/test/'\n",
    "    \n",
    "    base_paths = [base_train, base_val, base_test]\n",
    "    unique_classes = list(np.unique(car_df['target'].to_numpy()))\n",
    "    \n",
    "    folder_ext_map = make_class_num_to_folder_ext_map(df)\n",
    "    \n",
    "    for path in base_paths:\n",
    "        for class_name in unique_classes:\n",
    "            os.makedirs(path + f\"class_{folder_ext_map[class_name]}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e665d3-837d-4e2b-ba37-7b29e0ca62f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================================================================\n",
    "# This function is used to three dataframes: train_df, val_df and test_df which will contain the Stanford Dataset car image\n",
    "# filenames that have been split according to the desired training, validation and test proportions.\n",
    "#\n",
    "# Default proportions are 65% train, 20% validation, 15% test.\n",
    "# ============================================================================================================================\n",
    "def create_train_val_test_dfs(df, target_column = 'target', train_pct=0.65, val_pct=0.20, stratify_target=True):\n",
    "    \n",
    "    if stratify_target:\n",
    "        \n",
    "        # Split into a training dataframe and a validation + test dataframe\n",
    "        train_df, val_test_df = train_test_split(df, train_size = train_pct, stratify=df[target_column], random_state=42)\n",
    "\n",
    "        # Percentage of data that remains after allocating the train data\n",
    "        remaining_pct = 1 - train_pct\n",
    "\n",
    "        # Percentage to allocation to validation in the next train_test_splt\n",
    "        val_pct = round(val_pct / remaining_pct, 3)\n",
    "\n",
    "        # Split the validation + test dataframe into separate validation and test dataframes.\n",
    "        val_df, test_df = train_test_split(val_test_df, train_size = val_pct, stratify=val_test_df[target_column], random_state=2)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Split into a training dataframe and a validation + test dataframe\n",
    "        train_df, val_test_df = train_test_split(df, train_size = train_pct, random_state=42)\n",
    "        \n",
    "        # Percentage of data that remains after allocating the train data\n",
    "        remaining_pct = 1 - train_pct\n",
    "        \n",
    "        # Percentage to allocation to validation in the next train_test_splt\n",
    "        val_pct = round(val_pct / remaining_pct, 3)\n",
    "        \n",
    "        # Split the validation + test dataframe into separate validation and test dataframes.\n",
    "        val_df, test_df = train_test_split(val_test_df, train_size = val_pct, random_state=2)\n",
    "        \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee6ab28d-2b49-4df9-9adc-df44aefce43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================================================================\n",
    "# This function returns a dictionary that maps each target class to a list of filenames that contain examples of cars \n",
    "# from that class.\n",
    "# ============================================================================================================================\n",
    "def build_class_filename_dict(df, target_col = 'target'):\n",
    "    \n",
    "    # List of each unique target class in the dataset (196 classes of cars).\n",
    "    unique_classes = list(np.unique(df['target'].to_numpy()))\n",
    "    \n",
    "    filename_dict = {}\n",
    "    \n",
    "    for target_class in unique_classes:\n",
    "        \n",
    "        filename_dict[target_class] = list(df.loc[df['target'] == target_class, 'filename'].to_numpy())\n",
    "        \n",
    "    return filename_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf215f6f-4c3b-402b-941c-c0b975045dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================================================================\n",
    "# This function will take as input the train_df, test_df or val_df dataframe, and will copy the associated image files\n",
    "# to the correct folders.\n",
    "# ============================================================================================================================\n",
    "def copy_files_to_organized_folders(df, dataset_type, target_col, base_source_folder, base_destination_folder):\n",
    "    \n",
    "    valid_dataset_types = ['train', 'test', 'val']\n",
    "    \n",
    "    if dataset_type not in valid_dataset_types:\n",
    "        print(\"\\n================================ Error =======================================\")\n",
    "        print(f\"{dataset_type} is an invalid dataset_type\")\n",
    "        print(\"dataset_type parameter must be one of 'train', 'validation', or 'test'\")\n",
    "        print(\"=======================================================================\\n\")\n",
    "        return -1\n",
    "    \n",
    "    # Create the base path for the train, val or test set.\n",
    "    base_destination_path =f'{base_destination_folder}{dataset_type}/'\n",
    "    \n",
    "    # Dictionary mapping each target class to list of filenames in this dataset that contain examples of that class.\n",
    "    filename_dict = build_class_filename_dict(df, target_col = target_col)\n",
    "    \n",
    "    # Dictionary mapping each target class\n",
    "    class_folder_ext_map = make_class_num_to_folder_ext_map(df)\n",
    "    \n",
    "    for class_num, filenames in filename_dict.items(): \n",
    "        for filename in filenames:\n",
    "            shutil.copy(base_source_folder + filename, base_destination_path + f\"class_{class_folder_ext_map[class_num]}/\")\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d8d428-6dd7-4218-b122-a024132b4d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================================================================\n",
    "# All other functions in this notebook are used to support this function. \n",
    "# \n",
    "# This function executes the following process:\n",
    "#\n",
    "# 1. Make directories for training, validation and test data. Each directory containing 196 sub folders labeled\n",
    "# class_001 to class_196 to contain examples of images from each of the 196 target classes\n",
    "#\n",
    "# 2. Split the data into training, validation and test sets with the desired proportions.\n",
    "#\n",
    "# 3. Copy images files to the appropriate folders.\n",
    "#\n",
    "# ============================================================================================================================\n",
    "def create_file_structure(df, verbose=False, target_col='target', base_image_source_folder=\"./data/car_ims/\",\n",
    "                          train_pct=0.65, val_pct=0.20, stratify_target=True, base_destination_folder = \"./data/organized/\"): \n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n==============================================================\")\n",
    "        print(\"Creating train, val and test data directories\")\n",
    "        print(\"Each folder has a sub folder for each of the target classes.\")\n",
    "        print(\"==============================================================\\n\")\n",
    "        \n",
    "    make_class_directories(df)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n==============================================================\")\n",
    "        print(\"Splitting the data into training, validation and test sets...\")\n",
    "        print(f\"Training: {round(train_pct * 100, 2)}%\")\n",
    "        print(f\"Validation: {round(val_pct * 100, 2)}%\")\n",
    "        print(f\"Test: {round((1 - (train_pct + val_pct))* 100, 2)}%\")\n",
    "        print(\"==============================================================\\n\")\n",
    "    \n",
    "    train_df, val_df, test_df = create_train_val_test_dfs(df, target_column = target_col,\n",
    "                                                          train_pct=train_pct, val_pct=val_pct,\n",
    "                                                          stratify_target=stratify_target) \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n==============================================================\")\n",
    "        print(\"Copying the training files to the appropriate folders...\")\n",
    "        print(\"==============================================================\\n\")\n",
    "        \n",
    "         \n",
    "    copy_files_to_organized_folders(train_df,\n",
    "                                    dataset_type='train',\n",
    "                                    target_col=target_col,\n",
    "                                    base_source_folder = base_image_source_folder,\n",
    "                                    base_destination_folder = base_destination_folder)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n==============================================================\")\n",
    "        print(\"Copying the validation files to the appropriate folders...\")\n",
    "        print(\"==============================================================\\n\")\n",
    "         \n",
    "    copy_files_to_organized_folders(val_df,\n",
    "                                    dataset_type='val',\n",
    "                                    target_col=target_col,\n",
    "                                    base_source_folder = base_image_source_folder,\n",
    "                                    base_destination_folder = base_destination_folder)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n==============================================================\")\n",
    "        print(\"Copying the test files to the appropriate folders...\")\n",
    "        print(\"==============================================================\\n\")\n",
    "         \n",
    "    copy_files_to_organized_folders(test_df,\n",
    "                                    dataset_type='test',\n",
    "                                    target_col=target_col,\n",
    "                                    base_source_folder = base_image_source_folder,\n",
    "                                    base_destination_folder = base_destination_folder)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n==============================================================\")\n",
    "        print(\"Finished file organization!\")\n",
    "        print(f\"Total Elapsed time: {time.time() - start_time}\")\n",
    "        print(\"==============================================================\\n\")\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb9d14ee-e2af-4685-a969-4cfc3e62086f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================\n",
      "Creating train, val and test data directories\n",
      "Each folder has a sub folder for each of the target classes.\n",
      "==============================================================\n",
      "\n",
      "\n",
      "==============================================================\n",
      "Splitting the data into training, validation and test sets...\n",
      "Training: 65.0%\n",
      "Validation: 20.0%\n",
      "Test: 15.0%\n",
      "==============================================================\n",
      "\n",
      "\n",
      "==============================================================\n",
      "Copying the training files to the appropriate folders...\n",
      "==============================================================\n",
      "\n",
      "\n",
      "==============================================================\n",
      "Copying the validation files to the appropriate folders...\n",
      "==============================================================\n",
      "\n",
      "\n",
      "==============================================================\n",
      "Copying the test files to the appropriate folders...\n",
      "==============================================================\n",
      "\n",
      "\n",
      "==============================================================\n",
      "Finished file organization!\n",
      "Total Elapsed time: 16.46264338493347\n",
      "==============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = create_file_structure(car_df, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
