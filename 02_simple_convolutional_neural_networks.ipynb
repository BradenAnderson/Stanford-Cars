{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3VlDOvXmkUoN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VlDOvXmkUoN",
    "outputId": "adc30730-b12a-4eea-aca7-5c5c83134499"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f28fc-2a00-488e-aeb5-5a90e65ce3d5",
   "metadata": {
    "id": "918f28fc-2a00-488e-aeb5-5a90e65ce3d5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.python.client import device_lib \n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Global variable specifying the project directory. This variable helps make the code easier\n",
    "# to run in multiple locations. (For example on local pc vs google colab enviornments for \n",
    "# various team members). \n",
    "global PROJECT_DIRECTORY\n",
    "PROJECT_DIRECTORY = \"/content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/\"\n",
    "\n",
    "# Folder paths for my own computer\n",
    "#train_directory = \"./data/organized/train/\"\n",
    "#val_directory = \"./data/organized/val/\"\n",
    "#test_directory = \"./data/organized/test/\"\n",
    "\n",
    "# Folder paths when using Google Colab and after copying the data to the folder where the colab notebook runs.\n",
    "train_dir = \"./organized/train\"\n",
    "val_dir = \"./organized/val\"\n",
    "test_dir = \"./organized/test\"\n",
    "\n",
    "# Allow pandas to display more than 50 rows when calling .head()\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb3a286-16e5-494e-b4e7-4cd07fe7cff0",
   "metadata": {},
   "source": [
    "**A note on training models with large datasets on Google Colab**\n",
    "\n",
    "My project has been set up such that image files are read in one batch at a time as they are needed for training the model. This is used so we can avoid reading the entire dataset into RAM at once, which depending on the system may be simply inefficient or even impossible. This process presents a separate set of challenges when trying to implement it on Google Colaboratory. Specifically, Google Colab is very inefficient when reading large files from Google Drive. This means that model training times are significantly increased, to the point where the code is spending most of its time reading files and a relatively small amount of time actually utilizing the valuable GPUs. \n",
    "\n",
    "The solution to the issue described above is to copy the dataset from drive to the folder where colab is actually running prior to model training. This significantly increases the speed at which image files can be read in, and therefore also significantly increase model training times. The code to perform this copy and paste is shown in the following two cells, and is also described in this article: \n",
    "\n",
    "https://medium.datadriveninvestor.com/speed-up-your-image-training-on-google-colab-dc95ea1491cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115a341-5a09-4a40-9178-d1934793d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to where I stored the Stanford Cars dataset images on google drive.\n",
    "data_path = \"/content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/data/organized/\"\n",
    "\n",
    "# This command takes the folder containing the stanford cars dataset images and creates a new zipped version of the folder.\n",
    "!(cd '{data_path}' && zip -r -q organized_data.zip organized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fwnroG-wXjST",
   "metadata": {
    "id": "fwnroG-wXjST"
   },
   "outputs": [],
   "source": [
    "# Path to to the zipped stanford cars dataset images.\n",
    "zip_path = \"/content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/data/organized_data.zip\"\n",
    "\n",
    "# Copy the zip folder containing the images to the directory where google colab is running.\n",
    "!cp '{zip_path}' .\n",
    "\n",
    "# Unzip the images in the folder that google colab uses.\n",
    "!unzip -q organized_data.zip\n",
    "\n",
    "# Remove the zipped version of the folder.\n",
    "!rm organized_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f9e1e-8fde-4db7-899c-660f014096d8",
   "metadata": {
    "id": "f82f9e1e-8fde-4db7-899c-660f014096d8"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function creates training, validation and test datasets using the file structure created in the\n",
    "# 01_create_train_val_test_directories notebook. \n",
    "# ===============================================================================================================\n",
    "def create_tensorflow_datasets(image_size, train_directory, val_directory, test_directory, batch_size=32):\n",
    "    \n",
    "    train_dataset = image_dataset_from_directory(directory = train_directory,\n",
    "                                                 labels='inferred',\n",
    "                                                 label_mode = 'int',\n",
    "                                                 image_size=image_size,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 smart_resize=True)\n",
    "\n",
    "    val_dataset = image_dataset_from_directory(directory = val_directory,\n",
    "                                               labels='inferred',\n",
    "                                               label_mode = 'int',\n",
    "                                               image_size=image_size,\n",
    "                                               batch_size=batch_size,\n",
    "                                               smart_resize=True)\n",
    "\n",
    "    test_dataset = image_dataset_from_directory(directory = test_directory,\n",
    "                                                labels = \"inferred\",\n",
    "                                                label_mode = \"int\",\n",
    "                                                image_size=image_size,\n",
    "                                                batch_size=batch_size,\n",
    "                                                smart_resize=True)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad798a-4b7e-420b-96a3-1508d1a23f1c",
   "metadata": {
    "id": "6fad798a-4b7e-420b-96a3-1508d1a23f1c"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# Helper function to inspect the contents of a tensorflow dataset.\n",
    "# ===============================================================================================================\n",
    "def inspect_tf_dataset(tf_dataset):\n",
    "    for batch, labels in tf_dataset:\n",
    "        print(f\"Batch Shape: {batch.shape}\")\n",
    "        print(f\"Labels Shape: {labels.shape}\\n\")\n",
    "        print(f\"len(Batch):\\n {len(batch)}\\n\")\n",
    "        print(f\"len(Labels):\\n {len(labels)}\\n\")\n",
    "        print(f\"type Batch:\\n {batch.dtype}\\n\")\n",
    "        print(f\"type Labels:\\n {labels.dtype}\\n\")\n",
    "        \n",
    "        \n",
    "        for batch_num in range(1):\n",
    "            print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "            print(f\"Batch Item Number: {batch_num}\")\n",
    "            print(f\"Batch[{batch_num}].shape:\\n {batch[batch_num].shape}\\n\")\n",
    "            print(f\"Labels[{batch_num}].shape:\\n {labels[batch_num].shape}\\n\")\n",
    "            print(f\"type Batch[{batch_num}].shape:\\n {batch[batch_num].dtype}\\n\")\n",
    "            print(f\"type Labels[{batch_num}].shape:\\n {labels[batch_num].dtype}\\n\")\n",
    "            print(f\"Batch[{batch_num}]:\\n {batch[batch_num]}\\n\")\n",
    "            print(f\"Labels[{batch_num}]:\\n {labels[batch_num]}\\n\")\n",
    "            print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69b4d86-88f2-43b6-bd05-8246f638a42c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a69b4d86-88f2-43b6-bd05-8246f638a42c",
    "outputId": "11342898-1e3d-45e4-a72c-9b3a392566d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10520 files belonging to 196 classes.\n",
      "Found 3234 files belonging to 196 classes.\n",
      "Found 2431 files belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_tensorflow_datasets(image_size=(520, 520),\n",
    "                                                                      train_directory=train_dir,\n",
    "                                                                      val_directory=val_dir,\n",
    "                                                                      test_directory=test_dir,\n",
    "                                                                      batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D3e9npMFP2CC",
   "metadata": {
    "id": "D3e9npMFP2CC"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function implements a custom learning rate schedule.\n",
    "#\n",
    "# The learning rate is decreased by a factor of 1.3 every 10 epochs, until a minimum allowed learning rate of\n",
    "# 1e-6 is reached.\n",
    "# ===============================================================================================================\n",
    "def learning_rate_scheduler(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        \n",
    "        updated_lr = max((lr / (1 + 0.30)), 0.000001)\n",
    "        \n",
    "        if updated_lr != lr: \n",
    "            print(\"/n====================================================\")\n",
    "            print(\"Updating the learning rate...\")\n",
    "            print(f\"Previous LR: {lr}  Updated LR: {updated_lr}\")\n",
    "            print(\"====================================================\\n\")    \n",
    "        return updated_lr \n",
    "    else:\n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s1sERsntl8jn",
   "metadata": {
    "id": "s1sERsntl8jn"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function creates a unique filename to save trained models. \n",
    "# ===============================================================================================================\n",
    "def get_model_save_path(optimizer, lr, epochs, batch_size, model_name):\n",
    "    \n",
    "    global PROJECT_DIRECTORY\n",
    "\n",
    "    # String\n",
    "    optimizer_string = optimizer + str(lr).split('.')[1]\n",
    "    time_stamp = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    \n",
    "    model_save_path = os.path.join(PROJECT_DIRECTORY, f\"trained_models/convnet/{time_stamp}_{model_name}_E{epochs}_O{optimizer_string}_B{batch_size}.keras\")\n",
    "    \n",
    "    return model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z-itr2MSmB7X",
   "metadata": {
    "id": "Z-itr2MSmB7X"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# Function to easily switch which optimizer is used for training.\n",
    "# ===============================================================================================================\n",
    "def get_optimizer(optimizer_name, lr):\n",
    "    \n",
    "    if optimizer_name == 'rmsprop':\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.RMSProp(learning_rate = lr)\n",
    "    \n",
    "    elif optimizer_name == 'adam':\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "        \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df6004-f076-4101-af70-9615fc8b8828",
   "metadata": {
    "id": "62df6004-f076-4101-af70-9615fc8b8828"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function instantiates and compiles a convolutional neural network.\n",
    "# \n",
    "# Keras preprocessing layers are used to implement random data augmentations throughout training.\n",
    "# ===============================================================================================================\n",
    "def build_convnet_classifier(input_shape, optimizer, learning_rate, metrics):\n",
    "    \n",
    "    # Get the specified optimizer.\n",
    "    optimizer = get_optimizer(optimizer, learning_rate)\n",
    "    \n",
    "    # Create a layer that randomly augments the data prior to being input to the model.\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "            layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Perform data augmentation\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # Recale the pixel values from the 1-255 range to a 0-1 range\n",
    "    x = layers.experimental.preprocessing.Rescaling(1./255)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Softmax Activation for multiclass classification\n",
    "    outputs = layers.Dense(196, activation=\"softmax\")(x)\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss = SparseCategoricalCrossentropy(),\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed91fb7-d968-4e4b-a2e5-d4196279ff8d",
   "metadata": {
    "id": "8ed91fb7-d968-4e4b-a2e5-d4196279ff8d"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function takes as input a tensorflow dataset containing test data, and either a trained model\n",
    "# or the path to where a trained model is located. \n",
    "#\n",
    "# The function then evaluates the model using the test data and returns the associated test metrics.\n",
    "# ===============================================================================================================\n",
    "def test_convnet_classifier(test_ds, model=None, model_path=None):\n",
    "    \n",
    "    if model is not None:\n",
    "        \n",
    "        test_loss, test_acc = model.evaluate(test_ds)\n",
    "        print(\"\\n========================== Model Test Results ===============================\")\n",
    "        print(f\"Test Accuracy: {test_acc}\")\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "        print(\"=============================================================================\\n\")\n",
    "        \n",
    "    elif model_path is not None:\n",
    "        \n",
    "        model = keras.models.load_model(model_path)\n",
    "        test_loss, test_acc = model.evaluate(test_dataset)\n",
    "        print(\"\\n========================== Model Test Results ===============================\")\n",
    "        print(f\"Test Accuracy: {test_acc}\")\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "        print(\"=============================================================================\\n\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n========================== Error ===============================\")\n",
    "        print(\"Must pass either a trained model or a path to a trained model file.\")\n",
    "        print(\"Cannot have both model and model_path = None\")\n",
    "        print(\"=============================================================================\\n\")\n",
    "        return -1\n",
    "    \n",
    "    return test_loss, test_acc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c8f5e-0f5d-486c-88af-230c2d6503af",
   "metadata": {
    "id": "3e9c8f5e-0f5d-486c-88af-230c2d6503af"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function used to establish callbacks and train the convolutional neural network.\n",
    "#\n",
    "# Callbacks are utilized for model checkpoints (save the current best model as determined by val loss), EarlyStopping\n",
    "# stopping to discontinue training if val_loss has not decreased for 15 iterations, and a learning rate schedule.\n",
    "# ===============================================================================================================\n",
    "def train_convnet_classifier(model, train_ds, val_ds, epochs=20, model_save_path=None):\n",
    "    \n",
    "    # Callbacks for saving the best model, stopping training when improvements are no longer being made\n",
    "    # and to decrease the learning rate at specified intervals. \n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(filepath=model_save_path,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor=\"val_loss\",\n",
    "                                                 verbose=1),\n",
    "                 keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                               patience=15,\n",
    "                                               verbose=1),\n",
    "                 keras.callbacks.LearningRateScheduler(learning_rate_scheduler)]\n",
    "    \n",
    "    history = model.fit(train_ds,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_ds,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    # Save the model history to a .csv\n",
    "    try:\n",
    "        \n",
    "        # Path to save the model history\n",
    "        history_save_path = model_save_path.split(\".\")[0] + \"_HISTORY.csv\"\n",
    "        \n",
    "        # Use pandas to save the models history attribute to .csv\n",
    "        df = pd.DataFrame(history.history)\n",
    "        df.to_csv(history_save_path, index=False)\n",
    "        \n",
    "        # The model checkpoint only saves the \"best model\", which is not necessarily the final model. This section\n",
    "        # also saves the final model as it existed after the last epoch of training. This is helpful if it is ever\n",
    "        # desired to continue training at that point.\n",
    "        final_save_path = model_save_path.split(\".\")[0] + \"_FINAL_SAVE.keras\"\n",
    "        save_model(model=model, filepath=final_save_path, overwrite=True, include_optimizer=True, save_format='tf')\n",
    "        \n",
    "    except:\n",
    "        print(\"Couldn't save history or final model!\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aebd2a-2c88-43d8-811d-9657af54ae3d",
   "metadata": {
    "id": "d8aebd2a-2c88-43d8-811d-9657af54ae3d"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function uses all the other functions defined above to drive the entire model training process.\n",
    "# The full process implemented by this function is as follows:\n",
    "#\n",
    "# 1. Instantiate and compile the model using the build_convnet_classifier function.\n",
    "# 2. Generate a uniue filepath to save the best model found during training.\n",
    "# 3. Train the model and save the history attribute after training.\n",
    "# 4. Evaluate the best model on the test data.\n",
    "# ===============================================================================================================\n",
    "def build_and_train_convnet(train_ds, val_ds, test_ds = None, input_shape=(520, 520, 3), optimizer='adam', metrics=['accuracy'],\n",
    "                            epochs=20, batch_size=32, lr = 0.001, model_name = 'conv1'):\n",
    "    \n",
    "    \n",
    "    # Build and compile the model\n",
    "    model = build_convnet_classifier(input_shape=input_shape, optimizer=optimizer, learning_rate = lr, metrics=metrics)\n",
    "    \n",
    "    # Display the models summary.\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Get the filepath where the model should be saved.\n",
    "    model_save_path =  get_model_save_path(optimizer=optimizer, lr=lr, epochs=epochs, batch_size=batch_size, model_name=model_name)\n",
    "    \n",
    "    # Display the save filepath\n",
    "    print(f\"Model Checkpoint Save Path: {model_save_path}\")\n",
    "    \n",
    "    # Fit the neural network. \n",
    "    training_history = train_convnet_classifier(model, train_ds, val_ds, epochs=epochs, model_save_path=model_save_path)\n",
    "    \n",
    "    # After training, evaluate the best model on the test data.\n",
    "    if test_ds is not None:\n",
    "        test_loss, test_acc, best_model = test_convnet_classifier(test_ds, model=None, model_path=model_save_path)\n",
    "    \n",
    "    return training_history, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1f454-1cf4-4915-aa05-d9497aecf92b",
   "metadata": {
    "id": "b3d1f454-1cf4-4915-aa05-d9497aecf92b"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "history, model = build_and_train_convnet(train_ds=train_dataset,\n",
    "                                         val_ds = val_dataset,\n",
    "                                         test_ds = test_dataset,\n",
    "                                         input_shape = (520, 520, 3),\n",
    "                                         optimizer = 'adam',\n",
    "                                         metrics=['accuracy'],\n",
    "                                         epochs=100,\n",
    "                                         batch_size=32,\n",
    "                                         lr = 0.0005)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab940dd-5859-4f4c-827a-6e311ee68faf",
   "metadata": {
    "id": "4ab940dd-5859-4f4c-827a-6e311ee68faf"
   },
   "source": [
    "# Second Architecture Type\n",
    "\n",
    "Define a second convnet architecture with one slight difference. Adding another dense layer after the convolutional layers, and prior to the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f3783-4afb-4602-896b-40ed83b2a9fb",
   "metadata": {
    "id": "782f3783-4afb-4602-896b-40ed83b2a9fb"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is identical to the build_convnet_classifier function shown above, with the addition of \n",
    "# a second dense layer in the models output classifier.\n",
    "# ===============================================================================================================\n",
    "def build_convnet_classifier_arch2(input_shape, optimizer, learning_rate, metrics):\n",
    "\n",
    "    optimizer = get_optimizer(optimizer, learning_rate)\n",
    "    \n",
    "    # Create a layer that is a set of data augmentations.\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "            layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Perform data augmentation\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # Recale the pixel values from the 1-255 range to a 0-1 range\n",
    "    x = layers.experimental.preprocessing.Rescaling(1./255)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    # Begining of the Dense classifier\n",
    "    x = layers.Dense(256, activation = 'relu')(x)\n",
    "    \n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Softmax Activation for binary classification\n",
    "    outputs = layers.Dense(196, activation=\"softmax\")(x)\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss = SparseCategoricalCrossentropy(),\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8fdc19-446b-469e-a4e5-7ea89e0d62c8",
   "metadata": {
    "id": "de8fdc19-446b-469e-a4e5-7ea89e0d62c8"
   },
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function drives the entire process of instantiating, training, and evaluating the second convolutional\n",
    "# neural network architecture. \n",
    "# ===============================================================================================================\n",
    "def build_and_train_convnet_arch2(train_ds, val_ds, test_ds = None, input_shape=(520, 520, 3), optimizer='adam', metrics=['accuracy'],\n",
    "                                  epochs=20, batch_size=32, lr = 0.001, model_name = 'conv2'):\n",
    "    \n",
    "\n",
    "    # Build and compile the model.\n",
    "    model = build_convnet_classifier_arch2(input_shape=input_shape, optimizer=optimizer, learning_rate = lr, metrics=metrics)\n",
    "    \n",
    "    # Print the model summary.\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Get the path to save the trained model to.\n",
    "    model_save_path =  get_model_save_path(optimizer=optimizer, lr=lr, epochs=epochs, batch_size=batch_size, model_name=model_name)\n",
    "    \n",
    "    # Print the models save path.\n",
    "    print(f\"Model Checkpoint Save Path: {model_save_path}\")\n",
    "    \n",
    "    # Train the model\n",
    "    training_history = train_convnet_classifier(model, train_ds, val_ds, epochs=epochs, model_save_path=model_save_path)\n",
    "    \n",
    "    # Evaluate the best model on the test data.\n",
    "    if test_ds is not None:\n",
    "        \n",
    "        test_loss, test_acc, best_model = test_convnet_classifier(test_ds, model=None, model_path=model_save_path)\n",
    "    \n",
    "    return training_history, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36893521-dbc8-48f8-a643-f16263c9332f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36893521-dbc8-48f8-a643-f16263c9332f",
    "outputId": "f3e3c384-9f02-47a6-d78f-6f227fa9397c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 520, 520, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 518, 518, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 259, 259, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 257, 257, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 126, 126, 128)     73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 63, 63, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 61, 61, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               12845312  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 196)               50372     \n",
      "=================================================================\n",
      "Total params: 13,874,180\n",
      "Trainable params: 13,874,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model Checkpoint Save Path: /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 1/100\n",
      "329/329 [==============================] - 124s 360ms/step - loss: 5.2574 - accuracy: 0.0064 - val_loss: 5.1964 - val_accuracy: 0.0071\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.19640, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 2/100\n",
      "329/329 [==============================] - 117s 352ms/step - loss: 5.1895 - accuracy: 0.0080 - val_loss: 5.1428 - val_accuracy: 0.0173\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.19640 to 5.14278, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 3/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 5.1546 - accuracy: 0.0104 - val_loss: 5.1256 - val_accuracy: 0.0099\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.14278 to 5.12563, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 4/100\n",
      "329/329 [==============================] - 117s 352ms/step - loss: 5.1366 - accuracy: 0.0125 - val_loss: 5.1391 - val_accuracy: 0.0114\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 5.12563\n",
      "Epoch 5/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 5.1198 - accuracy: 0.0120 - val_loss: 5.0986 - val_accuracy: 0.0167\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.12563 to 5.09857, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 6/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 5.0980 - accuracy: 0.0144 - val_loss: 5.0771 - val_accuracy: 0.0213\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.09857 to 5.07713, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 7/100\n",
      "329/329 [==============================] - 117s 354ms/step - loss: 5.0650 - accuracy: 0.0179 - val_loss: 5.0535 - val_accuracy: 0.0223\n",
      "\n",
      "Epoch 00007: val_loss improved from 5.07713 to 5.05350, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 8/100\n",
      "329/329 [==============================] - 117s 354ms/step - loss: 5.0327 - accuracy: 0.0210 - val_loss: 5.0177 - val_accuracy: 0.0238\n",
      "\n",
      "Epoch 00008: val_loss improved from 5.05350 to 5.01765, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 9/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 5.0014 - accuracy: 0.0211 - val_loss: 5.0076 - val_accuracy: 0.0232\n",
      "\n",
      "Epoch 00009: val_loss improved from 5.01765 to 5.00755, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 10/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 4.9707 - accuracy: 0.0240 - val_loss: 4.9813 - val_accuracy: 0.0275\n",
      "\n",
      "Epoch 00010: val_loss improved from 5.00755 to 4.98131, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 11/100\n",
      "/n====================================================\n",
      "Updating the learning rate...\n",
      "Previous LR: 0.0005000000237487257  Updated LR: 0.0003846154028836351\n",
      "====================================================\n",
      "\n",
      "329/329 [==============================] - 116s 352ms/step - loss: 4.9382 - accuracy: 0.0266 - val_loss: 4.9535 - val_accuracy: 0.0300\n",
      "\n",
      "Epoch 00011: val_loss improved from 4.98131 to 4.95347, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 12/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 4.8952 - accuracy: 0.0317 - val_loss: 4.9443 - val_accuracy: 0.0318\n",
      "\n",
      "Epoch 00012: val_loss improved from 4.95347 to 4.94431, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 13/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 4.8659 - accuracy: 0.0356 - val_loss: 4.9029 - val_accuracy: 0.0377\n",
      "\n",
      "Epoch 00013: val_loss improved from 4.94431 to 4.90291, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 14/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 4.8270 - accuracy: 0.0378 - val_loss: 4.9447 - val_accuracy: 0.0362\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.90291\n",
      "Epoch 15/100\n",
      "329/329 [==============================] - 117s 352ms/step - loss: 4.7989 - accuracy: 0.0400 - val_loss: 4.8744 - val_accuracy: 0.0374\n",
      "\n",
      "Epoch 00015: val_loss improved from 4.90291 to 4.87443, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 16/100\n",
      "329/329 [==============================] - 117s 352ms/step - loss: 4.7565 - accuracy: 0.0443 - val_loss: 4.8239 - val_accuracy: 0.0408\n",
      "\n",
      "Epoch 00016: val_loss improved from 4.87443 to 4.82392, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 17/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 4.7344 - accuracy: 0.0476 - val_loss: 4.7757 - val_accuracy: 0.0501\n",
      "\n",
      "Epoch 00017: val_loss improved from 4.82392 to 4.77570, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 18/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 4.6884 - accuracy: 0.0489 - val_loss: 4.7702 - val_accuracy: 0.0473\n",
      "\n",
      "Epoch 00018: val_loss improved from 4.77570 to 4.77021, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 19/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 4.6731 - accuracy: 0.0531 - val_loss: 4.7226 - val_accuracy: 0.0516\n",
      "\n",
      "Epoch 00019: val_loss improved from 4.77021 to 4.72257, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 20/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 4.6311 - accuracy: 0.0570 - val_loss: 4.7195 - val_accuracy: 0.0563\n",
      "\n",
      "Epoch 00020: val_loss improved from 4.72257 to 4.71954, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 21/100\n",
      "/n====================================================\n",
      "Updating the learning rate...\n",
      "Previous LR: 0.00038461541407741606  Updated LR: 0.0002958580108287816\n",
      "====================================================\n",
      "\n",
      "329/329 [==============================] - 117s 354ms/step - loss: 4.5816 - accuracy: 0.0614 - val_loss: 4.6895 - val_accuracy: 0.0588\n",
      "\n",
      "Epoch 00021: val_loss improved from 4.71954 to 4.68952, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 22/100\n",
      "329/329 [==============================] - 117s 352ms/step - loss: 4.5555 - accuracy: 0.0687 - val_loss: 4.6517 - val_accuracy: 0.0594\n",
      "\n",
      "Epoch 00022: val_loss improved from 4.68952 to 4.65167, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 23/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 4.5128 - accuracy: 0.0713 - val_loss: 4.6461 - val_accuracy: 0.0662\n",
      "\n",
      "Epoch 00023: val_loss improved from 4.65167 to 4.64605, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 24/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 4.4831 - accuracy: 0.0723 - val_loss: 4.6119 - val_accuracy: 0.0665\n",
      "\n",
      "Epoch 00024: val_loss improved from 4.64605 to 4.61189, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 25/100\n",
      "329/329 [==============================] - 117s 352ms/step - loss: 4.4530 - accuracy: 0.0784 - val_loss: 4.5802 - val_accuracy: 0.0693\n",
      "\n",
      "Epoch 00025: val_loss improved from 4.61189 to 4.58023, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 26/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 4.4119 - accuracy: 0.0822 - val_loss: 4.5683 - val_accuracy: 0.0720\n",
      "\n",
      "Epoch 00026: val_loss improved from 4.58023 to 4.56827, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 27/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 4.3808 - accuracy: 0.0856 - val_loss: 4.5675 - val_accuracy: 0.0720\n",
      "\n",
      "Epoch 00027: val_loss improved from 4.56827 to 4.56747, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 28/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 4.3534 - accuracy: 0.0897 - val_loss: 4.5715 - val_accuracy: 0.0739\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4.56747\n",
      "Epoch 29/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 4.3241 - accuracy: 0.0884 - val_loss: 4.5094 - val_accuracy: 0.0748\n",
      "\n",
      "Epoch 00029: val_loss improved from 4.56747 to 4.50943, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 30/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 4.2849 - accuracy: 0.0967 - val_loss: 4.4977 - val_accuracy: 0.0813\n",
      "\n",
      "Epoch 00030: val_loss improved from 4.50943 to 4.49766, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 31/100\n",
      "/n====================================================\n",
      "Updating the learning rate...\n",
      "Previous LR: 0.00029585801530629396  Updated LR: 0.0002275830886971492\n",
      "====================================================\n",
      "\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 4.2364 - accuracy: 0.1034 - val_loss: 4.4612 - val_accuracy: 0.0801\n",
      "\n",
      "Epoch 00031: val_loss improved from 4.49766 to 4.46116, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 32/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 4.1961 - accuracy: 0.1052 - val_loss: 4.4504 - val_accuracy: 0.0860\n",
      "\n",
      "Epoch 00032: val_loss improved from 4.46116 to 4.45040, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 33/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 4.1671 - accuracy: 0.1104 - val_loss: 4.3932 - val_accuracy: 0.0887\n",
      "\n",
      "Epoch 00033: val_loss improved from 4.45040 to 4.39320, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 34/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 4.1371 - accuracy: 0.1154 - val_loss: 4.3948 - val_accuracy: 0.0934\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 4.39320\n",
      "Epoch 35/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 4.0990 - accuracy: 0.1206 - val_loss: 4.3769 - val_accuracy: 0.1011\n",
      "\n",
      "Epoch 00035: val_loss improved from 4.39320 to 4.37694, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 36/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 4.0668 - accuracy: 0.1221 - val_loss: 4.3400 - val_accuracy: 0.0971\n",
      "\n",
      "Epoch 00036: val_loss improved from 4.37694 to 4.34000, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 37/100\n",
      "329/329 [==============================] - 115s 347ms/step - loss: 4.0256 - accuracy: 0.1269 - val_loss: 4.3211 - val_accuracy: 0.1058\n",
      "\n",
      "Epoch 00037: val_loss improved from 4.34000 to 4.32111, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 38/100\n",
      "329/329 [==============================] - 115s 347ms/step - loss: 3.9986 - accuracy: 0.1298 - val_loss: 4.3167 - val_accuracy: 0.0999\n",
      "\n",
      "Epoch 00038: val_loss improved from 4.32111 to 4.31674, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 39/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 3.9653 - accuracy: 0.1338 - val_loss: 4.2999 - val_accuracy: 0.1064\n",
      "\n",
      "Epoch 00039: val_loss improved from 4.31674 to 4.29989, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 40/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 3.9320 - accuracy: 0.1381 - val_loss: 4.2875 - val_accuracy: 0.1113\n",
      "\n",
      "Epoch 00040: val_loss improved from 4.29989 to 4.28750, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 41/100\n",
      "/n====================================================\n",
      "Updating the learning rate...\n",
      "Previous LR: 0.0002275830920552835  Updated LR: 0.00017506391696560267\n",
      "====================================================\n",
      "\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 3.8912 - accuracy: 0.1477 - val_loss: 4.2443 - val_accuracy: 0.1138\n",
      "\n",
      "Epoch 00041: val_loss improved from 4.28750 to 4.24425, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 42/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 3.8607 - accuracy: 0.1481 - val_loss: 4.2311 - val_accuracy: 0.1141\n",
      "\n",
      "Epoch 00042: val_loss improved from 4.24425 to 4.23108, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 43/100\n",
      "329/329 [==============================] - 117s 352ms/step - loss: 3.8469 - accuracy: 0.1514 - val_loss: 4.2290 - val_accuracy: 0.1166\n",
      "\n",
      "Epoch 00043: val_loss improved from 4.23108 to 4.22898, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 44/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 3.7952 - accuracy: 0.1608 - val_loss: 4.2016 - val_accuracy: 0.1144\n",
      "\n",
      "Epoch 00044: val_loss improved from 4.22898 to 4.20163, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 45/100\n",
      "329/329 [==============================] - 117s 353ms/step - loss: 3.7772 - accuracy: 0.1594 - val_loss: 4.1913 - val_accuracy: 0.1184\n",
      "\n",
      "Epoch 00045: val_loss improved from 4.20163 to 4.19131, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 46/100\n",
      "329/329 [==============================] - 117s 352ms/step - loss: 3.7594 - accuracy: 0.1617 - val_loss: 4.1721 - val_accuracy: 0.1212\n",
      "\n",
      "Epoch 00046: val_loss improved from 4.19131 to 4.17208, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 47/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 3.7008 - accuracy: 0.1736 - val_loss: 4.1864 - val_accuracy: 0.1172\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 4.17208\n",
      "Epoch 48/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 3.7182 - accuracy: 0.1676 - val_loss: 4.1618 - val_accuracy: 0.1243\n",
      "\n",
      "Epoch 00048: val_loss improved from 4.17208 to 4.16181, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 49/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 3.6480 - accuracy: 0.1792 - val_loss: 4.1491 - val_accuracy: 0.1289\n",
      "\n",
      "Epoch 00049: val_loss improved from 4.16181 to 4.14914, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 50/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 3.6496 - accuracy: 0.1772 - val_loss: 4.1276 - val_accuracy: 0.1286\n",
      "\n",
      "Epoch 00050: val_loss improved from 4.14914 to 4.12756, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 51/100\n",
      "/n====================================================\n",
      "Updating the learning rate...\n",
      "Previous LR: 0.00017506392032373697  Updated LR: 0.00013466455409518228\n",
      "====================================================\n",
      "\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 3.6108 - accuracy: 0.1834 - val_loss: 4.1302 - val_accuracy: 0.1364\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 4.12756\n",
      "Epoch 52/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 3.5885 - accuracy: 0.1866 - val_loss: 4.1119 - val_accuracy: 0.1271\n",
      "\n",
      "Epoch 00052: val_loss improved from 4.12756 to 4.11193, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 53/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 3.5483 - accuracy: 0.1872 - val_loss: 4.0910 - val_accuracy: 0.1413\n",
      "\n",
      "Epoch 00053: val_loss improved from 4.11193 to 4.09102, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 54/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 3.5133 - accuracy: 0.2007 - val_loss: 4.0791 - val_accuracy: 0.1327\n",
      "\n",
      "Epoch 00054: val_loss improved from 4.09102 to 4.07914, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 55/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 3.5051 - accuracy: 0.2009 - val_loss: 4.1030 - val_accuracy: 0.1308\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 4.07914\n",
      "Epoch 56/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 3.4781 - accuracy: 0.2024 - val_loss: 4.0893 - val_accuracy: 0.1361\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 4.07914\n",
      "Epoch 57/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 3.4665 - accuracy: 0.2018 - val_loss: 4.1031 - val_accuracy: 0.1391\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 4.07914\n",
      "Epoch 58/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 3.4641 - accuracy: 0.2000 - val_loss: 4.0505 - val_accuracy: 0.1416\n",
      "\n",
      "Epoch 00058: val_loss improved from 4.07914 to 4.05047, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 59/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 3.4233 - accuracy: 0.2108 - val_loss: 4.0636 - val_accuracy: 0.1404\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 4.05047\n",
      "Epoch 60/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 3.3749 - accuracy: 0.2182 - val_loss: 4.0377 - val_accuracy: 0.1447\n",
      "\n",
      "Epoch 00060: val_loss improved from 4.05047 to 4.03773, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 61/100\n",
      "/n====================================================\n",
      "Updating the learning rate...\n",
      "Previous LR: 0.00013466455857269466  Updated LR: 0.00010358812197899589\n",
      "====================================================\n",
      "\n",
      "329/329 [==============================] - 117s 352ms/step - loss: 3.3614 - accuracy: 0.2178 - val_loss: 4.0322 - val_accuracy: 0.1478\n",
      "\n",
      "Epoch 00061: val_loss improved from 4.03773 to 4.03215, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 62/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 3.3061 - accuracy: 0.2282 - val_loss: 4.0122 - val_accuracy: 0.1475\n",
      "\n",
      "Epoch 00062: val_loss improved from 4.03215 to 4.01221, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 63/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 3.3215 - accuracy: 0.2251 - val_loss: 4.0227 - val_accuracy: 0.1494\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 4.01221\n",
      "Epoch 64/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 3.2966 - accuracy: 0.2343 - val_loss: 4.0112 - val_accuracy: 0.1515\n",
      "\n",
      "Epoch 00064: val_loss improved from 4.01221 to 4.01120, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 65/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 3.2928 - accuracy: 0.2333 - val_loss: 3.9922 - val_accuracy: 0.1543\n",
      "\n",
      "Epoch 00065: val_loss improved from 4.01120 to 3.99222, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 66/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 3.2662 - accuracy: 0.2349 - val_loss: 4.0102 - val_accuracy: 0.1568\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.99222\n",
      "Epoch 67/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 3.2500 - accuracy: 0.2373 - val_loss: 4.0017 - val_accuracy: 0.1546\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 3.99222\n",
      "Epoch 68/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 3.2253 - accuracy: 0.2435 - val_loss: 3.9985 - val_accuracy: 0.1552\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3.99222\n",
      "Epoch 69/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 3.2133 - accuracy: 0.2476 - val_loss: 4.0015 - val_accuracy: 0.1568\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 3.99222\n",
      "Epoch 70/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 3.1910 - accuracy: 0.2417 - val_loss: 3.9699 - val_accuracy: 0.1540\n",
      "\n",
      "Epoch 00070: val_loss improved from 3.99222 to 3.96991, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 71/100\n",
      "/n====================================================\n",
      "Updating the learning rate...\n",
      "Previous LR: 0.00010358812141930684  Updated LR: 7.968317032254372e-05\n",
      "====================================================\n",
      "\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 3.1501 - accuracy: 0.2571 - val_loss: 4.0036 - val_accuracy: 0.1596\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 3.96991\n",
      "Epoch 72/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 3.1448 - accuracy: 0.2586 - val_loss: 3.9850 - val_accuracy: 0.1633\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 3.96991\n",
      "Epoch 73/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 3.1286 - accuracy: 0.2615 - val_loss: 3.9478 - val_accuracy: 0.1605\n",
      "\n",
      "Epoch 00073: val_loss improved from 3.96991 to 3.94778, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 74/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 3.1111 - accuracy: 0.2570 - val_loss: 3.9731 - val_accuracy: 0.1614\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 3.94778\n",
      "Epoch 75/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 3.1173 - accuracy: 0.2589 - val_loss: 3.9537 - val_accuracy: 0.1596\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3.94778\n",
      "Epoch 76/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 3.0976 - accuracy: 0.2623 - val_loss: 3.9782 - val_accuracy: 0.1626\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 3.94778\n",
      "Epoch 77/100\n",
      "329/329 [==============================] - 115s 347ms/step - loss: 3.0745 - accuracy: 0.2611 - val_loss: 3.9557 - val_accuracy: 0.1617\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 3.94778\n",
      "Epoch 78/100\n",
      "329/329 [==============================] - 115s 347ms/step - loss: 3.0464 - accuracy: 0.2755 - val_loss: 4.0121 - val_accuracy: 0.1639\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 3.94778\n",
      "Epoch 79/100\n",
      "329/329 [==============================] - 115s 349ms/step - loss: 3.0421 - accuracy: 0.2734 - val_loss: 3.9680 - val_accuracy: 0.1694\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3.94778\n",
      "Epoch 80/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 3.0298 - accuracy: 0.2703 - val_loss: 3.9543 - val_accuracy: 0.1738\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 3.94778\n",
      "Epoch 81/100\n",
      "/n====================================================\n",
      "Updating the learning rate...\n",
      "Previous LR: 7.968317368067801e-05  Updated LR: 6.129474898513693e-05\n",
      "====================================================\n",
      "\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 2.9855 - accuracy: 0.2804 - val_loss: 3.9800 - val_accuracy: 0.1682\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 3.94778\n",
      "Epoch 82/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 2.9501 - accuracy: 0.2831 - val_loss: 3.9578 - val_accuracy: 0.1732\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 3.94778\n",
      "Epoch 83/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 2.9791 - accuracy: 0.2837 - val_loss: 3.9255 - val_accuracy: 0.1732\n",
      "\n",
      "Epoch 00083: val_loss improved from 3.94778 to 3.92546, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 84/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 2.9724 - accuracy: 0.2846 - val_loss: 3.9975 - val_accuracy: 0.1735\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 3.92546\n",
      "Epoch 85/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 2.9535 - accuracy: 0.2887 - val_loss: 3.9607 - val_accuracy: 0.1676\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 3.92546\n",
      "Epoch 86/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 2.9255 - accuracy: 0.2943 - val_loss: 3.9655 - val_accuracy: 0.1738\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 3.92546\n",
      "Epoch 87/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 2.9386 - accuracy: 0.2906 - val_loss: 3.9794 - val_accuracy: 0.1716\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 3.92546\n",
      "Epoch 88/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 2.9310 - accuracy: 0.2906 - val_loss: 3.9350 - val_accuracy: 0.1729\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3.92546\n",
      "Epoch 89/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 2.9092 - accuracy: 0.2953 - val_loss: 3.9925 - val_accuracy: 0.1738\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 3.92546\n",
      "Epoch 90/100\n",
      "329/329 [==============================] - 115s 348ms/step - loss: 2.8993 - accuracy: 0.3009 - val_loss: 3.9216 - val_accuracy: 0.1812\n",
      "\n",
      "Epoch 00090: val_loss improved from 3.92546 to 3.92156, saving model to /content/drive/MyDrive/Programming/Colab Notebooks/General_Assembly/Car/trained_models/convnet/2021_07_20-15_45_53_conv2_E100_Oadam0005_B32.keras\n",
      "Epoch 91/100\n",
      "/n====================================================\n",
      "Updating the learning rate...\n",
      "Previous LR: 6.129474786575884e-05  Updated LR: 4.714980605058372e-05\n",
      "====================================================\n",
      "\n",
      "329/329 [==============================] - 115s 349ms/step - loss: 2.8630 - accuracy: 0.3068 - val_loss: 3.9438 - val_accuracy: 0.1732\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3.92156\n",
      "Epoch 92/100\n",
      "329/329 [==============================] - 116s 349ms/step - loss: 2.8528 - accuracy: 0.3028 - val_loss: 3.9393 - val_accuracy: 0.1778\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 3.92156\n",
      "Epoch 93/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 2.8861 - accuracy: 0.2980 - val_loss: 3.9630 - val_accuracy: 0.1753\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 3.92156\n",
      "Epoch 94/100\n",
      "329/329 [==============================] - 116s 352ms/step - loss: 2.8353 - accuracy: 0.3045 - val_loss: 3.9688 - val_accuracy: 0.1763\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3.92156\n",
      "Epoch 95/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 2.8338 - accuracy: 0.3040 - val_loss: 3.9676 - val_accuracy: 0.1747\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3.92156\n",
      "Epoch 96/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 2.8214 - accuracy: 0.3091 - val_loss: 3.9364 - val_accuracy: 0.1781\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 3.92156\n",
      "Epoch 97/100\n",
      "329/329 [==============================] - 117s 352ms/step - loss: 2.7982 - accuracy: 0.3201 - val_loss: 3.9609 - val_accuracy: 0.1750\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 3.92156\n",
      "Epoch 98/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 2.8090 - accuracy: 0.3080 - val_loss: 3.9413 - val_accuracy: 0.1793\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 3.92156\n",
      "Epoch 99/100\n",
      "329/329 [==============================] - 116s 351ms/step - loss: 2.7987 - accuracy: 0.3141 - val_loss: 3.9540 - val_accuracy: 0.1843\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 3.92156\n",
      "Epoch 100/100\n",
      "329/329 [==============================] - 116s 350ms/step - loss: 2.7926 - accuracy: 0.3201 - val_loss: 3.9516 - val_accuracy: 0.1812\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 3.92156\n",
      "Couldn't save history!\n",
      "76/76 [==============================] - 16s 202ms/step - loss: 3.9199 - accuracy: 0.1843\n",
      "\n",
      "========================== Model Test Results ===============================\n",
      "Test Accuracy: 0.18428629636764526\n",
      "Test Loss: 3.9198780059814453\n",
      "=============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function shown above to train the second convnet architecture, save the training history and the\n",
    "# best model, and evaluate the best model on test data.\n",
    "history2, model2 = build_and_train_convnet_arch2(train_ds=train_dataset,\n",
    "                                               val_ds = val_dataset,\n",
    "                                               test_ds = test_dataset,\n",
    "                                               input_shape = (520, 520, 3),\n",
    "                                               optimizer = 'adam',\n",
    "                                               metrics=['accuracy'],\n",
    "                                               epochs=100,\n",
    "                                               batch_size=32,\n",
    "                                               lr = 0.0005)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02_first_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
