{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce0b649-53e9-41f7-bc74-76a515c54baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import pydot\n",
    "import graphviz\n",
    "from clr_callback import CyclicLR\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.python.client import device_lib \n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet101V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "train_directory = \"./data/organized/train/\"\n",
    "val_directory = \"./data/organized/val/\"\n",
    "test_directory = \"./data/organized/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a22a4bc1-c6df-4fde-a9ad-c04a35104c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow Tensorflow to allocate GPU memory as needed, rather than pre-allocating the entire GPU memory at the start of program execution.\n",
    "# This option allows for better monitoring of system resource utilization.\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f953664-7436-46fe-ae2c-e818514c91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function creates training, validation and test datasets using the file structure created in the\n",
    "# 01_create_train_val_test_directories notebook. \n",
    "# ===============================================================================================================\n",
    "def create_tensorflow_datasets(image_size, train_directory, val_directory, test_directory, batch_size=32):\n",
    "    \n",
    "    train_dataset = image_dataset_from_directory(directory = train_directory,\n",
    "                                                 labels='inferred',\n",
    "                                                 label_mode = 'int',\n",
    "                                                 image_size=image_size,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 smart_resize=True)\n",
    "\n",
    "    val_dataset = image_dataset_from_directory(directory = val_directory,\n",
    "                                               labels='inferred',\n",
    "                                               label_mode = 'int',\n",
    "                                               image_size=image_size,\n",
    "                                               batch_size=batch_size,\n",
    "                                               smart_resize=True)\n",
    "\n",
    "    test_dataset = image_dataset_from_directory(directory = test_directory,\n",
    "                                                labels = \"inferred\",\n",
    "                                                label_mode = \"int\",\n",
    "                                                image_size=image_size,\n",
    "                                                batch_size=batch_size,\n",
    "                                                smart_resize=True)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b3990b-5112-470e-ba96-811c81f2cb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10520 files belonging to 196 classes.\n",
      "Found 3234 files belonging to 196 classes.\n",
      "Found 2431 files belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_tensorflow_datasets(image_size=(520, 520),\n",
    "                                                                      train_directory=train_directory,\n",
    "                                                                      val_directory=val_directory,\n",
    "                                                                      test_directory=test_directory,\n",
    "                                                                      batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b2ac4b-a5fd-4779-beaa-1b298014f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_resnet_conv_layers(model_filepath, resnet_layer = 4, num_layers_to_finetune = 5):\n",
    "    \n",
    "    # Load the resnet with already trained classifier attached.\n",
    "    model = load_model(model_filepath)\n",
    "    \n",
    "    # Unfreeze all resnet layers\n",
    "    model.layers[resnet_layer].trainable = True\n",
    "    \n",
    "    # List layer numbers for all convolutional layers in the last block in the resnet 101 model.\n",
    "    block_5_layers = [343, 347, 350, 351, 355, 359, 362, 366, 370, 373]\n",
    "    \n",
    "    # List of layers to tune\n",
    "    layers_to_tune = block_5_layers[-num_layers_to_finetune:]\n",
    "    \n",
    "    # Freeze all layers not in the list above\n",
    "    layers_to_freeze = [index for index, val in enumerate(model.layers[resnet_layer].layers)]\n",
    "    layers_to_freeze = [layer for layer in layers_to_freeze if layer not in layers_to_tune]\n",
    "    \n",
    "    # Freeze all layers we are not tuning by setting the layers trainable attribute to False.\n",
    "    for layer_num in layers_to_freeze:\n",
    "        model.layers[resnet_layer].layers[layer_num].trainable = False\n",
    "        \n",
    "    for index, layer_num in enumerate(block_5_layers):\n",
    "        print(\"================================\")\n",
    "        print(f\"Layer Number: {index}\")\n",
    "        print(f\"Layer: {layer_num}\")\n",
    "        print(f\"Resnet Layer Num: {model.layers[resnet_layer].layers[layer_num]}\")\n",
    "        print(f\"Num Trainable Weights: {len(model.layers[resnet_layer].layers[layer_num].trainable_weights)}\")\n",
    "        print(\"================================\\n\")\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1b48792-4e76-4ab9-b076-ed2adca5096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Layer Number: 0\n",
      "Layer: 343\n",
      "Resnet Layer Num: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002208E9C2610>\n",
      "Num Trainable Weights: 0\n",
      "================================\n",
      "\n",
      "================================\n",
      "Layer Number: 1\n",
      "Layer: 347\n",
      "Resnet Layer Num: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002208E9C2D00>\n",
      "Num Trainable Weights: 0\n",
      "================================\n",
      "\n",
      "================================\n",
      "Layer Number: 2\n",
      "Layer: 350\n",
      "Resnet Layer Num: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002208E9C9F10>\n",
      "Num Trainable Weights: 0\n",
      "================================\n",
      "\n",
      "================================\n",
      "Layer Number: 3\n",
      "Layer: 351\n",
      "Resnet Layer Num: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002208E9CD550>\n",
      "Num Trainable Weights: 0\n",
      "================================\n",
      "\n",
      "================================\n",
      "Layer Number: 4\n",
      "Layer: 355\n",
      "Resnet Layer Num: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002208E9CDC10>\n",
      "Num Trainable Weights: 0\n",
      "================================\n",
      "\n",
      "================================\n",
      "Layer Number: 5\n",
      "Layer: 359\n",
      "Resnet Layer Num: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002208E9D2EB0>\n",
      "Num Trainable Weights: 1\n",
      "================================\n",
      "\n",
      "================================\n",
      "Layer Number: 6\n",
      "Layer: 362\n",
      "Resnet Layer Num: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002208E9D7AF0>\n",
      "Num Trainable Weights: 2\n",
      "================================\n",
      "\n",
      "================================\n",
      "Layer Number: 7\n",
      "Layer: 366\n",
      "Resnet Layer Num: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002208E9DD880>\n",
      "Num Trainable Weights: 1\n",
      "================================\n",
      "\n",
      "================================\n",
      "Layer Number: 8\n",
      "Layer: 370\n",
      "Resnet Layer Num: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002208E9DDF70>\n",
      "Num Trainable Weights: 1\n",
      "================================\n",
      "\n",
      "================================\n",
      "Layer Number: 9\n",
      "Layer: 373\n",
      "Resnet Layer Num: <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002208E9E2D00>\n",
      "Num Trainable Weights: 2\n",
      "================================\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 520, 520, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda) (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet101v2 (Functional)     (None, 17, 17, 2048)      42626560  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 196)               50372     \n",
      "=================================================================\n",
      "Total params: 43,201,476\n",
      "Trainable params: 8,443,332\n",
      "Non-trainable params: 34,758,144\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Initial model with no fine tuning yet\n",
    "model_filepath = \"./trained_models/convnet/first_resnet_lr_decay_ealy_stop/2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_21_TO_40.keras\"\n",
    "\n",
    "model = unfreeze_resnet_conv_layers(model_filepath, resnet_layer = 4, num_layers_to_finetune = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dcfad46-da18-48e7-8c56-167a159c06ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 520, 520, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda) (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet101v2 (Functional)     (None, 17, 17, 2048)      42626560  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 196)               50372     \n",
      "=================================================================\n",
      "Total params: 43,201,476\n",
      "Trainable params: 8,443,332\n",
      "Non-trainable params: 34,758,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"./trained_models/convnet/first_resnet_lr_decay_ealy_stop/2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\"\n",
    "\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(filepath=model_save_path,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor=\"val_loss\",\n",
    "                                                 verbose=1),\n",
    "             keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                               factor=0.5,\n",
    "                                               patience=2,\n",
    "                                               min_lr=5e-7,\n",
    "                                               verbose=1)]\n",
    "\n",
    "model.compile(loss = SparseCategoricalCrossentropy(),\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=2e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dbe6fff-cbfb-4863-93e1-15c910ea5a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "329/329 [==============================] - 240s 709ms/step - loss: 1.5206 - accuracy: 0.5464 - val_loss: 1.0394 - val_accuracy: 0.6939\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.03936, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40\n",
      "329/329 [==============================] - 229s 694ms/step - loss: 1.4827 - accuracy: 0.5531 - val_loss: 1.0372 - val_accuracy: 0.6991\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.03936 to 1.03719, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 3/40\n",
      "329/329 [==============================] - 228s 694ms/step - loss: 1.4746 - accuracy: 0.5571 - val_loss: 1.0295 - val_accuracy: 0.7007\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.03719 to 1.02949, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 4/40\n",
      "329/329 [==============================] - 229s 695ms/step - loss: 1.4619 - accuracy: 0.5645 - val_loss: 1.0257 - val_accuracy: 0.7032\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.02949 to 1.02568, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 5/40\n",
      "329/329 [==============================] - 234s 711ms/step - loss: 1.4764 - accuracy: 0.5561 - val_loss: 1.0275 - val_accuracy: 0.7041\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.02568\n",
      "Epoch 6/40\n",
      "329/329 [==============================] - 232s 706ms/step - loss: 1.4842 - accuracy: 0.5548 - val_loss: 1.0219 - val_accuracy: 0.7010\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.02568 to 1.02193, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 7/40\n",
      "329/329 [==============================] - 233s 707ms/step - loss: 1.4731 - accuracy: 0.5484 - val_loss: 1.0165 - val_accuracy: 0.7028\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.02193 to 1.01646, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 8/40\n",
      "329/329 [==============================] - 230s 698ms/step - loss: 1.4773 - accuracy: 0.5549 - val_loss: 1.0169 - val_accuracy: 0.7019\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.01646\n",
      "Epoch 9/40\n",
      "329/329 [==============================] - 232s 706ms/step - loss: 1.4349 - accuracy: 0.5688 - val_loss: 1.0140 - val_accuracy: 0.7035\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.01646 to 1.01403, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 10/40\n",
      "329/329 [==============================] - 233s 706ms/step - loss: 1.4650 - accuracy: 0.5590 - val_loss: 1.0154 - val_accuracy: 0.7081\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.01403\n",
      "Epoch 11/40\n",
      "329/329 [==============================] - 233s 706ms/step - loss: 1.4419 - accuracy: 0.5663 - val_loss: 1.0081 - val_accuracy: 0.7050\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.01403 to 1.00812, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 12/40\n",
      "329/329 [==============================] - 232s 704ms/step - loss: 1.4356 - accuracy: 0.5642 - val_loss: 1.0110 - val_accuracy: 0.7069\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.00812\n",
      "Epoch 13/40\n",
      "329/329 [==============================] - 232s 704ms/step - loss: 1.4378 - accuracy: 0.5737 - val_loss: 1.0092 - val_accuracy: 0.7100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.00812\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999974752427e-07.\n",
      "Epoch 14/40\n",
      "329/329 [==============================] - 231s 700ms/step - loss: 1.4489 - accuracy: 0.5634 - val_loss: 1.0006 - val_accuracy: 0.7106\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.00812 to 1.00055, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 15/40\n",
      "329/329 [==============================] - 233s 707ms/step - loss: 1.4295 - accuracy: 0.5739 - val_loss: 1.0006 - val_accuracy: 0.7093\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.00055\n",
      "Epoch 16/40\n",
      "329/329 [==============================] - 231s 702ms/step - loss: 1.4326 - accuracy: 0.5671 - val_loss: 0.9988 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.00055 to 0.99877, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 17/40\n",
      "329/329 [==============================] - 230s 699ms/step - loss: 1.4159 - accuracy: 0.5711 - val_loss: 0.9968 - val_accuracy: 0.7090\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.99877 to 0.99683, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 18/40\n",
      "329/329 [==============================] - 234s 709ms/step - loss: 1.4481 - accuracy: 0.5644 - val_loss: 0.9953 - val_accuracy: 0.7109\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.99683 to 0.99528, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 19/40\n",
      "329/329 [==============================] - 232s 705ms/step - loss: 1.4202 - accuracy: 0.5683 - val_loss: 0.9972 - val_accuracy: 0.7106\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.99528\n",
      "Epoch 20/40\n",
      "329/329 [==============================] - 232s 705ms/step - loss: 1.4197 - accuracy: 0.5732 - val_loss: 0.9985 - val_accuracy: 0.7084\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.99528\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 5e-07.\n",
      "Epoch 21/40\n",
      "329/329 [==============================] - 231s 702ms/step - loss: 1.4357 - accuracy: 0.5651 - val_loss: 0.9975 - val_accuracy: 0.7124\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.99528\n",
      "Epoch 22/40\n",
      "329/329 [==============================] - 234s 710ms/step - loss: 1.3829 - accuracy: 0.5834 - val_loss: 0.9970 - val_accuracy: 0.7115\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.99528\n",
      "Epoch 23/40\n",
      "329/329 [==============================] - 235s 713ms/step - loss: 1.3959 - accuracy: 0.5796 - val_loss: 0.9949 - val_accuracy: 0.7130\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.99528 to 0.99487, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 24/40\n",
      "329/329 [==============================] - 231s 702ms/step - loss: 1.3985 - accuracy: 0.5746 - val_loss: 0.9942 - val_accuracy: 0.7140\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.99487 to 0.99419, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 25/40\n",
      "329/329 [==============================] - 231s 702ms/step - loss: 1.4169 - accuracy: 0.5694 - val_loss: 0.9920 - val_accuracy: 0.7155\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.99419 to 0.99196, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 26/40\n",
      "329/329 [==============================] - 232s 705ms/step - loss: 1.4044 - accuracy: 0.5721 - val_loss: 0.9914 - val_accuracy: 0.7134\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.99196 to 0.99137, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 27/40\n",
      "329/329 [==============================] - 233s 706ms/step - loss: 1.4226 - accuracy: 0.5726 - val_loss: 0.9905 - val_accuracy: 0.7152\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.99137 to 0.99045, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 28/40\n",
      "329/329 [==============================] - 231s 702ms/step - loss: 1.3944 - accuracy: 0.5779 - val_loss: 0.9897 - val_accuracy: 0.7137\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.99045 to 0.98974, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 29/40\n",
      "329/329 [==============================] - 232s 703ms/step - loss: 1.4030 - accuracy: 0.5715 - val_loss: 0.9872 - val_accuracy: 0.7177\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.98974 to 0.98724, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 30/40\n",
      "329/329 [==============================] - 232s 704ms/step - loss: 1.4047 - accuracy: 0.5689 - val_loss: 0.9900 - val_accuracy: 0.7103\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.98724\n",
      "Epoch 31/40\n",
      "329/329 [==============================] - 233s 708ms/step - loss: 1.4076 - accuracy: 0.5769 - val_loss: 0.9908 - val_accuracy: 0.7130\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.98724\n",
      "Epoch 32/40\n",
      "329/329 [==============================] - 231s 700ms/step - loss: 1.3858 - accuracy: 0.5817 - val_loss: 0.9880 - val_accuracy: 0.7121\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.98724\n",
      "Epoch 33/40\n",
      "329/329 [==============================] - 230s 700ms/step - loss: 1.3955 - accuracy: 0.5780 - val_loss: 0.9887 - val_accuracy: 0.7140\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.98724\n",
      "Epoch 34/40\n",
      "329/329 [==============================] - 232s 705ms/step - loss: 1.3883 - accuracy: 0.5808 - val_loss: 0.9847 - val_accuracy: 0.7127\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.98724 to 0.98468, saving model to ./trained_models/convnet/first_resnet_lr_decay_ealy_stop\\2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80.keras\n",
      "Epoch 35/40\n",
      "329/329 [==============================] - 233s 709ms/step - loss: 1.3940 - accuracy: 0.5757 - val_loss: 0.9856 - val_accuracy: 0.7112\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.98468\n",
      "Epoch 36/40\n",
      "329/329 [==============================] - 232s 703ms/step - loss: 1.4006 - accuracy: 0.5735 - val_loss: 0.9883 - val_accuracy: 0.7127\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.98468\n",
      "Epoch 37/40\n",
      "329/329 [==============================] - 234s 709ms/step - loss: 1.3651 - accuracy: 0.5817 - val_loss: 0.9864 - val_accuracy: 0.7134\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.98468\n",
      "Epoch 38/40\n",
      "329/329 [==============================] - 234s 709ms/step - loss: 1.3797 - accuracy: 0.5779 - val_loss: 0.9869 - val_accuracy: 0.7134\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.98468\n",
      "Epoch 39/40\n",
      "329/329 [==============================] - 233s 706ms/step - loss: 1.3714 - accuracy: 0.5809 - val_loss: 0.9854 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.98468\n",
      "Epoch 40/40\n",
      "329/329 [==============================] - 233s 709ms/step - loss: 1.3773 - accuracy: 0.5824 - val_loss: 0.9881 - val_accuracy: 0.7134\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.98468\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=40,\n",
    "                    validation_data=val_dataset,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc6723e7-4b75-4026-8b2e-87445b3125e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "\n",
    "df.to_csv(\"./model_histories/2021_07_20-13_14_36_resnet101_arch1_lrdecay_FINE_TUNE_41_TO_80_HISTORY.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c357b6-7e58-4bc5-9a0d-baece193b05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.400571</td>\n",
       "      <td>0.573479</td>\n",
       "      <td>0.988342</td>\n",
       "      <td>0.712740</td>\n",
       "      <td>5.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.365050</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.986367</td>\n",
       "      <td>0.713358</td>\n",
       "      <td>5.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.379661</td>\n",
       "      <td>0.577947</td>\n",
       "      <td>0.986872</td>\n",
       "      <td>0.713358</td>\n",
       "      <td>5.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.371359</td>\n",
       "      <td>0.580894</td>\n",
       "      <td>0.985397</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>5.000000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.377250</td>\n",
       "      <td>0.582414</td>\n",
       "      <td>0.988127</td>\n",
       "      <td>0.713358</td>\n",
       "      <td>5.000000e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy            lr\n",
       "35  1.400571  0.573479  0.988342      0.712740  5.000000e-07\n",
       "36  1.365050  0.581654  0.986367      0.713358  5.000000e-07\n",
       "37  1.379661  0.577947  0.986872      0.713358  5.000000e-07\n",
       "38  1.371359  0.580894  0.985397      0.714286  5.000000e-07\n",
       "39  1.377250  0.582414  0.988127      0.713358  5.000000e-07"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf722a-f8ab-436f-9ec1-aed4edd3b956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
