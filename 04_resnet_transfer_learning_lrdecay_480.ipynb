{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a173eb3-03df-4aeb-95a9-a614de5b79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import pydot\n",
    "import graphviz\n",
    "from clr_callback import CyclicLR\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.python.client import device_lib \n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet101V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "train_directory = \"./data/organized/train/\"\n",
    "val_directory = \"./data/organized/val/\"\n",
    "test_directory = \"./data/organized/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d648de32-2ca5-4252-ba24-1cef0209eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow Tensorflow to allocate GPU memory as needed, rather than pre-allocating the entire GPU memory at the start of program execution.\n",
    "# This option allows for better monitoring of system resource utilization.\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd548f5-acb9-4506-84e6-0808a3667318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(res101_base, show_shapes=True, expand_nested=True, show_dtype=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2194a53b-a541-433a-b779-7058381f58bf",
   "metadata": {},
   "source": [
    "### Creating tf datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d12ac8-a202-48f8-8b11-1260c51a0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function creates training, validation and test datasets using the file structure created in the\n",
    "# 01_create_train_val_test_directories notebook. \n",
    "# ===============================================================================================================\n",
    "def create_tensorflow_datasets(image_size, train_directory, val_directory, test_directory, batch_size=32):\n",
    "    \n",
    "    train_dataset = image_dataset_from_directory(directory = train_directory,\n",
    "                                                 labels='inferred',\n",
    "                                                 label_mode = 'int',\n",
    "                                                 image_size=image_size,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 smart_resize=True)\n",
    "\n",
    "    val_dataset = image_dataset_from_directory(directory = val_directory,\n",
    "                                               labels='inferred',\n",
    "                                               label_mode = 'int',\n",
    "                                               image_size=image_size,\n",
    "                                               batch_size=batch_size,\n",
    "                                               smart_resize=True)\n",
    "\n",
    "    test_dataset = image_dataset_from_directory(directory = test_directory,\n",
    "                                                labels = \"inferred\",\n",
    "                                                label_mode = \"int\",\n",
    "                                                image_size=image_size,\n",
    "                                                batch_size=batch_size,\n",
    "                                                smart_resize=True)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b038a1-7505-43e0-b648-8b71f6363cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10520 files belonging to 196 classes.\n",
      "Found 3234 files belonging to 196 classes.\n",
      "Found 2431 files belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_tensorflow_datasets(image_size=(520, 520),\n",
    "                                                                      train_directory=train_directory,\n",
    "                                                                      val_directory=val_directory,\n",
    "                                                                      test_directory=test_directory,\n",
    "                                                                      batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6ed413-2181-4fc5-a63e-3534f9fca96a",
   "metadata": {},
   "source": [
    "### Custom Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a61d83-c4fb-4511-b683-1e08529aca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# Custom learning rate schedule. Updated by passing the function with keras.callbacks.LearningRateScheduler\n",
    "# to model.fit\n",
    "# ===============================================================================================================\n",
    "def learning_rate_scheduler(epoch, lr):\n",
    "    \n",
    "    if epoch <= 10:\n",
    "        updated_lr = 0.0008\n",
    "    elif epoch > 10 and epoch <= 40:\n",
    "        updated_lr = 0.0004\n",
    "    elif epoch > 40 and epoch <=60:\n",
    "        updated_lr = 0.0003\n",
    "    elif epoch > 60 and epoch <= 80:\n",
    "        updated_lr = 0.0002\n",
    "    elif epoch > 80 and epoch <= 100:\n",
    "        updated_lr = 0.0001\n",
    "    elif epoch > 100 and epoch <= 105:\n",
    "        updated_lr = 0.0025\n",
    "    elif epoch > 105 and epoch <= 110:\n",
    "        updated_lr = 0.002\n",
    "    elif epoch > 110 and epoch <= 115:\n",
    "        updated_lr = 0.001\n",
    "    elif epoch > 115 and epoch <= 120:\n",
    "        updated_lr = 0.0005\n",
    "    elif epoch > 120 and epoch <= 140:\n",
    "        updated_lr = 0.00025\n",
    "    elif epoch > 140 and epoch <= 160:\n",
    "        updated_lr = 0.0001\n",
    "    elif epoch > 160 and epoch <= 180:\n",
    "        updated_lr = 0.00005\n",
    "    elif epoch > 180 and epoch <= 200:\n",
    "        updated_lr = 0.00004\n",
    "    elif epoch > 200 and epoch <= 220:\n",
    "        updated_lr = 0.00003\n",
    "    elif epoch > 220 and epoch <= 240:\n",
    "        updated_lr = 0.00002\n",
    "    elif epoch > 240 and epoch <= 245:\n",
    "        updated_lr = 0.001\n",
    "    elif epoch > 245 and epoch <= 250:\n",
    "        updated_lr = 0.0001\n",
    "    elif epoch > 250 and epoch <= 275:\n",
    "        updated_lr = 0.00001\n",
    "    elif epoch > 275:\n",
    "        updated_lr = 0.000005\n",
    "    \n",
    "    if round(updated_lr, 2) != round(lr, 2): \n",
    "        print(\"/n====================================================\")\n",
    "        print(\"Updating the learning rate...\")\n",
    "        print(f\"Previous LR: {lr}  Updated LR: {updated_lr}\")\n",
    "        print(\"====================================================\\n\")\n",
    "            \n",
    "    return updated_lr "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb7d04d-5d97-4060-8ec3-337b5378f7b1",
   "metadata": {},
   "source": [
    "### Resnet Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4370fd2-8a00-45d0-a5bc-c1f3d5a37268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is used to instantiate either the Adam or RMSProp optimizers with the desired learning rate.\n",
    "# ===============================================================================================================\n",
    "def get_optimizer(optimizer_name, lr):\n",
    "    \n",
    "    if optimizer_name == 'rmsprop':\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.RMSProp(learning_rate = lr)\n",
    "    \n",
    "    elif optimizer_name == 'adam':\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "        \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99a9f56c-ae65-448e-958c-dea7e7d0d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is used to generate a unique filename to save the \"best model\" found during training.\n",
    "# ===============================================================================================================\n",
    "def get_model_save_path(optimizer, lr, epochs, batch_size, model_name):\n",
    "    \n",
    "    # String\n",
    "    optimizer_string = optimizer + str(lr).split('.')[1]\n",
    "    time_stamp = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
    "    \n",
    "    model_save_path = os.path.join(os.getcwd(), f\"trained_models/convnet/{time_stamp}_{model_name}_E{epochs}_O{optimizer_string}_B{batch_size}.keras\")\n",
    "    \n",
    "    return model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f3b02fc-a22e-4997-94e3-5ea9e21bc917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function insantiates and compiles a model that contains the following:\n",
    "#\n",
    "# 1. A pretrained Resnet101 base model with all weights frozen.\n",
    "# 2. A set of keras preprocessing layers to perform random data augmentations.\n",
    "# 3. A \"model top\" (output dense classifier) that needs to be trained.\n",
    "# ===============================================================================================================\n",
    "def build_resnet_classifier(input_shape, optimizer, learning_rate, metrics):\n",
    "    \n",
    "    \n",
    "    optimizer = get_optimizer(optimizer, learning_rate)\n",
    "\n",
    "    res101_base = keras.applications.ResNet101V2(weights='imagenet',\n",
    "                                                 input_shape = input_shape,\n",
    "                                                 include_top=False)\n",
    "    \n",
    "    # Freeze the resnet backbone.\n",
    "    res101_base.trainable = False\n",
    "    \n",
    "    # Create a layer that is a set of data augmentations.\n",
    "    data_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "                                          layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "                                          layers.experimental.preprocessing.RandomZoom(0.2)])\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Perform data augmentation\n",
    "    x = data_augmentation(inputs)\n",
    "    \n",
    "    # Preprocess the images the way resnet101 expects them.\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    # Pass the input to the resnet101 backbone.\n",
    "    # Setting training = False tells the resnet to run its forward pass in inference mode\n",
    "    # rather than training mode.\n",
    "    x = res101_base(x, training = False)\n",
    "    \n",
    "    x = layers.GlobalAvgPool2D()(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(480, activation='relu')(x)\n",
    "    \n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    outputs = layers.Dense(196, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss = SparseCategoricalCrossentropy(),\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c792c9f-5453-4e50-8afa-709499f93b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function is used for the following:\n",
    "#\n",
    "# 1. Setup callbacks and fit the model instantiated by the function above.\n",
    "# 2. Save the model history attribtue after training is completed.\n",
    "# ===============================================================================================================\n",
    "def train_convnet_classifier(model, train_ds, val_ds, epochs=20, model_save_path=None):\n",
    "    \n",
    "    callbacks = [keras.callbacks.ModelCheckpoint(filepath=model_save_path,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor=\"val_loss\",\n",
    "                                                 verbose=1),\n",
    "                 keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                               patience=25,\n",
    "                                               verbose=1),\n",
    "                 keras.callbacks.LearningRateScheduler(learning_rate_scheduler)]\n",
    "    \n",
    "    history = model.fit(train_ds,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_ds,\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    try:\n",
    "        history_save_path = model_save_path.split(\".\")[0] + \"_HISTORY.csv\"\n",
    "        df = pd.DataFrame(history.history)\n",
    "        df.to_csv(history_save_path, index=False)\n",
    "    except:\n",
    "        print(\"Couldn't save history!\")\n",
    "    \n",
    "    try:\n",
    "        final_save_path = model_save_path.split(\".\")[0] + \"_FINAL_SAVE.keras\"\n",
    "        save_model(model=model, filepath=final_save_path, overwrite=True, include_optimizer=True, save_format='tf')\n",
    "    except:\n",
    "        print(\"Couldn't save model!\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39f8c3b0-d317-4f44-960c-5c15bc3c993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function takes as input a tensorflow dataset containing test data, and either a trained model\n",
    "# or the path to where a trained model is located. \n",
    "#\n",
    "# The function then evaluates the model using the test data and returns the associated test metrics.\n",
    "# ===============================================================================================================\n",
    "def test_convnet_classifier(test_ds, model=None, model_path=None):\n",
    "    \n",
    "    if model is not None:\n",
    "        \n",
    "        test_loss, test_acc = model.evaluate(test_ds)\n",
    "        print(\"\\n========================== Model Test Results ===============================\")\n",
    "        print(f\"Test Accuracy: {test_acc}\")\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "        print(\"=============================================================================\\n\")\n",
    "        \n",
    "    elif model_path is not None:\n",
    "        \n",
    "        model = keras.models.load_model(model_path)\n",
    "        test_loss, test_acc = model.evaluate(test_dataset)\n",
    "        print(\"\\n========================== Model Test Results ===============================\")\n",
    "        print(f\"Test Accuracy: {test_acc}\")\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "        print(\"=============================================================================\\n\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n========================== Error ===============================\")\n",
    "        print(\"Must pass either a trained model or a path to a trained model file.\")\n",
    "        print(\"Cannot have both model and model_path = None\")\n",
    "        print(\"=============================================================================\\n\")\n",
    "        return -1\n",
    "    \n",
    "    return test_loss, test_acc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1b81f40-f9c7-426c-bcd4-5be67a06bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# This function uses all the other functions defined above to drive the entire model training process.\n",
    "# The full process implemented by this function is as follows:\n",
    "#\n",
    "# 1. Instantiate and compile the model using the build_convnet_classifier function.\n",
    "# 2. Generate a uniue filepath to save the best model found during training.\n",
    "# 3. Train the model and save the history attribute after training.\n",
    "# 4. Evaluate the best model on the test data.\n",
    "# ===============================================================================================================\n",
    "def build_and_train_resnet(train_ds, val_ds, test_ds = None, input_shape=(520, 520, 3), optimizer='adam', metrics=['accuracy'],\n",
    "                           epochs=20, batch_size=32, lr = 0.001, model_name = 'resnet101_ARCH2_LRDECAY2'):\n",
    "    \n",
    "    \n",
    "    # Build and compile the model \n",
    "    model = build_resnet_classifier(input_shape=input_shape, optimizer=optimizer, learning_rate=lr, metrics=metrics)\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    model_save_path = get_model_save_path(optimizer=optimizer, lr=lr, epochs=epochs, batch_size=batch_size, model_name=model_name)\n",
    "    \n",
    "    # Train the model\n",
    "    training_history = train_convnet_classifier(model, train_ds, val_ds, epochs=epochs, model_save_path=model_save_path)\n",
    "    \n",
    "    if test_ds is not None:\n",
    "        \n",
    "        test_loss, test_acc, best_model = test_convnet_classifier(test_ds, model=None, model_path=model_save_path)\n",
    "    \n",
    "    return training_history, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba17add2-a9b5-489b-a8d0-41f151fbadcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 520, 520, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda) (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda (None, 520, 520, 3)       0         \n",
      "_________________________________________________________________\n",
      "resnet101v2 (Functional)     (None, 17, 17, 2048)      42626560  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 480)               983520    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 196)               94276     \n",
      "=================================================================\n",
      "Total params: 43,704,356\n",
      "Trainable params: 1,077,796\n",
      "Non-trainable params: 42,626,560\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/300\n",
      "329/329 [==============================] - 226s 668ms/step - loss: 5.0348 - accuracy: 0.0236 - val_loss: 4.3583 - val_accuracy: 0.1027\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.35834, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Braden\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/300\n",
      "329/329 [==============================] - 217s 658ms/step - loss: 4.3114 - accuracy: 0.0694 - val_loss: 3.6744 - val_accuracy: 0.1704\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.35834 to 3.67444, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 3/300\n",
      "329/329 [==============================] - 219s 666ms/step - loss: 3.8621 - accuracy: 0.1170 - val_loss: 3.2652 - val_accuracy: 0.2579\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.67444 to 3.26521, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 4/300\n",
      "329/329 [==============================] - 221s 670ms/step - loss: 3.5514 - accuracy: 0.1574 - val_loss: 2.9775 - val_accuracy: 0.2888\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.26521 to 2.97746, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 5/300\n",
      "329/329 [==============================] - 217s 659ms/step - loss: 3.3398 - accuracy: 0.1930 - val_loss: 2.8190 - val_accuracy: 0.3253\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.97746 to 2.81903, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 6/300\n",
      "329/329 [==============================] - 217s 658ms/step - loss: 3.1562 - accuracy: 0.2247 - val_loss: 2.6560 - val_accuracy: 0.3426\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.81903 to 2.65596, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 7/300\n",
      "329/329 [==============================] - 219s 666ms/step - loss: 3.0295 - accuracy: 0.2432 - val_loss: 2.4923 - val_accuracy: 0.3961\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.65596 to 2.49229, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 8/300\n",
      "329/329 [==============================] - 218s 661ms/step - loss: 2.9145 - accuracy: 0.2640 - val_loss: 2.3828 - val_accuracy: 0.3989\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.49229 to 2.38275, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 9/300\n",
      "329/329 [==============================] - 221s 670ms/step - loss: 2.8015 - accuracy: 0.2799 - val_loss: 2.2945 - val_accuracy: 0.4252\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.38275 to 2.29455, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 10/300\n",
      "329/329 [==============================] - 221s 672ms/step - loss: 2.7151 - accuracy: 0.3041 - val_loss: 2.2113 - val_accuracy: 0.4409\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.29455 to 2.21132, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 11/300\n",
      "329/329 [==============================] - 219s 665ms/step - loss: 2.6346 - accuracy: 0.3211 - val_loss: 2.1394 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.21132 to 2.13941, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 12/300\n",
      "329/329 [==============================] - 219s 664ms/step - loss: 2.4923 - accuracy: 0.3498 - val_loss: 2.0961 - val_accuracy: 0.4663\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.13941 to 2.09610, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 13/300\n",
      "329/329 [==============================] - 218s 663ms/step - loss: 2.4514 - accuracy: 0.3656 - val_loss: 2.0790 - val_accuracy: 0.4626\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.09610 to 2.07901, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 14/300\n",
      "329/329 [==============================] - 219s 663ms/step - loss: 2.3974 - accuracy: 0.3678 - val_loss: 2.0236 - val_accuracy: 0.4839\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.07901 to 2.02365, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 15/300\n",
      "329/329 [==============================] - 219s 663ms/step - loss: 2.3729 - accuracy: 0.3792 - val_loss: 1.9998 - val_accuracy: 0.4827\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.02365 to 1.99979, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 16/300\n",
      "329/329 [==============================] - 219s 664ms/step - loss: 2.3177 - accuracy: 0.3945 - val_loss: 1.9799 - val_accuracy: 0.4929\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.99979 to 1.97991, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 17/300\n",
      "329/329 [==============================] - 219s 665ms/step - loss: 2.3129 - accuracy: 0.3919 - val_loss: 1.9506 - val_accuracy: 0.4994\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.97991 to 1.95060, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 18/300\n",
      "329/329 [==============================] - 216s 657ms/step - loss: 2.2614 - accuracy: 0.4038 - val_loss: 1.9301 - val_accuracy: 0.4957\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.95060 to 1.93006, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 19/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.2071 - accuracy: 0.4136 - val_loss: 1.9020 - val_accuracy: 0.4991\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.93006 to 1.90198, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 20/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.1787 - accuracy: 0.4224 - val_loss: 1.8659 - val_accuracy: 0.5152\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.90198 to 1.86591, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 21/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.1695 - accuracy: 0.4169 - val_loss: 1.8790 - val_accuracy: 0.5090\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.86591\n",
      "Epoch 22/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.1316 - accuracy: 0.4244 - val_loss: 1.8307 - val_accuracy: 0.5158\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.86591 to 1.83070, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 23/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 2.1359 - accuracy: 0.4367 - val_loss: 1.8108 - val_accuracy: 0.5204\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.83070 to 1.81078, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 24/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.0887 - accuracy: 0.4442 - val_loss: 1.8050 - val_accuracy: 0.5186\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.81078 to 1.80496, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 25/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 2.0443 - accuracy: 0.4460 - val_loss: 1.7804 - val_accuracy: 0.5269\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.80496 to 1.78036, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 26/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.0479 - accuracy: 0.4468 - val_loss: 1.7950 - val_accuracy: 0.5266\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.78036\n",
      "Epoch 27/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 2.0291 - accuracy: 0.4539 - val_loss: 1.7779 - val_accuracy: 0.5278\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.78036 to 1.77795, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 28/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.9948 - accuracy: 0.4558 - val_loss: 1.7412 - val_accuracy: 0.5383\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.77795 to 1.74121, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 29/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.9668 - accuracy: 0.4705 - val_loss: 1.7383 - val_accuracy: 0.5353\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.74121 to 1.73833, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 30/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.9646 - accuracy: 0.4664 - val_loss: 1.7225 - val_accuracy: 0.5408\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.73833 to 1.72248, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 31/300\n",
      "329/329 [==============================] - 214s 649ms/step - loss: 1.9703 - accuracy: 0.4634 - val_loss: 1.6992 - val_accuracy: 0.5532\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.72248 to 1.69925, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 32/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.9224 - accuracy: 0.4818 - val_loss: 1.6828 - val_accuracy: 0.5470\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.69925 to 1.68280, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 33/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.8935 - accuracy: 0.4856 - val_loss: 1.6832 - val_accuracy: 0.5482\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.68280\n",
      "Epoch 34/300\n",
      "329/329 [==============================] - 214s 650ms/step - loss: 1.8804 - accuracy: 0.4904 - val_loss: 1.6726 - val_accuracy: 0.5498\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.68280 to 1.67255, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 35/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.8743 - accuracy: 0.4834 - val_loss: 1.6808 - val_accuracy: 0.5467\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.67255\n",
      "Epoch 36/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.8373 - accuracy: 0.4951 - val_loss: 1.6548 - val_accuracy: 0.5563\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.67255 to 1.65482, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 37/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.8522 - accuracy: 0.4934 - val_loss: 1.6484 - val_accuracy: 0.5563\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.65482 to 1.64842, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 38/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.8107 - accuracy: 0.5001 - val_loss: 1.6264 - val_accuracy: 0.5622\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.64842 to 1.62638, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 39/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.7954 - accuracy: 0.5072 - val_loss: 1.6145 - val_accuracy: 0.5662\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.62638 to 1.61450, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 40/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.7860 - accuracy: 0.5126 - val_loss: 1.6237 - val_accuracy: 0.5547\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.61450\n",
      "Epoch 41/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.7835 - accuracy: 0.5103 - val_loss: 1.6111 - val_accuracy: 0.5609\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.61450 to 1.61113, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 42/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.7262 - accuracy: 0.5175 - val_loss: 1.6007 - val_accuracy: 0.5615\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.61113 to 1.60068, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 43/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.6975 - accuracy: 0.5303 - val_loss: 1.5811 - val_accuracy: 0.5686\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.60068 to 1.58107, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 44/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.7066 - accuracy: 0.5293 - val_loss: 1.5778 - val_accuracy: 0.5773\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.58107 to 1.57779, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 45/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.6955 - accuracy: 0.5299 - val_loss: 1.5703 - val_accuracy: 0.5665\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.57779 to 1.57029, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 46/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.6783 - accuracy: 0.5371 - val_loss: 1.5624 - val_accuracy: 0.5742\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.57029 to 1.56236, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 47/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.6840 - accuracy: 0.5338 - val_loss: 1.5655 - val_accuracy: 0.5727\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.56236\n",
      "Epoch 48/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.6621 - accuracy: 0.5411 - val_loss: 1.5516 - val_accuracy: 0.5773\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.56236 to 1.55158, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 49/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.6385 - accuracy: 0.5471 - val_loss: 1.5443 - val_accuracy: 0.5720\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.55158 to 1.54426, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 50/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.6540 - accuracy: 0.5433 - val_loss: 1.5467 - val_accuracy: 0.5699\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.54426\n",
      "Epoch 51/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.6227 - accuracy: 0.5501 - val_loss: 1.5379 - val_accuracy: 0.5693\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.54426 to 1.53788, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 52/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.6364 - accuracy: 0.5468 - val_loss: 1.5386 - val_accuracy: 0.5761\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.53788\n",
      "Epoch 53/300\n",
      "329/329 [==============================] - 215s 654ms/step - loss: 1.5827 - accuracy: 0.5540 - val_loss: 1.5217 - val_accuracy: 0.5816\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.53788 to 1.52174, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 54/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.5736 - accuracy: 0.5651 - val_loss: 1.5198 - val_accuracy: 0.5860\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.52174 to 1.51984, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 55/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.6056 - accuracy: 0.5510 - val_loss: 1.5290 - val_accuracy: 0.5798\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.51984\n",
      "Epoch 56/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.5718 - accuracy: 0.5607 - val_loss: 1.5071 - val_accuracy: 0.5921\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.51984 to 1.50714, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 57/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.5651 - accuracy: 0.5578 - val_loss: 1.5049 - val_accuracy: 0.5915\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.50714 to 1.50494, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 58/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.5766 - accuracy: 0.5620 - val_loss: 1.5021 - val_accuracy: 0.5891\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.50494 to 1.50209, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 59/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.5542 - accuracy: 0.5645 - val_loss: 1.5024 - val_accuracy: 0.5853\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.50209\n",
      "Epoch 60/300\n",
      "329/329 [==============================] - 214s 651ms/step - loss: 1.5340 - accuracy: 0.5702 - val_loss: 1.4943 - val_accuracy: 0.5906\n",
      "\n",
      "Epoch 00060: val_loss improved from 1.50209 to 1.49435, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 61/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.5280 - accuracy: 0.5719 - val_loss: 1.4802 - val_accuracy: 0.5955\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.49435 to 1.48022, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 62/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.4968 - accuracy: 0.5826 - val_loss: 1.4709 - val_accuracy: 0.5934\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.48022 to 1.47088, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 63/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.4924 - accuracy: 0.5805 - val_loss: 1.4679 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.47088 to 1.46790, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 64/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.5125 - accuracy: 0.5800 - val_loss: 1.4768 - val_accuracy: 0.5903\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.46790\n",
      "Epoch 65/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.4832 - accuracy: 0.5794 - val_loss: 1.4596 - val_accuracy: 0.5977\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.46790 to 1.45963, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 66/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.4896 - accuracy: 0.5852 - val_loss: 1.4593 - val_accuracy: 0.5965\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.45963 to 1.45929, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 67/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.4897 - accuracy: 0.5857 - val_loss: 1.4550 - val_accuracy: 0.5962\n",
      "\n",
      "Epoch 00067: val_loss improved from 1.45929 to 1.45502, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 68/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.4678 - accuracy: 0.5878 - val_loss: 1.4618 - val_accuracy: 0.6005\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.45502\n",
      "Epoch 69/300\n",
      "329/329 [==============================] - 214s 651ms/step - loss: 1.4665 - accuracy: 0.5874 - val_loss: 1.4595 - val_accuracy: 0.5986\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.45502\n",
      "Epoch 70/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.4322 - accuracy: 0.5987 - val_loss: 1.4537 - val_accuracy: 0.5993\n",
      "\n",
      "Epoch 00070: val_loss improved from 1.45502 to 1.45370, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 71/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.4172 - accuracy: 0.6009 - val_loss: 1.4448 - val_accuracy: 0.5999\n",
      "\n",
      "Epoch 00071: val_loss improved from 1.45370 to 1.44480, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 72/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.4242 - accuracy: 0.5973 - val_loss: 1.4409 - val_accuracy: 0.6045\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.44480 to 1.44087, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 73/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.4184 - accuracy: 0.5972 - val_loss: 1.4423 - val_accuracy: 0.6005\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.44087\n",
      "Epoch 74/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.4101 - accuracy: 0.5962 - val_loss: 1.4443 - val_accuracy: 0.5977\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.44087\n",
      "Epoch 75/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.3950 - accuracy: 0.6046 - val_loss: 1.4505 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.44087\n",
      "Epoch 76/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.4277 - accuracy: 0.6046 - val_loss: 1.4335 - val_accuracy: 0.6048\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.44087 to 1.43348, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 77/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3993 - accuracy: 0.6009 - val_loss: 1.4306 - val_accuracy: 0.6045\n",
      "\n",
      "Epoch 00077: val_loss improved from 1.43348 to 1.43057, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 78/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.4014 - accuracy: 0.6055 - val_loss: 1.4304 - val_accuracy: 0.6048\n",
      "\n",
      "Epoch 00078: val_loss improved from 1.43057 to 1.43043, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 79/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.4002 - accuracy: 0.6004 - val_loss: 1.4254 - val_accuracy: 0.6095\n",
      "\n",
      "Epoch 00079: val_loss improved from 1.43043 to 1.42545, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 80/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.3907 - accuracy: 0.6082 - val_loss: 1.4215 - val_accuracy: 0.6095\n",
      "\n",
      "Epoch 00080: val_loss improved from 1.42545 to 1.42147, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 81/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.3750 - accuracy: 0.6112 - val_loss: 1.4160 - val_accuracy: 0.6101\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.42147 to 1.41604, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 82/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3369 - accuracy: 0.6241 - val_loss: 1.4135 - val_accuracy: 0.6129\n",
      "\n",
      "Epoch 00082: val_loss improved from 1.41604 to 1.41354, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 83/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.3424 - accuracy: 0.6196 - val_loss: 1.4089 - val_accuracy: 0.6113\n",
      "\n",
      "Epoch 00083: val_loss improved from 1.41354 to 1.40885, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 84/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.3489 - accuracy: 0.6198 - val_loss: 1.4030 - val_accuracy: 0.6194\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.40885 to 1.40305, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 85/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.3465 - accuracy: 0.6170 - val_loss: 1.4065 - val_accuracy: 0.6150\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.40305\n",
      "Epoch 86/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.3229 - accuracy: 0.6256 - val_loss: 1.4042 - val_accuracy: 0.6116\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.40305\n",
      "Epoch 87/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3212 - accuracy: 0.6261 - val_loss: 1.4059 - val_accuracy: 0.6104\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.40305\n",
      "Epoch 88/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3311 - accuracy: 0.6238 - val_loss: 1.4007 - val_accuracy: 0.6104\n",
      "\n",
      "Epoch 00088: val_loss improved from 1.40305 to 1.40066, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 89/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.3370 - accuracy: 0.6274 - val_loss: 1.4033 - val_accuracy: 0.6110\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.40066\n",
      "Epoch 90/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.3119 - accuracy: 0.6260 - val_loss: 1.4005 - val_accuracy: 0.6092\n",
      "\n",
      "Epoch 00090: val_loss improved from 1.40066 to 1.40051, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 91/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.3335 - accuracy: 0.6178 - val_loss: 1.3972 - val_accuracy: 0.6138\n",
      "\n",
      "Epoch 00091: val_loss improved from 1.40051 to 1.39723, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 92/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.3127 - accuracy: 0.6298 - val_loss: 1.3914 - val_accuracy: 0.6147\n",
      "\n",
      "Epoch 00092: val_loss improved from 1.39723 to 1.39145, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 93/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.3218 - accuracy: 0.6212 - val_loss: 1.3910 - val_accuracy: 0.6119\n",
      "\n",
      "Epoch 00093: val_loss improved from 1.39145 to 1.39105, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 94/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.3002 - accuracy: 0.6276 - val_loss: 1.3932 - val_accuracy: 0.6113\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.39105\n",
      "Epoch 95/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.3085 - accuracy: 0.6263 - val_loss: 1.3890 - val_accuracy: 0.6129\n",
      "\n",
      "Epoch 00095: val_loss improved from 1.39105 to 1.38903, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 96/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.2825 - accuracy: 0.6375 - val_loss: 1.3889 - val_accuracy: 0.6169\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.38903 to 1.38888, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 97/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.2947 - accuracy: 0.6325 - val_loss: 1.3848 - val_accuracy: 0.6169\n",
      "\n",
      "Epoch 00097: val_loss improved from 1.38888 to 1.38476, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 98/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.2824 - accuracy: 0.6352 - val_loss: 1.3881 - val_accuracy: 0.6184\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.38476\n",
      "Epoch 99/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.2951 - accuracy: 0.6273 - val_loss: 1.3827 - val_accuracy: 0.6169\n",
      "\n",
      "Epoch 00099: val_loss improved from 1.38476 to 1.38267, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 100/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.2947 - accuracy: 0.6352 - val_loss: 1.3815 - val_accuracy: 0.6187\n",
      "\n",
      "Epoch 00100: val_loss improved from 1.38267 to 1.38147, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 101/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.2806 - accuracy: 0.6413 - val_loss: 1.3801 - val_accuracy: 0.6156\n",
      "\n",
      "Epoch 00101: val_loss improved from 1.38147 to 1.38011, saving model to C:\\Users\\Braden\\Desktop\\Data_Science\\04_General_Assembly\\05_Projects\\03_car\\trained_models/convnet\\2021_07_23-02_04_21_resnet101_ARCH2_LRDECAY2_E300_Oadam0008_B32.keras\n",
      "Epoch 102/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.4156 - accuracy: 0.3610 - val_loss: 1.8675 - val_accuracy: 0.4923\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.38011\n",
      "Epoch 103/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.5442 - accuracy: 0.3347 - val_loss: 1.9145 - val_accuracy: 0.4731\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.38011\n",
      "Epoch 104/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.5462 - accuracy: 0.3382 - val_loss: 1.9212 - val_accuracy: 0.4685\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.38011\n",
      "Epoch 105/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 2.5307 - accuracy: 0.3343 - val_loss: 1.9451 - val_accuracy: 0.4629\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.38011\n",
      "Epoch 106/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 2.5401 - accuracy: 0.3439 - val_loss: 1.7999 - val_accuracy: 0.5028\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.38011\n",
      "Epoch 107/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 2.2980 - accuracy: 0.3881 - val_loss: 1.7190 - val_accuracy: 0.5195\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.38011\n",
      "Epoch 108/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.2410 - accuracy: 0.4038 - val_loss: 1.7088 - val_accuracy: 0.5189\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.38011\n",
      "Epoch 109/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.1932 - accuracy: 0.4135 - val_loss: 1.7329 - val_accuracy: 0.5226\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.38011\n",
      "Epoch 110/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 2.1741 - accuracy: 0.4195 - val_loss: 1.7225 - val_accuracy: 0.5124\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.38011\n",
      "Epoch 111/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 2.1543 - accuracy: 0.4169 - val_loss: 1.7247 - val_accuracy: 0.5269\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.38011\n",
      "Epoch 112/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.8282 - accuracy: 0.4936 - val_loss: 1.5814 - val_accuracy: 0.5628\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.38011\n",
      "Epoch 113/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.7628 - accuracy: 0.5080 - val_loss: 1.5576 - val_accuracy: 0.5600\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.38011\n",
      "Epoch 114/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.7376 - accuracy: 0.5183 - val_loss: 1.5707 - val_accuracy: 0.5609\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.38011\n",
      "Epoch 115/300\n",
      "329/329 [==============================] - 215s 651ms/step - loss: 1.6577 - accuracy: 0.5305 - val_loss: 1.5762 - val_accuracy: 0.5690\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.38011\n",
      "Epoch 116/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.6608 - accuracy: 0.5349 - val_loss: 1.5310 - val_accuracy: 0.5705\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.38011\n",
      "Epoch 117/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.5395 - accuracy: 0.5634 - val_loss: 1.5085 - val_accuracy: 0.5785\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.38011\n",
      "Epoch 118/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.4753 - accuracy: 0.5765 - val_loss: 1.4861 - val_accuracy: 0.5863\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.38011\n",
      "Epoch 119/300\n",
      "329/329 [==============================] - 215s 652ms/step - loss: 1.4590 - accuracy: 0.5822 - val_loss: 1.4802 - val_accuracy: 0.5860\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.38011\n",
      "Epoch 120/300\n",
      "329/329 [==============================] - 215s 653ms/step - loss: 1.4288 - accuracy: 0.5864 - val_loss: 1.4618 - val_accuracy: 0.5915\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.38011\n",
      "Epoch 121/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.3919 - accuracy: 0.5937 - val_loss: 1.4946 - val_accuracy: 0.5878\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.38011\n",
      "Epoch 122/300\n",
      "329/329 [==============================] - 220s 666ms/step - loss: 1.3393 - accuracy: 0.6106 - val_loss: 1.4535 - val_accuracy: 0.5983\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.38011\n",
      "Epoch 123/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 1.3136 - accuracy: 0.6151 - val_loss: 1.4367 - val_accuracy: 0.5999\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.38011\n",
      "Epoch 124/300\n",
      "329/329 [==============================] - 216s 656ms/step - loss: 1.2962 - accuracy: 0.6216 - val_loss: 1.4479 - val_accuracy: 0.6014\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.38011\n",
      "Epoch 125/300\n",
      "329/329 [==============================] - 217s 657ms/step - loss: 1.2973 - accuracy: 0.6249 - val_loss: 1.4352 - val_accuracy: 0.6024\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.38011\n",
      "Epoch 126/300\n",
      "329/329 [==============================] - 216s 654ms/step - loss: 1.2921 - accuracy: 0.6243 - val_loss: 1.4292 - val_accuracy: 0.6036\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.38011\n",
      "Epoch 00126: early stopping\n",
      "76/76 [==============================] - 39s 498ms/step - loss: 1.3741 - accuracy: 0.6199\n",
      "\n",
      "========================== Model Test Results ===============================\n",
      "Test Accuracy: 0.6199095249176025\n",
      "Test Loss: 1.3741015195846558\n",
      "=============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history, model = build_and_train_resnet(train_ds=train_dataset,\n",
    "                                         val_ds = val_dataset,\n",
    "                                         test_ds = test_dataset,\n",
    "                                         input_shape = (520, 520, 3),\n",
    "                                         optimizer = 'adam',\n",
    "                                         metrics=['accuracy'],\n",
    "                                         lr = 0.0008,\n",
    "                                         epochs=300,\n",
    "                                         batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73c99fce-674e-474b-91b7-ae5d4ec37e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69c311f2-00b1-4c6d-a43d-37705f2fbf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./model_histories/first_resnet101_lrdecay_history_300epochs_ARCH2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2cfc7-a16a-4fb8-aa6b-48983be02218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
