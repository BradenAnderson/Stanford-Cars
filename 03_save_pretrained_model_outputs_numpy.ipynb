{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e99c8d58-92df-43a1-9008-be679b8a20f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import keras_tuner as kt\n",
    "import tensorboard\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.python.client import device_lib \n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet101V2, Xception, InceptionResNetV2\n",
    "from tensorflow.keras.applications import resnet_v2, xception, inception_resnet_v2\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "global PROJECT_DIRECTORY\n",
    "PROJECT_DIRECTORY = os.getcwd()\n",
    "\n",
    "train_directory = \"./data/organized/train/\"\n",
    "val_directory = \"./data/organized/val/\"\n",
    "test_directory = \"./data/organized/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f915fbec-3be0-4af7-9c79-c81575e96875",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedf219c-a413-44fd-af9b-21b8a4363d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensorflow_datasets(image_size, train_directory, val_directory, test_directory, batch_size=32):\n",
    "    \n",
    "    train_dataset = image_dataset_from_directory(directory = train_directory,\n",
    "                                                 labels='inferred',\n",
    "                                                 label_mode = 'int',\n",
    "                                                 image_size=image_size,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 smart_resize=True)\n",
    "\n",
    "    val_dataset = image_dataset_from_directory(directory = val_directory,\n",
    "                                               labels='inferred',\n",
    "                                               label_mode = 'int',\n",
    "                                               image_size=image_size,\n",
    "                                               batch_size=batch_size,\n",
    "                                               smart_resize=True)\n",
    "\n",
    "    test_dataset = image_dataset_from_directory(directory = test_directory,\n",
    "                                                labels = \"inferred\",\n",
    "                                                label_mode = \"int\",\n",
    "                                                image_size=image_size,\n",
    "                                                batch_size=batch_size,\n",
    "                                                smart_resize=True)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b031eb9-1e2c-40d4-a7b7-41c5ea4f3016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10520 files belonging to 196 classes.\n",
      "Found 3234 files belonging to 196 classes.\n",
      "Found 2431 files belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_tensorflow_datasets(image_size=(520, 520),\n",
    "                                                                      train_directory=train_directory,\n",
    "                                                                      val_directory=val_directory,\n",
    "                                                                      test_directory=test_directory,\n",
    "                                                                      batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88381f58-e9d3-4421-9578-1841f3099d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_base_model_outputs(tf_dataset, base_model_type, input_shape, output_pooling):\n",
    "    \n",
    "    valid_base_model_types = ['resnet101', 'xception', 'inception_resnet']\n",
    "    \n",
    "    if base_model_type not in valid_base_model_types:\n",
    "        print(\"/n===========================================================\")\n",
    "        print(\"Invalid input for parameter base_model_type\")\n",
    "        print(f\"Valid inputs are: {valid_base_model_types}\")\n",
    "        print(\"===========================================================\\n\")\n",
    "        return -1\n",
    "    \n",
    "    target_labels = []\n",
    "    model_output_features = []\n",
    "    \n",
    "\n",
    "    data_augmentation = keras.Sequential([layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "                                          layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "                                          layers.experimental.preprocessing.RandomZoom(0.2)])\n",
    "    \n",
    "    \n",
    "    if base_model_type == 'resnet101':\n",
    "        \n",
    "        base_model =  ResNet101V2(weights='imagenet',\n",
    "                                  input_shape = input_shape,\n",
    "                                  include_top=False,\n",
    "                                  pooling = output_pooling)\n",
    "            \n",
    "        for images, labels in tf_dataset:\n",
    "                \n",
    "            augmented_images = data_augmentation(images)\n",
    "\n",
    "            preprocessed_images = resnet_v2.preprocess_input(augmented_images)\n",
    "\n",
    "            features = base_model.predict(preprocessed_images)\n",
    "\n",
    "            model_output_features.append(features)\n",
    "\n",
    "            target_labels.append(labels)\n",
    "\n",
    "        return np.concatenate(model_output_features), np.concatenate(target_labels)\n",
    "        \n",
    "    elif base_model_type == 'xception':\n",
    "        \n",
    "        base_model = Xception(weights='imagenet',\n",
    "                              input_shape=input_shape,\n",
    "                              include_top=False,\n",
    "                              pooling = output_pooling)\n",
    "        \n",
    "        for images, labels in tf_dataset:\n",
    "            \n",
    "            augmented_images = data_augmentation(images)\n",
    "            \n",
    "            preprocessed_images = xception.preprocess_input(augmented_images)\n",
    "            \n",
    "            features = base_model.predict(preprocessed_images)\n",
    "            \n",
    "            model_output_features.append(features)\n",
    "            \n",
    "            target_labels.append(labels)\n",
    "            \n",
    "        return np.concatenate(model_output_features), np.concatenate(target_labels)\n",
    "    \n",
    "    elif base_model_type == 'inception_resnet':\n",
    "        \n",
    "        base_model = InceptionResNetV2(weights='imagenet',\n",
    "                                       input_shape=input_shape,\n",
    "                                       include_top=False,\n",
    "                                       pooling = output_pooling)\n",
    "        \n",
    "        for images, labels in tf_dataset:\n",
    "            \n",
    "            augmented_images = data_augmentation(images)\n",
    "            \n",
    "            preprocessed_images = inception_resnet_v2.preprocess_input(augmented_images)\n",
    "            \n",
    "            features = base_model.predict(preprocessed_images)\n",
    "            \n",
    "            model_output_features.append(features)\n",
    "            \n",
    "            target_labels.append(labels)\n",
    "            \n",
    "        return (np.concatenate(model_output_features), np.concatenate(target_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b51c70-641b-423a-b916-29031214863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_base_model_outputs_to_disk(features, labels, base_model_type, input_shape, output_pooling, num_unique_epochs, current_epoch,\n",
    "                                    dataset_type):\n",
    "    \n",
    "    global PROJECT_DIRECTORY\n",
    "    \n",
    "    # Directory that will contain all outputs from base_model_type (as many data augmented variations as we make) that are\n",
    "    # preprocessed in the same way... (same starting image size and output pooling).\n",
    "    base_dir_name = f\"pretrained_model_output_features_numpy/{base_model_type}_pool{str(output_pooling)}_inShape_{str(input_shape)}_numpy\"\n",
    "    base_save_directory = os.path.join(PROJECT_DIRECTORY, base_dir_name)\n",
    "    \n",
    "    # Adding a unique folder inside the above directory that specifies if this is a train, val or test set\n",
    "    full_dir_path = os.path.join(base_save_directory, f\"{dataset_type}_unique_epoch_{current_epoch}_of_{num_unique_epochs}_numpy_\")\n",
    "    \n",
    "    os.makedirs(full_dir_path, exist_ok = True)\n",
    "    \n",
    "    full_file_path = os.path.join(full_dir_path, f\"{dataset_type}.npz\")\n",
    "    \n",
    "    np.savez_compressed(file = full_file_path,\n",
    "                        **{f\"{dataset_type}_features\" : features, f\"{dataset_type}_labels\" : labels})\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f50ef79-dbaa-4585-b5c0-95a8b9b2ad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf_dataset, base_model_type, input_shape, output_pooling\n",
    "\n",
    "def create_base_model_output_dirs(train_dataset, val_dataset, test_dataset, base_model_type, input_shape, output_pooling, num_unique_epochs,\n",
    "                                  verbose = True):\n",
    "    \n",
    "    global_clock = time.time()\n",
    "    \n",
    "    dataset_types = ['train', 'val', 'test']\n",
    "    datasets = [train_dataset, val_dataset, test_dataset]\n",
    "    \n",
    "    for epoch_num in range(1, num_unique_epochs + 1):\n",
    "    \n",
    "        for dataset, dset_type in zip(datasets, dataset_types):\n",
    "            \n",
    "            if verbose:\n",
    "                start_time = time.time()\n",
    "                print(\"\\n=======================================================================================\")\n",
    "                print(f\"Calculating pretrained {base_model_type} outputs for the {dset_type} dataset.\")\n",
    "                print(f\"Processing epoch set {epoch_num } of {num_unique_epochs}\")\n",
    "                print(f\"Output pooling setting: {output_pooling}\")\n",
    "                print(f\"Size of images before {base_model_type} preprocessing: {input_shape}\")\n",
    "                print(\"=======================================================================================\\n\")\n",
    "            \n",
    "            output_features, labels = calculate_base_model_outputs(tf_dataset = dataset,\n",
    "                                                                   base_model_type = base_model_type,\n",
    "                                                                   input_shape = input_shape,\n",
    "                                                                   output_pooling = output_pooling)\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"\\n=======================================================================================\")\n",
    "                print(f\"Finished calcuating {base_model_type} outputs!\")\n",
    "                print(f\"Time spent getting features: {time.time() - start_time} seconds.\")\n",
    "                print(\"Starting to save outputs to a numpy array on disk...\")\n",
    "                save_start_time = time.time()\n",
    "                print(\"=======================================================================================\\n\")\n",
    "        \n",
    "            save_base_model_outputs_to_disk(features = output_features,\n",
    "                                            labels = labels,\n",
    "                                            base_model_type = base_model_type,\n",
    "                                            input_shape = input_shape,\n",
    "                                            output_pooling = output_pooling,\n",
    "                                            num_unique_epochs=num_unique_epochs,\n",
    "                                            current_epoch = epoch_num,\n",
    "                                            dataset_type = dset_type)\n",
    "            if verbose:\n",
    "                print(\"\\n=======================================================================================\")\n",
    "                print(\"Finished saving to disk!\")\n",
    "                print(f\"Time spent saving: {time.time() - save_start_time} seconds.\")\n",
    "                print(\"=======================================================================================\\n\")\n",
    "                \n",
    "    if verbose:\n",
    "        print(\"\\n=======================================================================================\")\n",
    "        print(\"Finished getting preprocessed features for all datasets and epochs!\")\n",
    "        print(f\"Time spent: {round(((time.time() - global_clock) / 60), 2)} minutes.\")\n",
    "        print(\"=======================================================================================\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "585ca6ec-98ee-4036-80a5-b7625c2c9805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================================================\n",
      "Calculating pretrained resnet101 outputs for the train dataset.\n",
      "Processing epoch set 1 of 1\n",
      "Output pooling setting: None\n",
      "Size of images before resnet101 preprocessing: (520, 520, 3)\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "=======================================================================================\n",
      "Finished calcuating resnet101 outputs!\n",
      "Time spent getting features: 385.53385853767395 seconds.\n",
      "Starting to save outputs to a numpy array on disk...\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "=======================================================================================\n",
      "Finished saving to disk!\n",
      "Time spent saving: 270.0609202384949 seconds.\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "=======================================================================================\n",
      "Calculating pretrained resnet101 outputs for the val dataset.\n",
      "Processing epoch set 1 of 1\n",
      "Output pooling setting: None\n",
      "Size of images before resnet101 preprocessing: (520, 520, 3)\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "=======================================================================================\n",
      "Finished calcuating resnet101 outputs!\n",
      "Time spent getting features: 106.22245979309082 seconds.\n",
      "Starting to save outputs to a numpy array on disk...\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "=======================================================================================\n",
      "Finished saving to disk!\n",
      "Time spent saving: 79.77779841423035 seconds.\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "=======================================================================================\n",
      "Calculating pretrained resnet101 outputs for the test dataset.\n",
      "Processing epoch set 1 of 1\n",
      "Output pooling setting: None\n",
      "Size of images before resnet101 preprocessing: (520, 520, 3)\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "=======================================================================================\n",
      "Finished calcuating resnet101 outputs!\n",
      "Time spent getting features: 66.68327283859253 seconds.\n",
      "Starting to save outputs to a numpy array on disk...\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "=======================================================================================\n",
      "Finished saving to disk!\n",
      "Time spent saving: 59.89725351333618 seconds.\n",
      "=======================================================================================\n",
      "\n",
      "\n",
      "=======================================================================================\n",
      "Finished getting preprocessed features for all datasets and epochs!\n",
      "Time spent: 16.14 minutes.\n",
      "=======================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "create_base_model_output_dirs(train_dataset = train_dataset,\n",
    "                              val_dataset = val_dataset,\n",
    "                              test_dataset = test_dataset,\n",
    "                              base_model_type = 'resnet101',\n",
    "                              input_shape = (520, 520, 3),\n",
    "                              output_pooling = 'None',\n",
    "                              num_unique_epochs = 1,\n",
    "                              verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e27eef6d-99fa-472e-b8a3-710b524bdcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading the numpy arrays.\n",
    "'''\n",
    "train_arrays = np.load(dir_path)\n",
    "t_features = train_arrays['train_features']\n",
    "t_labels = train_arrays['train_labels']\n",
    "\n",
    "\n",
    "\n",
    "print(f\"output_features shape {output_features.shape}\")\n",
    "print(f\"labels shape: {labels.shape}\")\n",
    "''';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
